![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# The Black Swan

Back to Discover

[[book_md/the-black-swan/preview|preview]]

  * [[book_md/the-black-swan|the-black-swan]]
  * Full Book Guide

    * [[book_md/the-black-swan/shortform-introduction|shortform-introduction]]
    * [[book_md/the-black-swan/chapter-1|chapter-1]]
    * [[book_md/the-black-swan/chapter-2|chapter-2]]
    * [[book_md/the-black-swan/chapter-3|chapter-3]]
    * [[book_md/the-black-swan/exercise-responding-to-randomness|exercise-responding-to-randomness]]
    * [[book_md/the-black-swan/chapter-4|chapter-4]]
    * [[book_md/the-black-swan/exercise-learning-the-limits-of-prediction|exercise-learning-the-limits-of-prediction]]
    * [[book_md/the-black-swan/chapter-5|chapter-5]]
    * [[book_md/the-black-swan/chapter-6|chapter-6]]
    * [[book_md/the-black-swan/chapter-7|chapter-7]]
    * [[book_md/the-black-swan/exercise-the-barbell-strategy|exercise-the-barbell-strategy]]
    * [[book_md/the-black-swan/exercise-maximizing-positive-black-swans|exercise-maximizing-positive-black-swans]]
    * [[book_md/the-black-swan/appendix|appendix]]
    * [[book_md/the-black-swan/exercise-reflecting-on-the-black-swan|exercise-reflecting-on-the-black-swan]]
  * [[book_md/the-black-swan/highlights|highlights]]
  * [[book_md/the-black-swan/community|community]]



Adding to Favorites 

Removing from Favorites 

## Appendix: The Contours of Extremistan

Although one needs only an intuitive sense of phenomena like wealth and market returns to understand that they don’t adhere to the same rules as phenomena like height and weight, throughout the book Taleb provides a robust theoretical and statistical scaffolding for his claims about the differences between Mediocristan and Extremistan.

Because these discussions tend toward the technical and aren’t essential for understanding Black Swans and their role in our lives, we at Shortform have decided to summarize them as an appendix.

#### Unfairness in Extremistan

As exemplified by figures like Beyoncé and Jeff Bezos, social and economic advantages accrue highly unequally in Extremistan.

One reason for this disparity is the “superstar effect.” Coined by economist Sherwin Rosen to describe the unequal distributions of income and prestige in Extremistan sectors like stand-up comedy, classical music, and research scholarship, the “superstar effect” operates when marginal differences in talent yield massive rewards.

The superstar effect, it’s vital to note, is meritocratic—that is, those with the most talent, even if they’re only slightly more talented than their competitors, get the spoils. **What a theory like Rosen’s fails to take into account, however, is that all-important aspect of life in Extremistan:_dumb luck_**.

Consider research scholarship for instance. Sociologist Robert K. Merton has observed that academics rarely read all the papers they cite; rather, they look at the bibliography of a paper they _have_ read and pick sources to cite more or less at random.

Now imagine a scholar cites three authors at random. Then a second scholar cites those same three authors, because the first author cited them. Then a third does the same thing. Suddenly the three authors that have been cited are considered leaders in their field, all by dint of dumb luck.

The phenomenon identified by Merton’s study has been called both “cumulative advantage” and “preferential attachment.” These concepts describe**the innate human tendency to flock to past successes, regardless of whether those successes are the product of merit or chance.**

Although cumulative advantage/preferential attachment provides a better account of unfairness than the superstar effect—because it accounts for randomness in the distribution of advantage/preference—it still isn’t a perfect theory of Extremistan unfairness. This is because, according to cumulative advantage/preferential attachment, winners stay on top. Once an entity—a company, an academic, a professional sports coach—reaches a certain level of success, cumulative advantage/preferential attachments holds that that entity will _continue_ to be successful, because humans naturally favor past success. But this doesn’t reflect reality.

For example, according to cumulative advantage/preferential attachment, Apple will forever be the king of consumer electronics, and Google will forever own the Internet. But even a cursory knowledge of business history shows a belief like this to be misguided. Consider this: If you tracked the 500 largest U.S. companies from 1957 to 1997, you’d discover that only _74_ lasted the full 40 years. Some ceased to exist by virtue of mergers, but most simply failed. **In other words, even in Extremistan, giants can occasionally be toppled by dwarfs**.

Nevertheless, despite the possibility of creative destruction, Extremistan is defined by extreme _concentration_ —of prestige, income, capital, influence, size, or what have you. **These concentrations create the _appearance_ of stability—larger, more powerful entities are more resilient—but they actually create the potential for catastrophic black swans**.

The example par excellence of the risks of concentration is the banking industry. The explosive growth and interrelation of the major global financial institutions were the catalysts for the Great Recession of 2008.

(Shortform note: The popularity of _The Black Swan_ is due, in large part, to Taleb’s clairvoyance about the vulnerabilities of the financial industry. The book was published in April 2007, before the worst of the crisis, yet Taleb describes the contours of that crisis with eerie precision.)

The most far-reaching unfairness of Extremistan, however, more so than economic inequality, is inequality in intellectual influence. As illustrated by Merton’s citation example just above, intellectual influence can be a matter of dumb luck rather than ability or insightfulness. This problem becomes acute when we trust thought leaders—”experts”—with our lives and livelihoods (see Chapter 4: The Scandal of Prediction).

**The Limits of the Bell Curve**

The classic bell curve—which is also called the “Gaussian distribution” after German mathematician Carl Friedrich Gauss—is an accurate description of Mediocristan phenomena, but it is dangerously misleading when it comes to Extremistan.

Consider human height, an eminently Mediocristan phenomenon. With every increase or decrease in height relative to the average, the odds of a person being that tall or short decline. For example, the odds that a person (man or woman) is three inches taller than the average is 1 in 6.3; 7 inches taller, 1 in 44; 11 inches taller, 1 in 740; 14 inches taller, 1 in 32,000.

It’s important to note that the odds not only decline as the height number gets further and further away from the average, but they decline at an accelerating rate. For example, the odds of someone being 7’1” are 1 in 3.5 million, but the odds of someone being just four inches taller are 1 in 1 billion, and the odds of someone being four inches taller than _that_ are 1 in 780 billion!

Now consider an Extremistan phenomenon like wealth. In Europe, the probability that someone has a net worth higher than 1 million euros is 1 in 62.5; higher than 2 million euros, 1 in 250; higher than 4 million, 1 in 1,000; higher than 8 million, 1 in 4,000; and higher than 16 million, 1 in 16,000. **The odds decrease at a constant, rather than accelerating, rate** , **indicating that their distribution doesn’t conform to a bell curve.**

(Note: The European wealth statistics cited above aren’t precise, but they illustrate the central point: that wealth is scalable and does not look like a bell curve.)

The upshot is that**in Extremistan, as the name suggests, extreme events have much better odds of occurring than in Mediocristan. Simply put,_the bell curve does not apply_.**

> **The Mistakes of Adolphe Quételet**
> 
> Adolphe Quételet (1796–1874) was a French mathematician who developed the idea of the “average human” (_l’homme moyen_) through the use of “means”—golden averages that represented the ideal human form.
> 
> At first, his inquiries were limited to human beings’ physical characteristics—height, weight, newborn weight, chest size—but before long, he began to seek averages in the social realm by studying human habits and morals. Quételet developed bell curves to describe humans’ deviance—literally—from both physical and moral norms.
> 
> Although Quételet’s ideas were influential in his historical moment, there were skeptics. Augustin Cournot, a fellow mathematician and philosopher, pointed out that social averages would necessarily depend on exactly _whom_ and _what attribute_ was being studied. An obvious example is human diet: If you were trying to determine the amount of seafood an average human consumes, you might get vastly different measurements if you were surveying inland populations versus coastal ones, or populations whose cultural traditions included a seafood-heavy diet.

In our contemporary moment, the most egregious misuse of bell curves can be found among economists and financial-industry analysts. Most economists, including many Nobel Prize–winners, treat financial markets as though they hail from Mediocristan when, in fact, they’re from Extremistan.

A stunning example of economists’ misinterpretation of the market came in 1998, with the collapse of Long-Term Capital Management (LCTM), a hedge fund that included among its founding partners two Nobel Prize–winners, Myron Scholes and Robert C. Merton (Robert K. Merton’s son). Scholes and Merton won their Nobel Prize for a theory of stock option pricing; the theory, however, was based on a Gaussian model of the market that excluded the possibility of Black Swans.

When markets were disrupted by the Asian financial crisis of 1997 and the Russian financial crisis of 1998—a one-two punch of Black Swans—Scholes and Merton’s theory was revealed for the fantasy it was. The twin crises resulted in a crushing $4.6 billion loss for LCTM in fewer than four months. The firm had to be bailed out by a consortium of private banks, at the behest of the Federal Reserve.

The problem is that economists’ models are thoroughly Platonified: self-consistent, but bearing almost no resemblance to reality. **Economists are like philosopher John Locke’s madmen: they reason “correctly from erroneous premises.”**

#### Representing Randomness: Fractals and Power Laws

So can the phenomena of Extremistan be modeled—and thereby predicted—at all? Not precisely; but they _can_ be approximated—by the use of _fractals_.

Developed by mathematician Benoît Mandelbrot in the 1970s, “fractals” are Mandelbrot’s coinage for geometric patterns that repeat at different scales. Fractals, unlike pure geometric shapes like triangles or circles, are seen quite frequently in nature. For example, a leaf’s veins look like little branches, and a tree’s branches look like little trees: the basic shape of the tree is echoed at the smaller scales.

The reason fractals are helpful in representing Black Swans is that their internal ratios stay constant across scales. Unlike bell curves, in which ratios decline at accelerating rates the further one gets from the average, fractals exhibit no (or mild) acceleration. They obey _power laws_ , which describe a functional relationship between two quantities in which the relationship remains constant no matter what the initial size of the quantities.

Take the European wealth example noted just above. As the wealth number doubled, the incidence decreased by 4x (wealth greater than 1 million: 1 in 62.5; wealth greater than 2 million: 1 in 250; wealth greater than 4 million: 1 in 1,000; etc.). The “power” in this relationship is 2, because 2^2 (2 squared) is 4.

Now, imagine the power was 1: Each time the wealth doubled, the incidence would only decrease by 2x (2^1=2). **The probability of extraordinary wealth would increase**.

For Extremistan phenomena, the power laws aren’t known with any certainty, but they can be approximated. Say, for example, you want to assess the risk of a stock portfolio, and you know that, based on past data, the worst-case scenario is a -5% move once every 2 years. With a power of 2—remember that the power is estimated—you can assume that a -10% move will happen once every 8 years (2^2=4) and a -20 percent move will happen once every 32 years. (For scale, in the 1987 crash, the U.S. stock market lost almost 23% of its value, an _impossibility_ according to Gaussian economic models.) **With fractal/power-law distributions, a 1000-year flood can become a 100-year one, and a 100-year one can become a 10-year one**.

When we begin to analyze Extremistan in terms of the fractal paradigm, some Black Swans suddenly become “gray”—they’re not predictable with any sort of precision, but they are, at least, _imaginable_.

[[book_md/the-black-swan/exercise-maximizing-positive-black-swans|exercise-maximizing-positive-black-swans]]

[[book_md/the-black-swan/exercise-reflecting-on-the-black-swan|exercise-reflecting-on-the-black-swan]]

![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=55e2e458-accc-453d-bcec-5dd5c8955b07&sid=1711133063fa11eebdec89a8b8ae3bbc&vid=171147a063fa11eea7440fcfeb230d96&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Book&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fthe-black-swan%2Fappendix&r=&lt=287&evt=pageLoad&sv=1&rn=78372)

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__



