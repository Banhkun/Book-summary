![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# The Elephant in the Brain

Back to Discover

[[book_md/the-elephant-in-the-brain/preview|preview]]

  * [[book_md/the-elephant-in-the-brain|the-elephant-in-the-brain]]
  * Full Book Guide

    * [[book_md/the-elephant-in-the-brain/exercise-spot-your-own-elephants|exercise-spot-your-own-elephants]]
  * [[book_md/the-elephant-in-the-brain/highlights|highlights]]
  * [[book_md/the-elephant-in-the-brain/community|community]]



![](/img/tutorial-fonts.175b2111.svg)

##### Change text options

Here you can change the font, text size, and reading screen to just how you like it. 

Next

  *   *   *   *   * 


![](/img/tutorial-menu.4c76dd27.svg)

##### Table of contents

Here you’ll find everything else, including the full chapter-by-chapter guide, your highlights, PDF downloads, and book discussions. 

Next

  *   *   *   *   * 


![](/img/tutorial-player.d25b1afb.svg)

##### Audio

Every guide has an audio narration so you can listen on the go. 

Next

  *   *   *   *   * 


![](/img/tutorial-favorite.b948300a.svg)

##### Add to Favorite

Mark your favorite guides here. You can find your favorites on your homepage. 

Next

  *   *   *   *   * 


![](/img/tutorial-night.ddd7fb5c.svg)

##### Night Mode

Like a darker look when you read? Turn dark mode on here. 

Finish

  *   *   *   *   * 


Adding to Favorites 

Removing from Favorites 

## 1-Page Summary

In _The Elephant in the Brain_ , Kevin Simler and Robin Hanson argue that **human behavior is driven by selfish motives hidden behind altruistic pretexts**. They argue that because we’re a cooperative social species, our brains evolved to hide our true motives not just from others, but from ourselves so as to balance our selfishness with our need to get along. They call these selfish motives the “elephant in the brain” because, like the metaphorical “elephant in the room,” they’re a large, unavoidable problem that nobody wants to acknowledge. And the elephant doesn’t just affect us as individuals—it shows up in institutions like education, health care, and religion.

Therefore, Simler and Hanson say that if we learn to recognize the elephant, we can improve ourselves by being less selfish or by turning our self-interest toward better ends. Moreover, without understanding the real motives driving our social systems, we stand little chance of reforming these systems to better achieve their intended goals.

Published in 2018, _The Elephant in the Brain_ emerged when Simler (a software engineer and blogger) approached Hanson (an economics professor) about forming an informal student-advisor relationship. The authors describe the resulting book as a doctoral thesis written for a general audience instead of a dissertation committee. Together, they draw on research from evolutionary biology, sociology, and psychology to advance their arguments. They acknowledge that their core idea—humans are selfish but pretend not to be—isn’t original, but argue that their application of this idea to large scale social systems is. (Shortform note: In addition to his work in economics, Hanson is also known for his controversial social views.)

This guide is in three parts. First, we talk about _why_ we have hidden motives in the first place. Then we explore several areas in which these motives manifest—our communications; our use of money and other resources; and our social institutions such as health care, education, and religion. Finally, we discuss a few ways we can use our knowledge of hidden motives to improve our lives.

Throughout this guide, we’ll explore some alternative explanations for some of the phenomena the authors discuss. We’ll also offer some periodic suggestions for how to apply the book’s insights to your own life, which we’ve labeled as “taming the elephant.”

### Part 1: Where Hidden Motives Come From

At first glance, the idea of hidden motives may seem convoluted—why hide our true intentions not just from others, but from ourselves? The answer, according to Simler and Hanson, is that as a cooperative social species, **we evolved to advance our own interests while appearing as selfless as possible** —and it’s easier to deceive others if we’ve already deceived ourselves. In this section, we’ll explore how human life is organized around a set of _social games_ and how our hidden motives help us get ahead in these games.

#### We Excel at Social Games

Simler and Hanson believe hidden motives are an evolutionary adaptation. They argue that **the human brain evolved to excel simultaneously at selfishness and cooperation**. The authors observe that humans are a fundamentally social species—we depend on cooperation to survive.

They point out that humans began as foragers—small nomadic bands who depended on each other’s help to find and share food, care for the sick and injured, and defend the band from predators and rival humans. They argue that this kind of cooperation requires an egalitarian culture—if any one individual or clique tries to dominate the group, they’ll ruin life for everyone. At the same time, individuals in these groups compete with each other for resources, mates, and social influence.

> **The Evolutionary Basis of Altruism**
> 
> Biologists, anthropologists, and historians have long debated the origins of altruism. From an evolutionary standpoint, why should we help others when those others might be our rivals for resources, territory, and mates? There are no clear answers, but plenty of theories.
> 
> For example, biologist Richard Dawkins believes that cooperation and altruism are selfish—but for different reasons than the ones Simler and Hanson describe. In _The Selfish Gene_ , Hawkins argues that genes are the driving force of life and that cooperation at the organism and species level is merely one strategy by which genes maximize their chances of replicating themselves. In other words, in family groups and close-knit societies (like small foraging groups), genes “know” that copies of themselves exist in an organism’s relatives and offspring. If an individual dies saving the rest of his family, that individual’s genes survive and have more chances to reproduce themselves.
> 
> On the other side of the spectrum, in _Humankind_ , historian Rutger Bregman argues that humans are inherently compassionate and cooperative. He also points to the egalitarianism of foraging societies, but unlike Simler and Hanson, he concludes that human nature is fundamentally altruistic and that competitive impulses are a secondary invention. Specifically, he argues that violence, jealousy, and inequality only appeared with the advent of farming, private property, and other trappings of civilization.
> 
> Meanwhile, zoological research increasingly points to the fact that altruism isn’t uniquely human. According to a popular legend, anthropologist Margaret Mead cited a healed femur as the start of civilization. The story might not be true—but it points to a shared belief that our capacity to act selflessly by helping an injured group member is what sets us apart from other animals. Yet chimpanzees have been observed treating each other’s wounds while other animals have been seen medicating themselves with plants (and learning to do so by watching others).

Because of the tension between selfishness and altruism, Simler and Hanson argue that **the human brain evolved to play _social games_ —competitions that require balancing self-interest with cooperation**. Social games typically revolve around three main goals:

  * **Sex** —because we have an instinctual drive to reproduce, many of our behaviors are designed to attract mates.
  * **Social status** —the higher your regard within a group, the better you’re treated. You can raise your social status through _dominance_ (forcing your will on others) or _prestige_(winning respect from others).
  * **Politics** —humans form coalitions, which favor political acumen over physical dominance. Simler and Hanson explain that even the strongest individual can easily be defeated by a group of opponents if that individual lacks allies. 



Simler and Hanson argue that **social games require two main skills: the ability to attract good partners (mates, friends, allies) and to judge potential partners**. In practice, that means that everyone is constantly judging everyone else—we’re watching to see who’ll make a good partner, and because we know we’re _being watched_ , we want to advertise that _we’ll_ make good partners.

(Shortform note: Perhaps this is why we have such a strong capacity for intuitive snap judgments. As Malcolm Gladwell argues in _Blink_ , we often judge people and situations immediately without knowing how we reached the conclusion we did. In particular, Gladwell suggests that we excel at reading almost imperceptible expressions on other peoples’ faces—a useful skill if human life really does amount to constant social games.)

#### We _Cheat_ at Social Games

Simler and Hanson emphasize that social games are competitive and not everyone can win. To maximize our chances, they say, we’ve evolved the skills needed not just to play these games, but also to cheat at them. To see how, we need to understand how _norms_ regulate our social games and how we can get the upper hand by evading these norms.

(Shortform note: It’s unclear to what extent this propensity to cheat is conscious. As we’ll see, Simler and Hanson argue that our brains deliberately hide our true motives from us, suggesting that any cheating is, by design, unconscious. Yet the prevalence of social and religious proscriptions against covetousness, jealousy, theft, and so on suggests otherwise. If we have to be told not to covet someone else’s spouse or possessions (that is, their social game “prizes”), that suggests that we’re _consciously aware_ of doing so and can control our thoughts and behaviors with regards to this tendency.)

##### Social Games Are Governed by Norms

Human cultures regulate selfish behavior and competition with **_norms_ —which __ are the rules and standards of a society.** Sometimes they’re codified as laws and enforced centrally, but most often, **norms are collectively enforced by the group as a whole**. For example, if you make too much noise in a library, you probably won’t get escorted out by security. Instead, you’ll likely earn some dirty looks or shushing from your fellow patrons as they collectively enforce the norm against library noisiness.

Simler and Hanson explain that this group enforcement prevents any one individual from dominating the group. They point out that egalitarian early humans needed order without authority—norms evolved to meet this need by distributing the task of enforcement among the group. The authors point out that even in authoritarian societies which _do_ revolve around a central leader, norms are still often enforced by society as a whole via a “cult of personality.” In these environments, speaking out against the leader won’t just result in punishment from above—it’ll also earn you censure from your peers (we’ll explore this more in a moment).

In short, norms teach us to regulate _each other_ and to punish unwanted behavior with consequences ranging from eye rolls to gossiping to open violence. Perhaps more to the point, **norms teach us to regulate _ourselves_**. If we’re always concerned with what others will think, we have reason to follow norms (at least publicly) to make good impressions and avoid punishment. Moreover, we’re aware that failing to follow norms means forfeiting the social games that norms govern—and missing out on the rewards of those games. In other words, ignoring norms makes you a less attractive partner to others, which means you have less of a chance of finding mates, friends, and allies.

> **When Norms Create (Rather Than Resist) Autocracy**
> 
> Simler and Hanson argue that norms evolved as a way for humans to govern themselves while avoiding the need for a central authority. But in the contemporary world, norms seem more and more to be at the heart of authoritarian control.
> 
> For instance, though Simler and Hanson imply that the cult of personality is a product of dictatorial rule—their examples are Mao Zedong’s communist China and Steve Job’s tenure at Apple—this dynamic has in recent years emerged even in democratic systems. For example, historian Ruth Ben-Ghiat argues that leaders like former Italian Prime Minister Silvio Berlusconi and former US President Donald Trump base their power on cults of personality. We can see this dynamic at work, for example, in the way Republican politician Liz Cheney was ejected from her own state party and removed from her Congressional leadership position for speaking out against Trump following the January 6 attack on the US Capitol.
> 
> The January 6 attack itself also shows how easy it is to exploit social norms. Ben-Ghiat explains that a typical authoritarian strategy is to describe one’s opponents as autocrats and oneself as a champion of liberty and fairness. In other words, by convincing his supporters that Joe Biden stole the 2020 election, Trump tapped into their inherent norms against oppressive authority, which in turn convinced them they were enforcing justice by trying to overturn the election and reinstall Trump.
> 
> According to Steven Levitsky and Daniel Ziblatt, part of the problem is that democracy itself is based not on laws or constitutions, but on social norms. In _How Democracies Die_ , Levitsky and Ziblatt argue that American democracy is based on two norms: 1) accepting the legitimacy of the democratic system (even when one’s opponent wins) and 2) not using political institutions to marginalize one’s opponents. The authors say that Trump’s administration systematically dismantled both of these norms, thereby paving the way for an authoritarian cult of personality.
> 
> **Taming the elephant:** We might not be able to control politicians when they decide to violate political norms, but we can be aware they’re doing so and respond accordingly. If we acknowledge our selfish tendencies and if we recognize how norms can be weaponized to support the very behaviors they’re meant to curb, we’ll have a better chance of noticing when someone is trying to exploit norms in order to abuse their power or manipulate us.

##### Deception Lets Us Skirt Norms

Because norms evolved as a way to enforce pro-social behaviors like cooperation, sharing, and non-violence, our selfish motivations are at odds with the norms that govern us. But rather than making humans less inherently selfish, Simler and Hanson say that norms led humans to evolve ways to advance our selfish motivations while _appearing_ to adhere to social standards. In other words, **we’ve developed a whole range of strategies for avoiding norm enforcement so that we can get away with “cheating” at our social games**. These strategies include:

  * **Pretexts** —we give socially acceptable reasons for doing something that we’re actually doing for selfish reasons. For example, “concern trolling” is the practice of deliberately undermining another person or derailing a discussion under the guise of genuine interest and compassion (such as by criticizing someone’s weight while saying you’re only concerned about their health). 
  * **Discretion** —we use code words, subtext, innuendo, body language, and so on to avoid openly stating our intentions. For example, some American conservatives adopted the phrase “Let’s Go Brandon” as a code for “F**k Joe Biden,” allowing them to say something that’s not always acceptable to say in public _and_ to signal in-group membership (because not everyone knows the reference). 
  * **Toeing the line** —instead of violating norms outright, we test their boundaries in subtle and plausibly deniable ways. For example, the history of motor racing is full of examples of teams creatively interpreting regulations to gain advantages—such as when some Formula 1 teams installed “water-cooled brake systems” to get around minimum weight rules by jettisoning weight during the race then replacing it before post-race weigh-ins.



Each of these strategies relies on deceiving other people—the idea is that we can act selfishly and competitively while convincing everyone that our motives are pure and we’re obeying social norms. But according to Simler and Hanson, **we often don’t realize we’re using these strategies** —because deception is easier to pull off when we believe our own lies, we evolved to deceive others and ourselves simultaneously.

(Shortform note: Again, it’s unclear just how unconscious many of these behaviors are. Authors from Niccolo Macchiavelli to Robert Greene have given advice for manipulating others to achieve your own ends using means that are often quite similar to the ones Simler and Hanson describe. For example, in _The 48 Laws of Power_ , Greene describes tactics such as pretending to be a friend in order to spy on others (in other words, using a pretext) and saying little in order to remain ambiguous (in other words, exercising discretion). **Taming the elephant:** If we’re aware of these strategies, we can choose to behave more honestly (by following norms or by _openly_ breaking them)—or to improve our deceptions (for example, by implementing Greene’s laws of power).)

Simler and Hanson say that in order to help us deceive ourselves as well as others, the human brain is made up of a number of self-contained modules, meaning that we can actually hide information (including our true motives) from ourselves. They argue that the brain has a “press secretary” module that’s in charge of explaining our actions to the outside world—and to ourselves.

Like its real-life counterpart, our internal press secretary’s job is to put the best possible spin on whatever we do. Likewise, our internal press secretary tends not to lie outright, but rather to tell _selective_ truths while ignoring less attractive aspects of our behavior. For example, a politician might say he got into politics to serve the public good, which might be true. But what he’d never admit to others—and possibly to himself—is that power and prestige also attracted him to public office. Simler and Hanson argue that this internal spin doctoring is so ingrained that we constantly fool ourselves. They point to studies showing that if we’re tricked into an action or decision we didn’t mean to take—and if we don’t notice the deception—we’ll explain and defend “our” choice without noticing anything wrong.

> **The Importance of Internalized Norms**
> 
> Self deception might be, as Simler and Hanson suggest, a strategic advantage when it comes to skirting norms. But there are also reasons to think that self deception serves a more fundamental purpose in allowing us to skirt norms in the first place.
> 
> According to philosopher Michel Foucault, when rules are enforced through constant observation, we internalize those rules and govern ourselves accordingly. In _Discipline and Punish_ , Foucault argues that modern social systems function like a panopticon—a theoretical prison designed so that prisoners know they _might be_ being watched at any given moment, but can’t verify whether they are or not. In such a prison, Foucault says, inmates adhere to the code of conduct not because they’re overtly forced to but because their perpetual one-sided visibleness conditions them to do so.
> 
> Recall that, like Foucault’s metaphorical panopticon, our social games make it so that we’re always watching and being watched by others. It seems likely then that a similar internalization happens with norms. If you’re too loud in a library and your fellow patrons angrily shush you, you’ll probably feel shame—and this shame might well be enough for you to regulate your own library volume in the future.
> 
> Likewise, you probably wouldn’t be openly rude to a colleague you dislike, not just because you fear retribution from the colleague or from your superiors, but also because for many of us it just _feels wrong_ to insult people to their faces in a business setting. Even if our reason for “being a good colleague” is selfish—for example, we don’t want to hurt our chances of advancement—the point is that we enforce the “good colleague” norm all on our own.
> 
> And if that’s the case—if we internalize norms to the point that we proactively police our own behavior—then we might in fact _need_ to deceive ourselves not just to help us deceive others, but in order to violate norms in the first place. In other words, when we give a disliked coworker a backhanded compliment instead of an open insult, we’re not just looking for plausible deniability if our coworker gets upset—we’re looking for a way to get our true feelings past the conflict aversion and sense of decorum that serve as gatekeepers to our own actions.

### Part 2: Hidden Motives in Daily Life

Hidden motives may have evolved when humans still lived in small foraging societies, but according to Simler and Hanson, this phenomenon is now hard-wired into our brains. As a result, they say that **hidden motives affect most aspects of our daily lives, from our interactions to our behaviors to our social institutions**. In this section, we’ll explore how our communication is rife with hidden messages, how we use spending (and giving) to signal status, and how our social institutions are built around wholly different goals than the ones we admit to.

#### The Unspoken Messages in Our Communication

Considering hidden motives are a byproduct of humanity’s social nature, it’s no surprise that they show up in our most fundamental forms of communication. As we’ll see, both our speech and our body language are full of messages other than the ones we’re directly aware of.

##### Conversation

Simler and Hanson argue that **while we might think the purpose of conversation is to share information, its actual purpose is for the speaker to advertise him/herself as a good potential ally**. They say that good conversationalists exhibit two key qualities:

  * They’re **knowledgeable** —they have a wealth of new information that can help us accomplish our goals or better understand the world. Simler and Hanson argue that when we share information, it’s not just the _information_ that’s important—we’re also sending the message that we’re _the kind of person_ who has such information and is therefore a valuable ally.
  * They’re **relevant** —we expect speakers to stay on topic rather than blurting out random facts. Simler and Hanson say that’s because we’re not just interested in _how much_ knowledge someone has—we’re interested in allying with someone who can pull out the right knowledge _at the right time_.



(Shortform note: The ability to stay on topic also shows that the speaker is intelligent (can think clearly and craft an understandable message) and considerate (values our time enough not to follow every random tangent). Moreover, relevancy can signal that a speaker is interested in us, especially when they’re willing to keep the focus on a topic we care about. In fact, in _How to Talk to Anyone_ , communications expert Leil Lowndes argues that successful conversation makes the other person feel good—suggesting that conversation is more of an emotional transaction than an informational transaction (as Simler and Hanson suggest). **Taming the elephant:** Either way, if you want to be a better conversationalist, it pays to think about what you can offer your audience.)

Because conversation is really about signaling your social utility, Simler and Hanson say that **another purpose of conversation is to build prestige**. Speakers want to look smart, informed, and connected. Returning to the discussion of social games above, prestige is one of two ways to raise your social status (which also helps you win the games of sex and politics). The more your conversation sends the message “I’m a valuable mate/partner/friend,” the higher you can drive your social status.

Simler and Hanson point out that **listeners want to associate with prestigious speakers because that association raises the listener’s prestige as well**. They say that’s why it can be hard for people with very different social statuses to talk to each other: Someone with high social status won’t want to diminish that status or give it away cheaply by associating with someone with too little prestige.

> **The Dangers of Prestige**
> 
> The power of prestigious associations can lead to outrageous outcomes when someone is willing to exploit prestige. For example, in _Bad Blood_ , reporter John Carreyrou explains how Elizabeth Holmes built her company Theranos into a $10 billion scam based on imaginary blood testing innovations. Carreyrou says that part of Holmes’s strategy was to make ever more prestigious associations through her investors and supporters—starting with one of her college professors and ending with two former US Secretaries of State, one former Secretary of Defense, and media mogul Rupert Murdoch. With so many prestigious names on board, Theranos’s credibility seemed to speak for itself.
> 
> **Taming the elephant:** Don’t be afraid to admit when you’re wrong or to question authority. It’s better to lose a little prestige than to buy into a billion-dollar fraud.

##### Body Language

Whereas conversation is about sharing information in order to raise our social status and broadcast our utility as allies, Simler and Hanson say that **body language allows us to communicate about things that we’d never talk about openly**. That’s because body language is:

  * **Unconscious** —the authors argue that body language is mostly involuntary, which means that it communicates our true intentions (including intentions we wouldn’t put into words). Body language is also unconscious in that we typically interpret other peoples’ body language without being aware we’re doing so. The authors say that’s why we sometimes get a certain “vibe” from someone without knowing why. 
  * **Subtle** —it’s easy to overhear (and repeat) spoken words, but it’s much harder for a third party to notice many types of body language. The authors say that makes body language an ideal medium when we want to be discreet, like when communicating sexual interest.
  * **Deniable** —thanks to the previous two traits, it’s much easier to deny our true intentions (to ourselves and others) if something goes wrong. 



> **How Unconscious _Is_ Body Language?**
> 
> Simler and Hanson contend that because it’s unconscious, body language reveals our true intentions most of the time. But this argument doesn’t account for cases where someone is deliberately using his or her body language to make a specific impression. Simler and Hanson acknowledge this possibility, but they argue that consciously cultivated body language plays little role in most of our interactions. Yet the vast amount of literature on body language and nonverbal communication suggests otherwise. For just a few examples:
> 
>   * In _How to Talk to Anyone_ , Leil Lowndes gives tips for seeming approachable and likable. For example, she recommends pausing before smiling when meeting someone new.
> 
>   * In _The Way of the Wolf_ , Jordan Belfort gives extensive advice for using body language to close sales. For example, he suggests copying a potential customer’s gestures and mannerisms to create a subconscious rapport.
> 
>   * In _Surrounded by Idiots_ , Thomas Erikson argues that you can discern someone’s personality type from just their nonverbal communication style. For example, he says people who have little sense of personal space and stumble over their words tend to be “yellow” personalities—entertaining, idealistic extroverts.
> 
> 

> 
> Similar tips can be found in countless guides to dating, public speaking, job interviewing, getting ahead at work, making friends, closing business deals, and so on. And even if you don’t formally study and practice body language, most of us are taught (by parents, teachers, and others) some of the same practices that the above experts recommend: stand up tall, make eye contact, smile, use a firm handshake, and so on. Given all that, it’s perhaps not so easy to conclude that body language reveals the unfiltered truth of our intentions as Simler and Hanson suggest.
> 
> **Taming the elephant:** It’s worth studying body language so that you can project the image you want, avoid revealing truths you’d rather keep hidden, and be aware of when other people try to manipulate or control you.

Simler and Hanson say that body language’s subtlety and deniability allow us to use it to communicate about things that norms would ordinarily tell us to avoid, such as:

**Sex** : The authors point out that we would rarely meet a stranger in a club and openly ask about having sex. Instead, we unconsciously communicate our romantic intent by using eye contact, touch, tone of voice, and so on. These behaviors are subtle enough that many outsiders won’t notice them. And if the interaction goes badly (the other party isn’t interested—or his/her romantic partner suddenly shows up) it’s easier to deny our intent because we never actually stated it.

(Shortform note: This deniability might also ease the blow of rejection by allowing us to put less of ourselves out there than if we were to openly declare our interest. However, subtlety has its costs: One study suggests that we only correctly detect whether someone was flirting with us about 28% of the time.)

**Power** : Similarly, norms against dominance and self-aggrandizing mean that a boss probably won’t verbally declare his own importance to his employees. Instead, he unconsciously broadcasts his authority by using aggressive eye contact, interrupting others, adopting relaxed and open postures, and so on. Simler and Hanson point out that in these scenarios, subordinates unconsciously adapt their own behavior to signal their acceptance of a leader’s authority: They make less eye contact, speak less (and never interrupt the leader), and maintain more formal postures in the leader’s presence. The authors argue that because these signals are subtle and deniable, people can more easily overcome their aversion to authority since that authority is never explicitly stated or discussed.

(Shortform note: We need only look at recent politics to see that power signaling is often anything _but_ subtle. For example, Donald Trump is known for subjecting others to uncomfortably long and aggressive handshakes, while Russian president Putin and Turkish president Erdoğan have taken turns leaving each other waiting for hours before planned meetings. **Taming the elephant:** If you’re in a position of power and _don’t_ wish to be domineering, be careful how you use nonverbal dominance signals. If you’re on the receiving end of these dominance signals, recognizing them for what they are might help you better understand your office dynamics (and potentially change jobs). Or, as Robert Greene suggests in _The 48 Laws of Power_ , you can exploit your boss’s sense of superiority for your own gain.)

#### Spending As Signaling

Just as body language allows us to communicate about things we’d never put into words, Simler and Hansen argue that **many of our actions double as conspicuous _fitness displays_ —they say to a potential mate, ally, or enemy: “Look how strong, wealthy, powerful, and connected I am.”** This is especially noticeable when it comes to how we spend our money and other resources.

##### Conspicuous Consumption

For example, the authors point to the well-known phenomenon of conspicuous consumption, where **we buy expensive (and often superfluous or excessive) things to signal our wealth, status, and power to others**. For example, strictly speaking, nobody _needs_ a Tesla. But owning one suggests several things about you:

  * You have a lot of money.
  * You’re interested in new technologies (which implies that you’re well-informed and intelligent).
  * You care about sustainable energy and vehicle emissions (which implies that you’re selflessly concerned with your impact on other people and the planet).



Note that none of these messages are things we typically say outright. We don’t walk up to strangers and say: “I’m rich, smart, and selfless.” But a new Tesla promises to say all that for you. (Shortform note: _Non_ -consumption can also send conspicuous signals. For example, one study argues that vocally quitting or abstaining from social media can be a type of political performance—in other words, by avoiding Facebook and saying so, people can signal that they value more authentic communication or that they reject Facebook’s status as a commercial entity.)

Simler and Hanson argue that **this kind of signaling isn’t just about what _you_ believe; it relies on your assumptions about what _other people_ believe**. They explain that lifestyle advertising (where companies focus on brand identity rather than extolling the strengths of the product itself) is meant to create common knowledge about the signals that certain brands send. For example, a Tesla wouldn’t signal the above qualities if nobody knew that Tesla makes expensive electric cars.

(Shortform note: This effect also explains the phenomenon by which people will agree with a political candidate’s policies, but not vote for that candidate for fear that the candidate “isn’t electable” or “doesn't seem presidential enough.” This kind of vote has nothing to do with the voter’s opinion _of the candidate_ and everything to do with what the voter thinks _other voters will think_ about the candidate. **Taming the elephant:** Pay attention to times when you base your choices on what you think others think—this often doesn’t line up with what you actually want.)

##### Selfish Giving

Likewise, Simler and Hanson argue that **charity isn’t just about helping others—it’s also about showing off how compassionate and benevolent we are**.

For example, they point out that most people don’t pay attention to how efficiently charities use their donations. They argue that charities that have been shown to use donations the most effectively remain less popular than ones that have better name recognition—regardless of how objectively effective these better-known charities are. For example, they point out that the Against Malaria Foundation—which has been ranked as one of the most effective charities—is less popular than, say, the United Way. They suggest that one reason for this is that we know others will recognize the United Way and are therefore more likely to give us credit for donating there than they would with a more obscure—but possibly more effective—charity.

Simler and Hanson also argue that giving is affected by visibility and peer pressure. For example, they point out that people are more likely to give when solicited to do so by an attractive member of the sex they’re interested in—suggesting a desire to signal favorable qualities.

(Shortform note: **Taming the elephant:** If you want to make your giving more beneficial—even if that means it might be less visible—it’s worth investigating the effective altruism movement (which Simler and Hanson mention in the book). The idea of effective altruism is to use objective data to figure out which charities and causes do the most good per dollar spent. In general, effective causes are those that affect many lives, are currently neglected, and can be dramatically improved by money or other resources.)

#### Social Institutions: Deceiving Ourselves Together

Just as our charitable giving hides selfish motives behind a conscious intent to help others, the authors say that many of our social systems are driven by motives other than the ones we recognize. That means that **some of our most important institutions—including health care, education, and religion—are built around goals we’re not even aware of.**

##### Health Care Lets You Look Caring

In some cases, like health care, these selfish motives are extensions of the ones we’ve seen at the individual level. For instance, the authors argue that **medicine isn’t just about healing—it’s also about showing conspicuous care**. They give the example of a mother kissing her toddler’s scraped knee to “make it better.” This practice has no physical healing power, but it’s a social ritual that shows the mother cares and lets the child feel cared for.

Simler and Hanson argue that this ritual extends into our adult lives. For example, they point out that when someone gets sick or hurt, it’s common for friends, family, and community members to bring that person food. They argue that bringing food signals that you care—as with charity, it advertises your compassion and selflessness. Meanwhile, receiving food broadcasts your popularity and support (conversely, if nobody helps you when you’re in need, that doesn’t speak well to your status in the community).

Simler and Hanson further argue that **our professional health care systems function as a larger scale conspicuous care ritual which leads to medically inferior decisions**. They argue that this is why patients and doctors seem to prefer active interventions over watchful waiting (monitoring a patient’s status but not intervening unless symptoms worsen) or nonmedical preventative strategies like lifestyle changes. They suggest we want our doctors to be “doing something” so that we know they care about us (and likewise that doctors want to show their caring via active interventions).

Likewise, they argue that this is why, in end-of-life situations, patients and their families choose aggressive interventions (which come with great cost and limited efficacy) over palliative care. Palliative care focuses on managing a patient’s symptoms and maintaining or improving quality of life; it can be used in conjunction with curative treatments or, in the case of terminal disease, it can include measures like hospice care. By contrast, aggressive treatment means, for example, continuing chemotherapy and drug treatments (which typically have strong side effects) and performing surgery even when there’s no hope of curing a disease.

Simler and Hanson argue that patients (or their family members) often opt for the aggressive option because it sends the message that you care about your life (or your loved one’s life). They say that choosing palliative care—even when it’s objectively the better option— _seems to_ send the message that you’re okay letting yourself or a loved one die.

> **An Alternative Explanation of Unnecessary Health Care**
> 
> Simler and Hanson’s account doesn’t include a number of psychological and practical explanations for some of the phenomena they discuss, none of which have anything to do with signaling. For example:
> 
>   * Patients’ decisions about their own health care could be influenced by factors as subtle as the order in which they receive information. For example, you’ll probably be less inclined to get a procedure if you hear about its risks before hearing about its benefits. Similarly, if a doctor presents options for active intervention before presenting an option like watchful waiting, that might bias you toward the active option.
> 
>   * End-of-life patients might opt for treatment rather than palliative care because they’re afraid of death—or don’t want to admit that they’re dying. Similarly, they might opt for treatment because their doctor is uncomfortable discussing end-of-life options, resulting in patients having unclear understandings of their situations.
> 
>   * Doctors might pursue treatments based on incorrect assumptions about their patients’ preferences. For instance, when treating breast cancer, a doctor might choose treatments designed to preserve the breast even though that might not be a priority for the patient.
> 
>   * Doctors sometimes override patients’ advance directives (written instructions about when and how a doctor should try to save a patient’s life) to provide life-saving care the patient didn’t want. The reasons for this aren’t clear, but experts suspect it’s in part because doctors are trained to take action, not to sit by.
> 
>   * Doctors often order unnecessary tests to cover their bases and manage risks. Doctors and patients alike are uncomfortable with uncertainty, and testing gives the (often false) impression of knowledge. Plus, doctors fear being sued for malpractice if a patient gets sick or dies from something that could have been caught by a test.
> 
> 

> 
> Overall, it seems there is indeed an elephant when it comes to health care—but rather than being about hidden motives, this elephant has to do with patient-doctor communications (and fear of lawsuits).
> 
> **Taming the elephant:** To minimize the chances of unnecessary tests or procedures, have open and honest conversations with your doctor—and be aware of how the illusion of control might bias you in favor of testing and active interventions.

##### Education Certifies Future Workers

Whereas medicine is about conspicuously broadcasting our pro-social motives, according to Simler and Hanson, other institutions are about shaping society in a desired direction. As noted earlier, humans are inherently resistant to control and hierarchies. In order to get around this resistance, we have institutions that _say_ they benefit the individual but actually serve some other purpose.

For example, the authors say that **education isn’t just about learning—it's also about molding students into good future employees and citizens**. They argue that standardized schooling is a method for systematically overcoming humans’ natural resistance to authority. In other words, one function of school is to civilize students by getting them accustomed to power hierarchies, schedules, and being evaluated and judged. Part of the goal is to turn students into citizens—that’s why schools instill civic identity by teaching and enforcing the history, customs, and norms of a given society. For example, in the US, students are required to recite the Pledge of Allegiance, an oath of fealty to the US flag and government that’s often taught before students even begin to understand government or politics.

But above all, the authors suggest that the underlying motivation of schooling is to make people into good modern employees by teaching them to accept authority and routines. The authors give examples of societies that installed industrial economies without an established educational system: The result was workers who refused to follow instructions, only worked when and how much they wanted to, and so on.

(Shortform note: Simler and Hanson mostly focus on schools’ _explicit_ structure—things like schedules, rules, and authority figures. But according to author Alfie Kohn, education’s role in instilling discipline lies even deeper—he argues that the curriculum itself is designed to control and pacify students. According to Kohn, research shows that learning is more effective when it emphasizes student autonomy and creative projects over fact memorization and top-down instruction. Yet, he says, many teachers and administrators favor traditional methods like lectures, worksheets, and so on because those methods are much more likely to produce students who do what they’re told.)

That’s why the authors argue that **a main function of schools is to _certify_ their graduates as good potential employees**. The authors point out that education doesn’t necessarily seem like good preparation for work: Many degrees aren’t directly applicable to the workplace—and besides, students quickly forget what they’ve learned. They also point out that in many universities, anyone can audit classes and receive the same instruction that paying students receive, with the only difference being the lack of a diploma at the end.

From this, the authors conclude that **employers care less about your education itself than they care about your degree—because of what the degree implies about you.** A good transcript or a degree from a good school demonstrates a number of character traits (persistence, organization, punctuality, responsibility, willingness to follow rules and instructions, general intelligence) that bode well for the modern workplace. A degree proves that you can succeed in a hierarchical, structured institution that demands you spend a lot of time on tedious tasks.

(Shortform note: In _Quiet_ , Susan Cain argues that schools are so focused on making students into good employees that they’ve reshaped the curriculum according to perceived business needs. Specifically, she argues that schools have come to favor cooperative and group learning because these methods align with corporate preferences for teams and committees. Similarly, the popularity of STEM education in recent years is driven by the desire to prepare students for future careers.)

##### Religion Cements Social Norms

Similarly, the authors argue that **religion isn’t just about belief, salvation, and higher purpose—it’s also about cementing and enforcing societal norms**. For instance, they point out that most religions have rules about who can get married and many have teachings that encourage procreation. In other words, they say, one function of religion is to establish and enforce a set of norms around mating.

Similarly, they argue that many religious practices revolve around sacrifice because it shows that we’re good potential allies if we’re willing to selflessly put the group first. They claim that deities typically stand in for society at large, and so **sacrificing to a god shows that we’re willing to sacrifice for society**. For this reason, they conclude that demonstrating religious belief indicates your willingness to pay your dues for the greater good of the social group.

(Shortform note: This explanation may conflate sacrifice in the sense of soldiers dying for their country with sacrifice as a religious practice. In the former case, many psychologists support Simler and Hanson’s interpretation that sacrifice might come from a hidden desire to feel helpful or gain social approval. But religious sacrifice is a different matter—it has more to do with psychological and spiritual desires to atone for wrongdoings, to re-establish communion with deities, and ultimately, to control an unpredictable world. In other words, religious sacrifice probably has less to do with how sacrificers want to be seen by the rest of society and more to do with how they want to be seen by their deities.)

Meanwhile, other religious practices serve to distinguish adherents from nonadherents and implicitly signal things about the practitioner’s values. For example, the authors say that shared worship makes beliefs and values common knowledge in the community. In other words, when you attend a sermon or any other kind of public religious function, you see fellow believers and they see you. As a result, the religion’s rules and values become public knowledge, meaning everyone is more likely to observe them because they know the community _knows they know_ the rules and expects them to follow them.

Meanwhile, visible components of religion—such as attire—serve to identify believers to each other and to outsiders. In both cases, the authors say religious attire serves as an implicit promise to uphold the religion’s moral standards. For fellow believers, the attire activates the common knowledge of shared norms, and for outsiders, it implies that the wearer knows he or she speaks for the whole religion and is therefore motivated to behave well.

(Shortform note: The question of whether religious attire serves a spiritual or signaling purpose is complex—in part because it depends heavily on context. For instance, different branches of Judaism have very different expectations about whether and when men (and sometimes women) should wear a kippah. Plus, not all religious attire fits the signaling model at all. For example, many Mormon practitioners wear special undergarments known as “temple garments” at all times. These undergarments are explicitly _not_ meant for public display, as they’re meant to be a symbol of the practitioner’s covenant with God.)

### Part 3: Final Thoughts on Taming the Elephant

If hidden motives really are as prevalent as Simler and Hanson say, we might be left with a bleak picture of humanity. The authors themselves acknowledge that we might not be happy to hear their insights—few of us want to admit when we’re driven by selfishness and other “bad” motives. Perhaps worse is the thought that our valued social institutions are based on selfish deception.

But there’s a silver lining to learning about the elephant: Once we recognize it, we can do something about it. That’s why throughout this guide, we’ve offered tips for applying Simler and Hanson’s insights to improve your own life. In that spirit, here are a few final—and more general—ideas about how taming the elephant lets us:

  * **Become less selfish and less self-deceived**. For example, a researcher who honestly acknowledges that her work is driven in part by a desire to advance her career and win acclaim will be more likely to resist the temptation to doctor her results in order to get published. That’s because she’ll be able to choose between her (no longer) hidden desire for self-advancement and her altruistic desire to further scientific knowledge.
    * (Shortform note: According to stoicism popularizer Ryan Holiday, unchecked selfish motives can actually get in the way of your career. In _Ego Is the Enemy_ , Holiday argues that aiming for recognition causes you to compromise your values—instead, he suggests focusing on accomplishing things that will make a difference to your profession or to the world at large.)
  * **Accept our selfishness and transform it** into**_enlightened self interest_** by deliberately helping others in order to advance ourselves. For example, businesses with strong charitable cultures might enjoy better sales and customer loyalty—but only if their charitable engagement is genuine and effective. When businesses are honest about their desire to make money, it’s easier to see how helping others can actually advance this selfish goal. 
    * (Shortform note: We tend to think of selfishness and selflessness as opposites, but according to Adam Grant, they are independent motivations, meaning that you can be selfish and selfless at the same time. In fact, in _Give and Take_ , Grant argues that balancing these two motivations is crucial to your happiness and mental health.)
  * **Design better institutions**. The authors point out that we can’t change our social systems until we understand the hidden motives that drive them. For example, if we want to reform the penal system, we first need to recognize how unspoken motives (like the desire to have criminals suffer) are at odds with our stated goals (to rehabilitate offenders or to remove them from society for everyone’s safety). 
    * (Shortform note: For example, being aware of our true motivations might help reduce what Daniel Kahneman, Olivier Sibony, and Cass R. Sunstein call _noise_ —unwanted variances in judgment that reduce the quality and consistency of our social systems. In _Noise_ , the authors argue that the variances result in part from differences in opinion and perspective from one judger to the next. For example, if a group of judges _say_ they believe in rehabilitation—but some of them have hidden vengeance or punishment motivations—then as a whole, their sentencing decisions will be noisy.)



[[book_md/the-elephant-in-the-brain/preview|preview]]

[[book_md/the-elephant-in-the-brain/exercise-spot-your-own-elephants|exercise-spot-your-own-elephants]]

##### Welcome!

Let’s go on a quick tour of a Shortform book guide. 

Start

##### 1-Page Summary

Every guide starts with a 1-Page Summary. This is a 5-10 minute overview of the book’s key points. 

Next

##### Finished!

If you ever need to see this tour again, click here. 

Close

Guided Tour

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__




![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=3ab865f5-5e9b-4712-bf4b-b7bfb32df6f2&sid=1711133063fa11eebdec89a8b8ae3bbc&vid=171147a063fa11eea7440fcfeb230d96&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20The%20Elephant%20in%20the%20Brain&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fthe-elephant-in-the-brain%2F1-page-summary&r=&lt=717&evt=pageLoad&sv=1&rn=978315)
