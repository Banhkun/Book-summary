![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# Superforecasting

Back to Discover

[[book_md/superforecasting/preview|preview]]

  * [[book_md/superforecasting|superforecasting]]
  * Full Book Guide

    * [[book_md/superforecasting/shortform-introduction|shortform-introduction]]
    * [[book_md/superforecasting/part-1|part-1]]
    * [[book_md/superforecasting/chapter-3|chapter-3]]
    * [[book_md/superforecasting/chapter-4|chapter-4]]
    * [[book_md/superforecasting/exercise-are-you-a-hedgehog-or-a-fox|exercise-are-you-a-hedgehog-or-a-fox]]
    * [[book_md/superforecasting/part-2|part-2]]
    * [[book_md/superforecasting/exercise-answer-the-ball-and-bat-problem|exercise-answer-the-ball-and-bat-problem]]
    * [[book_md/superforecasting/exercise-generate-new-perspectives|exercise-generate-new-perspectives]]
    * [[book_md/superforecasting/chapter-6|chapter-6]]
    * [[book_md/superforecasting/exercise-embrace-probabilistic-thinking|exercise-embrace-probabilistic-thinking]]
    * [[book_md/superforecasting/chapter-7|chapter-7]]
    * [[book_md/superforecasting/chapter-8|chapter-8]]
    * [[book_md/superforecasting/exercise-develop-a-growth-mindset|exercise-develop-a-growth-mindset]]
    * [[book_md/superforecasting/chapters-9-10|chapters-9-10]]
    * [[book_md/superforecasting/exercise-identify-psychological-safety|exercise-identify-psychological-safety]]
    * [[book_md/superforecasting/chapter-11|chapter-11]]
    * [[book_md/superforecasting/exercise-weigh-the-impact-of-black-swan-events|exercise-weigh-the-impact-of-black-swan-events]]
    * [[book_md/superforecasting/chapter-12|chapter-12]]
  * [[book_md/superforecasting/highlights|highlights]]
  * [[book_md/superforecasting/community|community]]



Adding to Favorites 

Removing from Favorites 

## Part 1: Forecasting Basics | Chapters 1-2: Can You Predict the Future?

In this chapter, we’ll learn about the importance of measuring forecast accuracy, the philosophy that makes forecasting possible, what it means to be a “superforecaster,” and how superforecasters perform compared to computer algorithms.

### Lack of Measurement Makes It Difficult to Judge Accuracy of Forecasts

Tetlock and Gardner argue that to make better forecasts, we have to be able to measure accuracy. Predictions about everything from global politics to the weather are not hard to come by. You find them on news channels, in bestselling books, and among friends and family. According to the authors, most of these predictions have one thing in common: After the event, no one thinks to formally measure how accurate they were. **This lack of measurement means that you have no sense of how accurate any particular source usually is.** Without that baseline, how do you know who to listen to the next time you need to make a decision?

The authors note that given how important accurate predictions are, it’s surprising that we have no standard way of measuring their accuracy. Instead, forecasters in popular media deliver their predictions with so much confidence that we take them at their word, and by the time the events they predict happen (or don’t), the news cycle has moved on. According to Tetlock and Gardner, **the loudest voice is often the most convincing one, regardless of how accurate they are.**

> **Popular Forecasters Should Be Held Accountable**
> 
> Nassim Nicholas Taleb takes this argument one step further in _Antifragile. _He argues that not only should pundits be measured on the accuracy of their predictions, they should be held personally liable for the consequences of their predictions. For example, in 2003, Thomas Friedman, popular columnist and author of _Thanks for Being Late_ , predicted that if U.S. military forces invaded Iraq, it would have “a positive, transforming effect on the entire Arab world.” Taleb argues that Friedman’s forecasts influenced the decision to invade Iraq, leading to an eight-year war and 288,000 total casualties; however, Friedman himself never faced any consequences for these results of his predictions. In Taleb’s view, Friedman should, at least, be banned from writing further op-eds, since his words have proven to have dangerous consequences.

### The Philosophy of Forecasting

To appreciate the value of forecasting, we have to frame it the right way. Tetlock learned this the hard way when the data from his pioneering research found that the **majority of expert forecasts were no more accurate than chance**(which the popular press misinterpreted to mean “forecasting is pointless”). Additionally, the predictions these experts made within their fields of expertise were _less_ accurate than predictions they made outside their fields. In other words, intelligent analysts who invested time and effort into researching the issues were no more able to predict future events than if they’d guessed randomly.

(Shortform note: Why are experts so inaccurate, even within their own fields? Economics researcher Bryan Caplan points out one possible explanation of this core finding: Tetlock purposefully asked the experts challenging questions about their fields. Caplan surmises that when faced with these questions, experts become overconfident in their predictions, hence why they’re incorrect more often. He argues that if Tetlock had asked questions to which there are already well-established answers within the experts’ field (which Tetlock deliberately didn’t do), the experts’ prediction accuracy would have been higher. Caplan concludes that while forecasters admittedly need to stop being so overconfident in response to challenging questions, people should equally stop claiming that experts are useless at prediction: They can be accurate in the right circumstances.)

#### Chaos Theory

Tetlock and Gardner argue that this nihilistic perspective has its roots in _chaos theory_. This theory, first proposed by a meteorologist, argues that **tiny changes in nonlinear systems can escalate into enormous effects.** This means that the effects of changes in these systems are hard, if not impossible, to predict.

The authors note that you may have heard this referred to as “the butterfly effect," a moniker that stems from the title of the original 1972 paper: “Predictability: Does the Flap of a Butterfly’s Wings in Brazil Set Off a Tornado in Texas?”**** Most of the time, atmospheric conditions would prevent a Brazilian butterfly from setting off a tornado in Texas—but if every other factor lined up just right, there is a tiny chance that it _could_ happen. **This possibility is so unlikely and requires such a specific arrangement of variables that it is almost entirely unpredictable, even with the knowledge of every law of the universe.**

> **History Is a Nonlinear System**
> 
> Chaos theory only affects nonlinear systems, which are systems in which the input does not reliably predict the output—essentially, any system that can be impacted by random, unpredictable events. For example, the equation _y=x_ is linear; 1 will always equal 1, 2 will always equal 2, and so on, regardless of any other factors. However,**** the weather is a nonlinear system because the slightest change in temperature could lead to a huge storm developing. The change in input is not proportional to the change in output.
> 
> History itself is a nonlinear system. For example, many people cite Adolf Hitler’s rejection from art school as the butterfly wing that ultimately caused the Holocaust (because if he’d been accepted, he may have been too focused on his art career to pursue politics). Being rejected from art school has a set of predictable results: The person might keep applying to other schools until they’re accepted, go out on their own as an artist without formal schooling, or give up art altogether. At the time, no one predicted that being rejected from art school would lead to someone becoming the most hated figure in history because the input (rejection from art school) was disproportionate to the output (becoming a dictator).
> 
> We can further classify history as a particular type of nonlinear system: what author Yuval Noah Harari calls a level two chaotic system. In _Sapiens_ , Harari describes level two systems as those in which prediction can change the outcome of events. For example, if the art school administrators who evaluated Hitler’s application had predicted that rejecting him would lead to a world war, they may have accepted his application instead, thereby potentially nullifying their own prediction. This is distinct from a level one system in which outcomes are not impacted by prediction. For example, the weather is a level one system—if you predict that tomorrow will be cloudy, that doesn’t influence the likelihood that tomorrow will actually be cloudy.

#### Superforecasters

The authors argue that contrary to the media’s representation of the Good Judgment Project, the Project’s results don’t mean that there is no value in forecasting. What Tetlock’s team discovered was that certain kinds of forecasters could make certain kinds of predictions with an accuracy much higher than chance. **These forecasters, whom Tetlock calls “superforecasters,” apply a specific methodology to come up with their predictions, and they only make predictions a year into the future or less.** Any further out, and accuracy rates drop dramatically. But when superforecasters apply their skills to short-term questions, they’re remarkably accurate. (Shortform note: We’ll be discussing superforecasters, their methods, and their traits extensively in Part 2.)

#### Humans vs Computer Algorithms

But, the authors question, why rely on humans for forecasting at all, instead of an advanced computer algorithm? **For situations where a well-validated statistical algorithm exists and has been proven reliable, computer predictions are almost always more accurate than those of human forecasters.** The problem is that very few such algorithms exist.

Tetlock and Gardner believe that as technology advances, we may develop more of these algorithms, or refine the ones that already exist. But even then, the judgment of human forecasters will not be obsolete. Artificial intelligence (AI) is mostly immune to human cognitive biases, but it can’t interpret the results of its own predictions and create new meaning. **Therefore, the authors argue, the future of forecasting will be a combination of skilled forecasters and powerful algorithms.**

> **Forecasting Algorithms and AI Won’t Be Immune to Bias**
> 
> Tetlock and Gardner argue that algorithms and AI are mostly immune to bias—however, that’s not always the case. For example, in _Biased, _social psychologist Jennifer Eberhardt describes how AI has become a major tool in criminal justice settings, where it is used to predict the risk of an arrested person committing another crime. Those risk assessments are then used to set bail and even influence sentencing. However, these measures aren’t objective—an independent analysis found that, regardless of criminal history, the system was 77% more likely to assign a “high risk for violent crime” label to Black people. Furthermore, the system was more likely to mistakenly assign a “low risk” label to white people who _did_ go on to commit additional crimes.
> 
> This kind of bias pops up in other artificial intelligence tools—particularly those that involve facial recognition technology. While facial recognition systems are often remarkably accurate at identifying white male faces, they’re significantly less accurate when identifying the faces of women or people of color. When it comes to forecasting, relying on AI alone likely won’t be enough to sidestep biases.

[[book_md/superforecasting/shortform-introduction|shortform-introduction]]

[[book_md/superforecasting/chapter-3|chapter-3]]

![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=2b8aed60-6d89-41c3-ad5f-846c790411d6&sid=f30c5e70639211ee87d33f0876d93783&vid=f30c9700639211eeb3a75d830392c94f&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Book&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fsuperforecasting%2Fpart-1&r=&lt=308&evt=pageLoad&sv=1&rn=218936)

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__



