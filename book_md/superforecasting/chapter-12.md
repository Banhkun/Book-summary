![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# Superforecasting

Back to Discover

[[book_md/superforecasting/preview|preview]]

  * [[book_md/superforecasting|superforecasting]]
  * Full Book Guide

    * [[book_md/superforecasting/shortform-introduction|shortform-introduction]]
    * [[book_md/superforecasting/part-1|part-1]]
    * [[book_md/superforecasting/chapter-3|chapter-3]]
    * [[book_md/superforecasting/chapter-4|chapter-4]]
    * [[book_md/superforecasting/exercise-are-you-a-hedgehog-or-a-fox|exercise-are-you-a-hedgehog-or-a-fox]]
    * [[book_md/superforecasting/part-2|part-2]]
    * [[book_md/superforecasting/exercise-answer-the-ball-and-bat-problem|exercise-answer-the-ball-and-bat-problem]]
    * [[book_md/superforecasting/exercise-generate-new-perspectives|exercise-generate-new-perspectives]]
    * [[book_md/superforecasting/chapter-6|chapter-6]]
    * [[book_md/superforecasting/exercise-embrace-probabilistic-thinking|exercise-embrace-probabilistic-thinking]]
    * [[book_md/superforecasting/chapter-7|chapter-7]]
    * [[book_md/superforecasting/chapter-8|chapter-8]]
    * [[book_md/superforecasting/exercise-develop-a-growth-mindset|exercise-develop-a-growth-mindset]]
    * [[book_md/superforecasting/chapters-9-10|chapters-9-10]]
    * [[book_md/superforecasting/exercise-identify-psychological-safety|exercise-identify-psychological-safety]]
    * [[book_md/superforecasting/chapter-11|chapter-11]]
    * [[book_md/superforecasting/exercise-weigh-the-impact-of-black-swan-events|exercise-weigh-the-impact-of-black-swan-events]]
    * [[book_md/superforecasting/chapter-12|chapter-12]]
  * [[book_md/superforecasting/highlights|highlights]]
  * [[book_md/superforecasting/community|community]]



Adding to Favorites 

Removing from Favorites 

## Chapter 12: The Future of Forecasting

It’s clear by now that forecasting is important, even if there is debate about the relative importance of predictable events. The authors believe that forecasting tournaments are particularly important because they provide opportunities for superforecasters to sharpen their skills and for researchers to test theories about what makes some forecasters more accurate than others.

But **forecasting is not always about accuracy.** In reality, forecasters (especially those in the public eye) may have other goals for their forecasts. If the goal is to provoke a person or group or to draw attention to a cause, being right is an afterthought. (Shortform note: We can see this in the case of doomsday predictions. Many of the people who predicted the end of the world on a particular date were religious leaders who were more concerned with attracting followers to their cause than with the accuracy of their predictions.)

### Big and Little Questions

According to the authors, the field of forecasting is facing another challenge in addition to concerns about accuracy: Namely, the idea that the questions people really care about and need to answer are typically too big for a forecaster to even attempt. For example, a solid superforecaster can predict the likelihood that China will begin closing any of its hundreds of coal plants (which experts say could help the country meet their environmental goals), but they can’t answer the real question people are asking: “Will we be able to prevent the most devastating effects of climate change?” Even the best superforecaster can’t answer that.

This is a valid criticism—luckily, Tetlock and Gardner argue that there is a way around it.**Like Fermi, we can break big questions like “Will things turn out okay?” into a host of smaller questions that superforecasters _can_ answer.** This is called **Bayesian question clustering**. The answers to these questions contribute a small piece of the overall answer. Cumulatively, the answers to those small questions can approximate an answer to the bigger question.

For example, if we ask enough questions about factors that could contribute to worsening climate change, we know that the more “yes” answers we get to the small questions (for example, whether sea levels will rise by more than one millimeter in the next year, or whether the United States government will invest more money in solar energy), the more likely the big question is also a “yes.”

(Shortform note: This technique may help to answer a common critique of forecasting: that it is an example of the “streetlight effect,” or the equivalent of looking for your lost keys under the streetlight—even if that’s not where you lost them—because that’s where the light is best. This is related to black swan thinking—whatever future events you _can_ predict (metaphorically shine a light on) won’t matter because the only truly important events are, by definition, unpredictable. To see the utility of Bayesian question clustering, we can change the metaphor a bit: If a forecaster searches for multiple puzzle pieces under the streetlight as opposed to a single set of keys, they may find enough pieces to at least see the gist of the whole puzzle—even if half the pieces are still lost in the dark.)

#### Asking Good Questions

To get an accurate picture of the big question, the authors argue that we need to ask relevant small questions that avoid bias and cover every perspective of the big question. The best questions are those we look back on after the event and curse ourselves for not thinking of them sooner.

By definition, these kinds of questions are difficult to think up in advance. They are often driven by a central big idea and so don’t come naturally to fox-minded superforecasters. This is where the hedgehogs we encountered in Chapter 3 excel. The vague, ideologically-driven predictions made by hedgehog-style pundits aren’t solid forecasts, but they _do_ raise excellent questions.

**In other words, superforecasters are excellent at finding answers to questions but not at choosing the right questions to answer in the first place.** For that, they need the complementary strengths of the hedgehogs. A symbiotic working relationship between foxes and hedgehogs would maximize the skills of both groups.

> **To Ask Good Questions, We Need Diverse Hedgehogs**
> 
> In _Superforecasting_ , Tetlock and Gardner describe the importance of hedgehog thinkers generating questions for foxes to solve. Elsewhere, Tetlock describes a related concern: the need for hedgehogs with diverse Big Ideas all contributing to the same conversation.
> 
> In 2014, Tetlock and a group of coauthors published a paper on the dangers of political homogeneity in the social sciences. The authors argue that the social sciences are less politically diverse than ever (with up to 66% of social science professors in the United States identifying as liberal and only 5-8% identifying as conservative). In their view, this lack of diversity presents a serious challenge to the validity of the field in part because it influences the questions that researchers think to ask in the first place (for example, liberal researchers typically don’t study the possibility of stereotype accuracy because rejecting racial and gender stereotypes is a liberal value).
> 
> By the same logic, it’s possible for those asking forecasting questions to fall into the same ideological traps. In order to generate the full range of useful forecasting questions, we need hedgehog thinkers from across the ideological spectrum, including liberals and conservatives as well as libertarians and moderates.

### Forecasting and Evidence-Based Policy

Forecasting can play an important role in almost any field, but Tetlock and Gardner believe its biggest potential lies in evidence-based policymaking. In the current political climate, policy debates often result in both sides of an issue becoming further entrenched in their positions, no matter how much evidence there is against it. Ultimately, debates like these go nowhere.

For more productive conversations, the authors recommend **adversarial collaboration** , in which people on both sides of an argument agree to focus on a shared goal and to make specific, testable forecasts about the best way to reach that goal. This also requires both parties to agree to follow the evidence, even if it means abandoning their original position. Adversarial collaboration requires an assumption of good faith on both sides. This is a lot to ask of people accustomed to fierce debate, especially because it usually results in a blended answer where neither side is completely “right” or “wrong.”

> **Tetlock and Taleb’s Failed Adversarial Collaboration**
> 
> Adversarial collaboration isn’t easy, even for experienced academics like Tetlock. In 2013, he and Nassim Taleb attempted a form of adversarial collaboration in which they co-wrote a paper on the difference between predicting events with a yes/no outcome versus predicting events with many possible outcomes. The resulting paper was never published in an academic journal (Tetlock says it was “stillborn”), and the experience of working together only worsened their professional relationship. In the following years, Taleb published his criticisms of Tetlock as a coauthor and a scientist and christened him “Phil the Rat.” He argues that the experience wasn’t actually “collaboration” of any kind because he wrote most of the paper himself. Tetlock, for his part, tweeted that he was “ashamed” to have worked with Taleb at all.
> 
> Why did Tetlock and Taleb’s attempt at adversarial collaboration fail? It’s hard to say for sure, but it’s possible the two authors overestimated how much their beliefs overlap. According to Daniel Kahneman, when two authors who agree on very little attempt adversarial collaboration, it’s best to write in two voices (and possibly even have an arbiter present) so that neither author feels pressured to accept the other’s interpretations of their joint research.

[[book_md/superforecasting/exercise-weigh-the-impact-of-black-swan-events|exercise-weigh-the-impact-of-black-swan-events]]

Done

Go to home page 

![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=4bc95156-ba2f-4ce9-a340-b7206771f365&sid=f30c5e70639211ee87d33f0876d93783&vid=f30c9700639211eeb3a75d830392c94f&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Book&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fsuperforecasting%2Fchapter-12&r=&lt=406&evt=pageLoad&sv=1&rn=102099)

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__



