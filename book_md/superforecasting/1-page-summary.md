![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# Superforecasting

Back to Discover

[[book_md/superforecasting/preview|preview]]

  * [[book_md/superforecasting|superforecasting]]
  * Full Book Guide

    * [[book_md/superforecasting/shortform-introduction|shortform-introduction]]
    * [[book_md/superforecasting/part-1|part-1]]
    * [[book_md/superforecasting/chapter-3|chapter-3]]
    * [[book_md/superforecasting/chapter-4|chapter-4]]
    * [[book_md/superforecasting/exercise-are-you-a-hedgehog-or-a-fox|exercise-are-you-a-hedgehog-or-a-fox]]
    * [[book_md/superforecasting/part-2|part-2]]
    * [[book_md/superforecasting/exercise-answer-the-ball-and-bat-problem|exercise-answer-the-ball-and-bat-problem]]
    * [[book_md/superforecasting/exercise-generate-new-perspectives|exercise-generate-new-perspectives]]
    * [[book_md/superforecasting/chapter-6|chapter-6]]
    * [[book_md/superforecasting/exercise-embrace-probabilistic-thinking|exercise-embrace-probabilistic-thinking]]
    * [[book_md/superforecasting/chapter-7|chapter-7]]
    * [[book_md/superforecasting/chapter-8|chapter-8]]
    * [[book_md/superforecasting/exercise-develop-a-growth-mindset|exercise-develop-a-growth-mindset]]
    * [[book_md/superforecasting/chapters-9-10|chapters-9-10]]
    * [[book_md/superforecasting/exercise-identify-psychological-safety|exercise-identify-psychological-safety]]
    * [[book_md/superforecasting/chapter-11|chapter-11]]
    * [[book_md/superforecasting/exercise-weigh-the-impact-of-black-swan-events|exercise-weigh-the-impact-of-black-swan-events]]
    * [[book_md/superforecasting/chapter-12|chapter-12]]
  * [[book_md/superforecasting/highlights|highlights]]
  * [[book_md/superforecasting/community|community]]



![](/img/tutorial-fonts.175b2111.svg)

##### Change text options

Here you can change the font, text size, and reading screen to just how you like it. 

Next

  *   *   *   *   * 


![](/img/tutorial-menu.4c76dd27.svg)

##### Table of contents

Here you’ll find everything else, including the full chapter-by-chapter guide, your highlights, PDF downloads, and book discussions. 

Next

  *   *   *   *   * 


![](/img/tutorial-player.d25b1afb.svg)

##### Audio

Every guide has an audio narration so you can listen on the go. 

Next

  *   *   *   *   * 


![](/img/tutorial-favorite.b948300a.svg)

##### Add to Favorite

Mark your favorite guides here. You can find your favorites on your homepage. 

Next

  *   *   *   *   * 


![](/img/tutorial-night.ddd7fb5c.svg)

##### Night Mode

Like a darker look when you read? Turn dark mode on here. 

Finish

  *   *   *   *   * 


Adding to Favorites 

Removing from Favorites 

## 1-Page Summary

_Superforecasting_ is the result of decades of research on **“superforecasters”: people who can predict future events with an accuracy better than chance.** Superforecasters are intelligent, but more importantly, they’re open-minded, deeply curious, and adept at sidestepping their own cognitive biases. Not everyone is cut out to be a superforecaster, but by studying the way superforecasters make predictions, anyone can improve their ability to predict the future.

_Superforecasting_ has two authors: Dan Gardner, a journalist and author of three books on the science of prediction; and Philip Tetlock, a psychologist and pioneering forecasting researcher. Tetlock is the co-founder of two major, research-focused forecasting tournaments: Expert Political Judgment and the Good Judgment Project.

### Part 1: Forecasting Basics

When the authors use the term “forecasting,” they’re referring to formal predictions expressed with numerical probabilities. To appreciate the value of forecasting, we have to frame it the right way. Tetlock learned this the hard way when the data from his pioneering research found that the **majority of expert forecasts were no more accurate than chance**(which the popular press misinterpreted to mean “forecasting is pointless''). Additionally, the predictions these experts made within their fields of expertise were _less_ accurate than predictions they made outside their fields. In other words, intelligent analysts who invested time and effort into researching the issues were no more able to predict future events than if they’d guessed randomly.

(Shortform note: Why are experts seemingly so inaccurate, even within their own fields? Economics researcher Bryan Caplan points out one possible explanation of this core finding: Tetlock purposefully asked the experts challenging questions about their fields. Caplan surmises that when faced with these questions, experts become overconfident in their predictions, hence why they’re incorrect more often. He argues that if Tetlock had asked questions to which there are already well-established answers within the experts’ field (which Tetlock deliberately didn’t do), the experts’ prediction accuracy would have been higher. Caplan concludes that while forecasters admittedly need to stop being so overconfident in response to challenging questions, people should equally stop claiming that experts are useless at prediction: They can be accurate in the right circumstances.)

#### Superforecasters

The authors argue that contrary to the media’s representation of Tetlock’s research, these results don’t mean that there is no value in forecasting. What Tetlock’s team discovered was that certain kinds of forecasters could make certain kinds of predictions with an accuracy much higher than chance. **These forecasters, whom Tetlock calls “superforecasters,” apply a specific methodology to come up with their predictions, and they only make predictions a year into the future or less.** Any further out, and accuracy rates drop dramatically. But when superforecasters apply their skills to short-term questions, they’re remarkably accurate. (Shortform note: We’ll be discussing superforecasters, their methods, and their traits extensively in Part 2.)

#### Measuring Forecasts

Forecasting accurately is incredibly difficult, but determining whether a forecast is accurate in the first place presents difficulties of its own.**** According to the authors, **a forecast judged by different standards than the forecaster intended will be deemed a failure, even if it’s not**.

For example, in 2007, Steve Ballmer, then-CEO of Microsoft, claimed that there was “no chance” that Apple’s iPhone would get “any significant market share." In hindsight, this prediction looks spectacularly wrong, but the wording is too vague to truly judge. What did he mean by “significant”? And was he referring to the US market or the global market?

According to the authors, these questions matter because the answers lead us to very different conclusions. Judged against the US smartphone market (where the iPhone commands 42% of the market share), Ballmer is laughably wrong. But in the global mobile phone market (not just smartphones), that number falls to 6%—far from significant. (Shortform note: In 2009, Ballmer admitted to seriously underestimating the iPhone, in effect contradicting the authors: Even Ballmer thinks that the prediction was bad after all.)

> **Judging the “Worst Tech Predictions” of All Time**
> 
> Hero Labs, a technology company, compiled a list of 22 of the “worst tech predictions of all time,” including Ballmer’s infamous quip. However, unlike Ballmer’s forecast, most of the other predictions on the list _are_ specific enough to judge. Here’s why:
> 
>   * **They use unequivocal language.** For example: In 1946, Darryl Zanuck of 20th Century Fox said, “Television will never hold onto an audience.” His use of the word “never” makes it easy to judge this forecast as completely false—in 2019, the television industry was worth $243 billion (and that’s _only_ traditional network television, not including television streaming services like Netflix or Hulu).
> 
>   * **They provide a time frame.** For example: In 1998, economist Paul Krugman said, “By 2005, it will be clear that the internet’s impact on the global economy has been no greater than the fax machine.” By the end of 2005, Amazon alone was already worth over $18 billion, and as of 2021, the combined market capitalization of the largest 100 internet companies was over $7 trillion. To contrast, experts predict the global fax machine market will be worth around $733 million by 2026.
> 
> 


#### The History of Superforecasting

Tetlock first discovered that some forecasters are more accurate than others thanks to a decades-long study called “Expert Political Judgment” (EPJ). He split the forecasters in that tournament into two groups based on their performance: one that did no better (and sometimes much worse) than chance, and another that did slightly better.

**Tetlock named the first group “Hedgehogs'' and the second group “Foxes,"** based on Isaiah Berlin’s classic philosophy essay entitled “The Hedgehog and the Fox'' (the title comes from a line from an ancient Greek poem: “The fox knows many things but the hedgehog knows one big thing”). (Shortform note: “Knowing many things'' is similar to the psychological concept of active open-mindedness. Actively open-minded thinkers are willing to consider other people’s ideas and opinions instead of clinging to their own point of view. Tetlock found that superforecasters tend to be more actively open-minded than most people.)

According to the authors, forecasters in the “hedgehog” group are passionately ideological thinkers who see the world through the lens of a Big Idea. They organize new information to fit their Big Idea, and they ignore any information that doesn’t fit that paradigm. The “Big Ideas” themselves vary widely from liberal to conservative and everything in between. Foxes, on the other hand, are “eclectic experts” who have a wide range of analytical tools at their disposal rather than a single Big Idea. The authors argue that this allows foxes to be more flexible, changing their approach based on the particular problem. Foxes vastly outperformed hedgehogs in the EPJ.

> **Foxes Make Better Forecasters, Hedgehogs Make Better CEOs**
> 
> A fox mentality is not always preferable to a hedgehog mentality. In fact, in some fields, hedgehogs have a distinctive advantage. For example, while researching for the book _Good to Great, _author Jim Collins and his research team interviewed leaders of companies that vastly outperform other companies in their respective industries. Collins found that the CEOs of great companies were overwhelmingly hedgehogs, not foxes. In fact, the hedgehog mentality was so crucial to success that these companies tended to organize their entire business models around the hedgehog’s one Big Idea.
> 
> Based on what we’ve learned so far about foxes and hedgehogs, this might be somewhat counterintuitive. If foxes make better forecasters, and CEOs need to be able to predict the outcomes of their business decisions, shouldn’t CEOs strive to be foxes? Collins argues that a fox mentality considers too many variables, which ultimately distracts leaders from pursuing the company’s core mission (or, as Collins calls it, their “Hedgehog Concept”). Instead, strong business leaders should boil down the answers to three questions: What can I do better than anyone else? What is my financial engine? And what am I most passionate about? The combined answers to these questions form the core of the Hedgehog Concept, and pursuing that central concept—without getting distracted by outside factors—is what takes a company from good to great.

### Part 2: Traits of Superforecasters

The authors argue that what makes superforecasters truly “super” isn’t how smart they are—it’s the way they use their intelligence to approach a problem. Let’s examine the various ways they do this in detail.

#### Trait 1: They Avoid Cognitive Biases

According to the authors, the reason superforecasters make such accurate predictions is that they’re adept at avoiding cognitive biases. We’re all prone to certain cognitive biases that stem from unconscious thinking, or what psychologists like Tetlock often describe as “System 1” thinking. These biases skew our judgment, often without us even noticing. Superforecasters constantly monitor and question their System 1 assumptions. (Daniel Kahneman describes the two-system model of thinking in _Thinking, Fast and Slow_ ; **System 2 governs conscious, deliberate thinking, while System 1 functions automatically and unconsciously.**)

(Shortform note: Kahneman argues that System 1 is also prone to making snap predictions. For example, when we see someone with an angry expression, System 1 automatically predicts that person is about to start yelling. Those automatic predictions could be another mental trap for prudent forecasters to avoid.)

#### Trait 2: They Generate Multiple Perspectives

Superforecasters also rely on aggregated judgment (aggregation is the process of combining data from multiple sources). Tetlock and Gardner argue that aggregation is a powerful tool for forecasters because the **aggregated judgment of a group of people is usually more accurate than the judgment of an average member of the group.**

Superforecasters use aggregation by pulling from many sources and using many tools to produce an answer, despite being just one person. This skill doesn’t come naturally to most people—we struggle to even recognize that there are other perspectives beyond our own “tip-of-the-nose” view, let alone fully consider those ideas. This is part of what sets superforecasters apart.

> **How to Generate New Perspectives Like a Superforecaster**
> 
> To think like a superforecaster, you need to look beyond the tip-of-your-nose view and find new ways of viewing a problem. Here are some tips to get you in the right mindset:
> 
>   * Reverse-engineer the problem. For example, if you’re asked to predict the likelihood of the U.S. raising the federal minimum wage to $15 per hour, pretend it’s already happened and work backwards from there. What would have had to change to lead to a change in the minimum wage?
> 
>   * Broaden your horizons. Commit to reading books and following news sources outside of your comfort zone. The more diverse perspectives you expose yourself to, the easier it will be to approach a particular problem from a different vantage point.
> 
>   * Try attacking your own conclusions. This is similar to the technique of “negative empiricism” that Nassim Nicholas Taleb describes in _The Black Swan_ , which involves deliberately searching for evidence that will disprove your argument. For example, for the minimum wage question, if you ultimately conclude that the U.S. federal government _will_ raise the minimum wage, go back and look for evidence that they _won’t_.
> 
> 


#### Trait 3: They Think in Probabilities

According to the authors, superforecasters are probabilistic thinkers. This goes beyond just phrasing their forecasts in terms of probability percentages. In situations where most of us think in terms of black and white, superforecasters think in shades of grey.

**Most people’s mental “probability dial” has three distinct settings: yes, no, and maybe. By contrast, probabilistic thinkers have an unlimited number of settings.** They’re more likely to answer questions in terms of percentages rather than “yes” or “no.” And this is not just in the realm of forecasting—this is how superforecasters normally think and speak in their everyday lives.

(Shortform note: Superforecasters’ emphasis on probabilistic thinking may help to explain the gender gap among superforecasters, who tend to be male. Young children perform about the same on tests of probabilistic thinking regardless of gender—however, by age 10, boys tend to outperform girls, a pattern that holds true for many other math skills. This could be because, as Sheryl Sandberg argues in _Lean In_ , social norms discourage girls from pursuing math and science.)

#### Trait 4: They Think From the Outside In

Tetlock and Gardner argue that when superforecasters first encounter a question, they begin by looking at the wide perspective of that question before accounting for the specifics (in _Thinking, Fast and Slow_ , Daniel Kahneman calls that wider perspective the “outside view”). Compare this to the “inside view,” which describes the particular details of a situation.

For example, imagine someone tells you about their physician friend, Dr. Jones, and asks you to estimate the likelihood that Dr. Jones is a pediatrician. If you start with the inside view, you’ll analyze the specifics of Dr. Jones’s life and personality and make predictions based on what you find. The trouble is, specifics can often lead us to make random and extreme guesses. If we’re told that Dr. Jones loves children and worked at a summer camp for sick children during college, we might say it’s 80% likely that Dr. Jones is a pediatrician. On the other hand, if we’re told that Dr. Jones is a very serious, reserved person and has no plans to become a parent, we might swing to the other extreme and guess 2%.

In contrast, if you start with the outside view, you’ll ignore any details about the specific person. Instead, you’d try to answer the question “What percentage of doctors specialize in pediatrics overall?” This gives you a base rate from which to calibrate your prediction, which is more likely to lead to an accurate forecast than if you begin with a random “inside view”-inspired guess.

> **Master the Outside View With a Premortem**
> 
> In _Thinking, Fast and Slow_ , Daniel Kahneman advises using a “premortem” analysis to avoid the dangers of inside-out thinking. A premortem analysis is a mental exercise in which you imagine that whatever you’re working on (be it a project or a forecast) has already come to fruition—and was a complete disaster. Your goal is to come up with as many reasons as possible to explain this hypothetical “failure.”
> 
> This approach is helpful because, by nature, the inside view makes a situation feel “special” because it predisposes you to focus on what makes the situation unique. That feeling can make it more difficult to notice biases in your answer because you might assume the current situation won’t abide by the usual “rules.” For example, most newlyweds probably don’t expect to ever get divorced, despite the 40-50% divorce rate. That’s because, from the inside, the relationship feels “special” or distinct from the relationships that ended in divorce.
> 
> The premortem technique can help you reorient to the outside view because assuming your answer is incorrect will likely force you to recognize that the specifics of this situation aren’t as important as the base rate. For example, if you’re predicting whether a startup will succeed, it’s tempting to take the inside view and make your forecast based on the business model or the founder’s previous business experience. However, if you try a premortem analysis, it will be easy to come up with reasons the company failed given that the failure rate for startups is roughly 90%. That sobering statistic can help remind you that even if the inside view looks like a recipe for success, the odds are stacked so strongly against new businesses that failure is much more likely.

#### Trait 5: They Have a Growth Mindset

Forecasting involves quite a bit of failure because forecasters are asked to predict the unpredictable. While no one enjoys being wrong, the authors argue that superforecasters are more likely than regular forecasters to see their failures as an opportunity to learn and improve. Educational psychologists call this a “growth mindset.”**People with a growth mindset believe that talent and intelligence can be developed through learning and practice.**

The idea behind the growth mindset seems intuitive, but in practice, the authors report that most of us gravitate towards a “fixed mindset” instead. **The fixed mindset tells us that talent and intelligence are traits we’re born with** , so practice can only strengthen the natural abilities that are already there.

> **Grow Your Own Growth Mindset**
> 
> Like many other superforecaster skills, a growth mindset isn’t an inborn trait—it can be grown and developed with practice. In _Mindset, _psychologist Carol Dweck lays out a few concrete tips to help you transition from a fixed mindset to a growth mindset.
> 
>   * First, acknowledge and accept your fixed mindset. Most people call on both mindsets in different scenarios, so having a predominantly fixed mindset doesn’t make you a bad or inferior person. It’s just another way of thinking, and if you want to develop a growth mindset, you absolutely can.
> 
>   * Next, take note of the situations that trigger your fixed mindset. For example, you might notice yourself slipping into a fixed mindset when you’re overwhelmed by a demanding task or when a colleague gets promoted over you.
> 
>   * Think of your fixed mindset as a separate persona and give it a name. That way, when you catch yourself thinking, “I should give up; I’m just not talented at this,” you can say, “Oh, that’s just Rigid Rita acting up.” Assigning those thoughts to a separate persona will help you remember that you don’t have to believe those fixed-mindset thoughts; you can choose to respond with a growth mindset instead.
> 
>   * Finally, when you notice your fixed mindset persona taking over, remind that persona that you _are_ capable of growth and that risk and effort are necessary parts of that.
> 
> 


#### Trait 6: They’re Intellectually Humble

According to the authors, superforecasting requires the humility to admit when you don’t know the answer and to acknowledge that bias might cloud your judgment. This is called **intellectual humility, which __ is an acknowledgment of the power of randomness. **It involves admitting that some things are impossible to predict or control, regardless of your skill.

Professional poker player Annie Duke describes this as the difference between “humility in the face of the game” and “humility in the face of your opponents.” In other words, Duke’s long record of success indicates that she is an exceptionally talented poker player and is probably more skilled than most of her opponents. But all of Duke’s skill and experience doesn’t mean she will automatically win every game or that she is even capable of fully understanding every possible intricacy. **Like superforecasters, her skills allow her to beat her opponents but not the game itself.**

> **To Foster Humility, Understand the Role of Luck in Success**
> 
> Annie Duke’s distinction between “humility in the face of the game” and “humility in the face of your opponents” reflects author Nassim Taleb’s views on luck and success. In _Fooled by Randomness_ , Taleb argues that, while skill is a good predictor of moderate success, luck is a better predictor of wild success.
> 
> Similarly, Duke understands that winning at poker requires a certain degree of luck; if she were extremely skilled but terribly unlucky, she’d be able to carve out a decent record, but she certainly wouldn’t be the champion player she is now. Therefore, Duke is able to remain humble because she understands that no matter how well she plays, she’s always one streak of bad luck away from a loss.

#### Trait 7: They’re Team Players

In forecasting tournaments, superforecasters work in teams to create forecasts. According to the authors, one feature of successful teams is the way they freely share resources with each other. Psychologist Adam Grant calls people who give more than they receive “givers.” He compares them to “matchers” (who give and take in equal measure) and “takers” (who take more than they give). Grant found that **givers tend to be _more_ successful than matchers or takers. **Tetlock and Gardner argue that successful superforecasting teams tend to be stacked with givers.

> **Superforecasting Teams Are Optimally Distinct**
> 
> In his book _Give and Take_ , Adam Grant offers another clue as to what makes superforecasting teams so prone to generosity. Grant argues that we’re more motivated to help people who are part of our own social and identity groups (which can be anything from immediate family to school classmates to fellow football fans). Additionally, the more unique the group is compared to the dominant culture, the more inclined members are to help one another (this is called “optimal distinctiveness”). Participating in forecasting tournaments is a rare hobby, and superforecasters are a unique subgroup of forecasters; that uniqueness might strengthen their group identity and make them even more likely to share resources with one another.

### Part 3: Can Forecasting Solve the Most Important Questions?

According to the authors, the field of forecasting is facing an important challenge: Namely, the idea that the questions people really care about and need to answer are typically too big for a forecaster to even attempt. For example, a solid superforecaster can predict the likelihood that China will begin closing any of its hundreds of coal plants (which experts say could help the country meet its environmental goals), but they can’t answer the real question people are asking: “Will we be able to prevent the most devastating effects of climate change?”

This is a valid criticism—luckily, Tetlock and Gardner argue that **we can get around it by breaking big questions like “Will things turn out okay?” into a host of smaller questions that superforecasters _can_ answer.** This is called **Bayesian question clustering**. The answers to these questions contribute a small piece of the overall answer. Cumulatively, the answers to those small questions can approximate an answer to the bigger question.

For example, if we ask enough questions about factors that could contribute to worsening climate change, we know that the more “yes” answers we get to the small questions (for example, whether sea levels will rise by more than one millimeter in the next year, or whether the United States government will invest more money in solar energy), the more likely the answer to the big question is also a “yes.”

(Shortform note: This technique may help to answer a common critique of forecasting: that it is an example of the “streetlight effect,” or the equivalent of looking for your lost keys under the streetlight—even if that’s not where you lost them—because that’s where the light is best. This is related to black swan thinking—whatever future events you _can_ predict (metaphorically shine a light on) won’t matter because the only truly important events are, by definition, unpredictable. To see the utility of Bayesian question clustering, we can change the metaphor a bit: If a forecaster searches for multiple puzzle pieces under the streetlight as opposed to a single set of keys, they may find enough pieces to at least see the gist of the whole puzzle—even if half the pieces are still lost in the dark.)

[[book_md/superforecasting/preview|preview]]

[[book_md/superforecasting/shortform-introduction|shortform-introduction]]

##### Welcome!

Let’s go on a quick tour of a Shortform book guide. 

Start

##### 1-Page Summary

Every guide starts with a 1-Page Summary. This is a 5-10 minute overview of the book’s key points. 

Next

##### Finished!

If you ever need to see this tour again, click here. 

Close

Guided Tour

![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=4960608e-cc82-42fa-9ad9-608501b64abd&sid=f30c5e70639211ee87d33f0876d93783&vid=f30c9700639211eeb3a75d830392c94f&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Book&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fsuperforecasting%2F1-page-summary&r=&lt=606&evt=pageLoad&sv=1&rn=489505)

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__



