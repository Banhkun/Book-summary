![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# Biased

Back to Discover

[[book_md/biased/preview|preview]]

  * [[book_md/biased|biased]]
  * Full Book Guide

    * [[book_md/biased/shortform-introduction|shortform-introduction]]
    * [[book_md/biased/chapters-1-2|chapters-1-2]]
    * [[book_md/biased/exercise-reflect-on-your-experiences-with-bias|exercise-reflect-on-your-experiences-with-bias]]
    * [[book_md/biased/chapter-6|chapter-6]]
    * [[book_md/biased/exercise-compare-the-impact-of-images-and-words|exercise-compare-the-impact-of-images-and-words]]
    * [[book_md/biased/exercise-think-about-the-black-ape-association|exercise-think-about-the-black-ape-association]]
    * [[book_md/biased/chapter-7|chapter-7]]
    * [[book_md/biased/chapter-8|chapter-8]]
    * [[book_md/biased/exercise-design-a-new-history-class|exercise-design-a-new-history-class]]
    * [[book_md/biased/chapter-10|chapter-10]]
    * [[book_md/biased/chapter-3|chapter-3]]
    * [[book_md/biased/chapters-4-5|chapters-4-5]]
    * [[book_md/biased/exercise-imagine-a-better-system|exercise-imagine-a-better-system]]
    * [[book_md/biased/chapter-9|chapter-9]]
    * [[book_md/biased/exercise-reflect-on-your-own-biases|exercise-reflect-on-your-own-biases]]
  * [[book_md/biased/highlights|highlights]]
  * [[book_md/biased/community|community]]



Adding to Favorites 

Removing from Favorites 

## Chapter 7: Bias in Housing and Neighborhoods

So far in this guide, we’ve learned how bias works in the brain and the history of racial bias in science. **Now, we’ll see how bias impacts very personal decisions—like where to live.** Today, segregation and racial bias in housing is a major problem, especially in large cities. This problem stems from a long history of racist policies that severely limited where black people could buy or rent property. Although most of those policies no longer exist, they created a pattern of de facto segregation that persists to this day.

(Shortform note: Whole books have been written on the subject of racist housing policies. For example, _The Color of Law _by Richard Rothstein examines segregated housing in the United States from a legal and historical standpoint.)

In this chapter, we’ll explore the history of racist residential policies, the link between housing discrimination and ideas about cleanliness and disease, and the way those ideas play out on modern platforms like Nextdoor and Airbnb.

### The History of Segregated Housing

In the early 20th century, private housing developers began instituting official real estate covenants as a response to black Southerners migrating northward. These covenants forbade white homeowners from renting or selling their homes to black people; if a white homeowner ignored this covenant, the new black occupants could be legally evicted based on their race because racial covenants were “voluntary private contracts.” Racial covenants were so widespread that by the time the Supreme Court banned them in 1948, black residents were banned from 80% of the neighborhoods in big cities like Los Angeles.

**For over 30 years, racial covenants ensured that black homeowners and renters were crowded into tiny neighborhoods, completely segregated from their white neighbors.** Those covenants are the origin of the segregated neighborhoods and ethnic ghettos that still exist today. During this time, there was no legal recourse for people facing housing discrimination—if anything, government policies were even _more_ discriminatory. State and local government policies varied, but many places had zoning regulations that specifically barred all non-white people from certain areas.

> **The Link Between Implicit Bias and Housing Segregation**
> 
> In _Biased_ , Eberhardt describes the history of housing segregation primarily as a backdrop to discuss modern racial discrimination in housing. The policies she describes are primarily examples of explicit bias, since they were deliberately designed to keep black families out of white neighborhoods.
> 
> However, implicit bias also played a strong role in the history of housing segregation. In _The Color of Law, _Rothstein describes “blockbusting,” a tactic that real estate agents used to scare white homeowners into selling their homes at a steep discount. While these agents sometimes relied on explicit bias by touting lies that black people moving into a neighborhood would reduce property values, they often employed subtler methods that preyed on white homeowners’ existing implicit biases. For example, real estate agents would pay black mothers to walk their babies through white neighborhoods. The agents knew that the mere sight of a black person in their neighborhood would activate white homeowners’ implicit biases and ultimately make them more likely to sell.
> 
> These tactics were so successful that they led to the phenomenon of “white flight,” in which white people moved out of racially diverse neighborhoods en masse, often fleeing to the suburbs, which were still almost exclusively white.

### Modern Segregation

Racial discrimination in housing is now technically illegal, but nearly 70 years of officially-sanctioned segregation left its mark on American cities. Today, African Americans are more likely to live in segregated neighborhoods than people of any other race—regardless of their economic status. What’s more, Eberhardt argues that **segregation is largely maintained by white people’s racial biases.** Studies show that most white people wouldn’t move to a neighborhood that is even 30% black, citing fears of high crime rates and low property values.

(Shortform note: In her 2018 memoir, _Becoming_ , former First Lady Michelle Obama describes a visceral childhood encounter with antiblack bias in white neighborhoods. The former First Lady and her family visited their close friends, a light-skinned black family, who had recently moved to the suburbs. When it was time to return home, the family discovered that someone had keyed a deep gouge in their Buick, most likely as a warning that they weren’t welcome in that white neighborhood.)

Racial bias also skews white people’s perception of risk and danger: The more black people living in a given neighborhood, the higher white people estimate the crime rate to be and the more they fear for their own personal safety. But Eberhardt argues that these biased ideas about black spaces don’t just affect white people—one study showed that both white and black people report seeing more “disorder” (like graffiti or loose garbage) in black neighborhoods, even if the neighborhood is actually well-maintained. Another study showed that people of all races associate black neighborhoods with words like “dangerous” and “dirty.” In fact, research shows that people are willing to pay $22,000 more for a house if they think the previous owners were white than they would if the owners were black.

> **“Space Racism” and Attitudes Toward Black Spaces**
> 
> These biased attitudes toward black spaces reflect the idea of “space racism” that Ibram X. Kendi describes in _How to Be an Antiracist_. “Space racism” describes the combination of attitudes and policies that contribute to inequality between spaces that are primarily inhabited by people of one race. For example, the funding gap between majority-white and majority-black schools is an example of space racism because it reflects the racist attitude of people in power that white children deserve more resources than black children.
> 
> As a concept, space racism also describes the bias Eberhardt observed against black neighborhoods, because people who hold those biases ignore the fact that majority-white neighborhoods can also experience dangerous crime, including mass shootings. In fact, a 2019 study funded by the Department of Justice found that perpetrators of mass shootings in K-12 schools, places of worship, and commercial locations are most often white men.

### Bias in Neighborhoods and Communities

As we’ve seen, racial biases can affect where we live and who we allow into our communities—**but the physical and cultural makeup of those communities also, in turn, affects our racial biases.** For example, if someone grows up in a culture with entrenched antiblack racial bias, they’ll most likely see that bias as just another social norm; if they move to a place with an actively antiracist culture, their idea of social norms will shift to reflect that.

#### Physical Space as a Tool of Bias

The physical environment a person lives in plays an important role in the biases they develop. Physical space can both reflect and reinforce bias. For example, “Whites Only” signs on businesses and drinking fountains reflect the racial bias of people in that space, but they also ensure that anyone who spends time there begins to share that bias (because when you’re literally, physically surrounded by a certain message, it’s easy to wind up believing it). Today, racially segregated neighborhoods work the same way—they reflect a history of racial bias and reinforce the message that “this is how things should be.”

For black people, living in those kinds of heavily segregated environments is not only demoralizing: It’s a constant reminder of an underlying threat of violence. Whether through lynch mobs or police brutality, black people have always faced deadly violence in white spaces. **That constant threat of violence turns the physical space itself into a tool of subjugation** —it’s impossible to live, work, or merely exist in those spaces without being reminded of your place in the social hierarchy and the potentially deadly consequences for stepping out of it.

> **Police Brutality: Retaliation for Barack Obama’s Success?**
> 
> In her 2020 book _Caste, _author Isabel Wilkerson argues that lynch mobs and police brutality are violent tools designed to keep black people in their place. She also argues that the recent spike in police violence against black people is, in part, a reaction to the election (and re-election) of Barack Obama. According to Wilkerson, many white people saw a black man occupying the highest office in the country as a threat to white social dominance. The ensuing panic brought up buried racist sentiments, which manifested in two ways: politically, in the form of the birther movement and the Tea Party; and socially, in the sudden explosion of racist hate groups. This increase in public anti-black sentiment was a precursor to the increase in police violence against black Americans.

#### Technology and Bias in Neighborhood Interactions

Today, much of the interaction between neighbors that once took place in person has moved into the digital space. **When it comes to racial bias, this is both a blessing and a curse.** On one hand, technology gives people from racial minorities a tool to document the bias they experience in daily life. For example, when a white man in Michigan fired his shotgun at a black teenager who came to his door asking for directions, the security camera integrated into the man’s doorbell recorded the entire incident; the recording corroborated the terrified 14-year-old’s story and led to the homeowner’s arrest and eventual conviction. Without that recording, the boy would have been powerless in the face of the biased criminal justice system.

(Shortform note: The perpetrator in this case, Jeffrey Zeigler, was convicted of “assault with intent to do great bodily harm less than murder” as well as possessing a firearm in the commission of a felony. He was sentenced to 4-10 years in prison. However, in 2020, Zeigler and his new defense attorney appealed the ruling and requested a full sentencing review, in part because they believe that a detective’s testimony in the original hearing “improperly injected race into the case when it really wasn’t an issue.")

On the other hand, technology can also escalate racial bias in dangerous ways. The lightning speed of online communication makes it easier than ever to circulate biased information. For example, if racial bias leads a white person to see a nervous black teenager as a threat, they can send a photo of the “suspicious person” to the entire neighborhood in the span of seconds. That decision can put an innocent person’s life at risk: While the person sending the message may not be the violent type, who’s to say their neighbors won’t take a “shoot first, ask questions second” approach like the homeowner above?

##### How Nextdoor Combats Racial Bias

Eberhardt argues that this unchecked bias is a particular problem for companies like Nextdoor, a social network specifically designed to connect people who live in the same physical neighborhoods. Nextdoor functions like a neighborhood bulletin board for the digital age where neighbors can ask for babysitter recommendations or spread the word about a lost dog. Its “crime and safety” category, however, quickly became a hotbed for racial profiling. The speed of communication was so quick that users never stopped to think about why a person walking down the street or sitting in their car seemed so “suspicious”; they thought they were helping to keep their neighborhood safe, never realizing that their suspicions boiled down to racial profiling.

When Nextdoor’s founders became aware of the problem, they called on Eberhardt and other experts to weigh in on the best ways to reduce racial profiling on the site. (Shortform note: Nextdoor executives were so impressed with what they learned about implicit bias that they now have a whole webpage dedicated to it.) They discovered that **fear and speed are the two biggest factors contributing to racial profiling** : People are most likely to let their biases go unchecked when they’re afraid and they don’t take time to stop and think before acting. Therefore, to combat racial profiling, Nextdoor needed to add just enough friction to the posting process to force users to stop and think about their biases, but not enough that users would become frustrated and abandon the site entirely.

To slow down the process of posting in the “crime and safety” category, Nextdoor implemented a checklist that users have to click through before posting. The checklist prompts users to get specific about what exactly makes someone “suspicious” by reminding them to focus on specific behaviors and give a detailed description of the person’s clothing. Crucially, the checklist also explicitly mentions race: It prompts users to “consider unintended consequences” if their description were to lead to an innocent person being stopped or arrested and reminds them not to “assume criminality” because of someone’s race. That’s important—according to Eberhardt, research shows that explicitly talking about race (instead of just alluding to it) leads people to act more fairly.

For technology companies, adding friction isn’t a natural instinct because the entire point of technology is typically to make daily activities faster and easier. However, in this case, **slowing the process down worked: Racial profiling on the site dropped by 75%, with no significant reduction in the total number of users.** Nextdoor even created international versions of the checklist that reflect the dominant racial, ethnic, and religious biases in each country, with similar positive results worldwide.

> **Nextdoor’s Racial Reckoning: Success Story or Empty Gesture?**
> 
> Eberhardt speaks highly of Nextdoor’s progress in combating racial profiling, but other commentators have raised serious concerns about the company’s approach to racial issues. For example, moderators often remove posts advertising Black Lives Matter protests, and the company still actively recruits local police departments to join the app.
> 
> The conversation escalated in 2020, when Nextdoor’s official Twitter made a post in support of Black Lives Matter one week after the killing of George Floyd. They faced immediate backlash from users who felt that, despite the company’s efforts, the Nextdoor app was still riddled with racism. The conversation garnered so much public attention that even Congresswoman Alexandria Ocasio-Cortez publicly called on the company to take concrete action and “deal [with] their Karen problem” instead of just tweeting a hashtag (“Karen” is slang for an entitled, middle-aged, and often openly racist white woman).
> 
> To their credit, Nextdoor listened to these complaints and took further concrete steps to address the app’s race problem. Nextdoor’s CEO accepted responsibility for Black Lives Matter posts being deleted and promised to provide bias training for the local “neighborhood leads” who serve as moderators on the app (previously, “neighborhood leads” received no training or vetting). The company also created an antiracism resource page on their site and is working to diversify their mostly-white executive board.
> 
> Like many companies, Nextdoor underwent significant upheaval in response to the COVID-19 pandemic and the widespread protests against police brutality. So far, it seems to be too soon to tell whether the changes they’ve implemented will be enough to solve the problem, and no data is available. Whatever its next moves, the company will move forward with Dr. Eberhardt’s guidance—she’s now an official member of their Neighborhood Vitality Advisory board.

### Bias in Travel and Hospitality

In addition to Nextdoor, Eberhardt describes how racial bias and housing discrimination often take place on platforms like Airbnb, a website that allows users to rent out their homes for travelers to use in lieu of a hotel. In 2016, the company received a huge wave of complaints of racial bias and discrimination in their booking process. (Shortform note: This problem came to a head in 2016, but it started much earlier. In 2014, researchers found that black hosts charged 12% less than non-black hosts for equivalent listings because the hosts knew that if two listings were equal in price, bias would tip guests away from black-owned properties.)

Black users reported trying to book available dates only to have the host reject their request for no apparent reason. To confirm their suspicions of racial discrimination, some users changed the name or photo on their profile to appear white; others enlisted white friends to help by requesting the same properties on the same dates. In both cases, when the host thought the guest was white, the rooms were suddenly available again. (Shortform note: In 2018, Airbnb changed their policy so that hosts don’t see guests’ profile photos until after they accept the booking.) These were not isolated incidents: **Independent researchers found thatblack people were 16% less likely to be accepted as guests**, even when they accounted for all other variables (like having young children who might be rowdy).

##### How Airbnb Combats Racial Bias

Ultimately, Airbnb abandoned the idea of a legal solution and simply made their own rules. Now, before users can sign up, they have to read Airbnb’s expanded non-discrimination policy and pledge to abide by it. Crucially, users also have to agree that if they violate this policy, they understand that Airbnb will terminate their account. (Shortform note: As of 2019, Airbnb reports that over 1 million users were banned after refusing to sign the Community Commitment and Nondiscrimination Policy.)

Eberhardt argues that while this policy change gives the company a built-in tool to respond to explicit racial bias,**it does very little to combat _implicit_ bias, which experts argue is a far bigger problem.** Airbnb’s “instant book” tool may be a solution. When hosts opt for “instant book,” they set certain dates that their property is available, and guests can book those dates without waiting for the host to approve their application (similar to booking a traditional hotel room). It’s a hands-off approach that bypasses the opportunity for bias to interfere, and research shows that it works: **There are no racial disparities in “instant book” transactions.**

> **Project Lighthouse and Airbnb’s Continued Antiracism Efforts**
> 
> In 2020, one year after _Biased_ was published, Airbnb announced the launch of Project Lighthouse, a data collection effort they developed with help from eight different civil rights agencies. The project will collect users’ first names and profile photos and send them to a third party evaluator who will indicate which race they think the user is. These judgments will be made by an actual human rather than by artificial intelligence, which often has racial bias issues of its own. Airbnb will then use those judgments to assign a racial category to the user profile and run experiments with internal data to see if users who are judged to be people of color experience discrimination on the site.
> 
> In addition to Project Lighthouse, Airbnb commissioned their internal Black@Airbnb employee resource group to create an Activism and Allyship guide. The guide was used internally before being shared with all Airbnb users in the wake of the George Floyd killing in 2020.
> 
> While Airbnb has made progress toward eliminating racial bias on the site, their internal bias problem remains. Despite launching a Diverse Candidate Slate Rule in 2017, Airbnb reported in 2019 that its workforce was just 3.5% African American. For reference, census data for the same year show that African American people make up 13.4% of the U.S. population.

[[book_md/biased/exercise-think-about-the-black-ape-association|exercise-think-about-the-black-ape-association]]

[[book_md/biased/chapter-8|chapter-8]]

![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=aebce09c-6b11-45f8-b9fc-431c7215e137&sid=201ffde0635411ee902411d77b750559&vid=20202bf0635411ee9ac03f2e618b0b9f&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Book&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fbiased%2Fchapter-7&r=&lt=378&evt=pageLoad&sv=1&rn=376537)

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__



