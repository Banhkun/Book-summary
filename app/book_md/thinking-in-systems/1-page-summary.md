![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# Thinking in Systems

Back to Discover

[[book_md/thinking-in-systems/preview|preview]]

  * [[book_md/thinking-in-systems|thinking-in-systems]]
  * Full Book Guide

    * [[book_md/thinking-in-systems/introduction|introduction]]
    * [[book_md/thinking-in-systems/part-1|part-1]]
    * [[book_md/thinking-in-systems/exercise-define-a-system|exercise-define-a-system]]
    * [[book_md/thinking-in-systems/chapter-1-2|chapter-1-2]]
    * [[book_md/thinking-in-systems/exercise-feedback-loops|exercise-feedback-loops]]
    * [[book_md/thinking-in-systems/chapter-2-1|chapter-2-1]]
    * [[book_md/thinking-in-systems/chapter-2-2|chapter-2-2]]
    * [[book_md/thinking-in-systems/part-2|part-2]]
    * [[book_md/thinking-in-systems/exercise-improve-your-system|exercise-improve-your-system]]
    * [[book_md/thinking-in-systems/chapter-4|chapter-4]]
    * [[book_md/thinking-in-systems/chapter-5|chapter-5]]
    * [[book_md/thinking-in-systems/part-3|part-3]]
    * [[book_md/thinking-in-systems/chapter-7|chapter-7]]
  * [[book_md/thinking-in-systems/highlights|highlights]]
  * [[book_md/thinking-in-systems/community|community]]



![](/img/tutorial-fonts.175b2111.svg)

##### Change text options

Here you can change the font, text size, and reading screen to just how you like it. 

Next

  *   *   *   *   * 


![](/img/tutorial-menu.4c76dd27.svg)

##### Table of contents

Here you’ll find everything else, including the full chapter-by-chapter guide, your highlights, PDF downloads, and book discussions. 

Next

  *   *   *   *   * 


![](/img/tutorial-player.d25b1afb.svg)

##### Audio

Every guide has an audio narration so you can listen on the go. 

Next

  *   *   *   *   * 


![](/img/tutorial-favorite.b948300a.svg)

##### Add to Favorite

Mark your favorite guides here. You can find your favorites on your homepage. 

Next

  *   *   *   *   * 


![](/img/tutorial-night.ddd7fb5c.svg)

##### Night Mode

Like a darker look when you read? Turn dark mode on here. 

Finish

  *   *   *   *   * 


Adding to Favorites 

Removing from Favorites 

## 1-Page Summary

_Thinking in Systems_ is an introduction to systems analysis. Many aspects of the world operate as complicated systems, rather than simple cause-effect relationships. Many problems in the world manifest from defects in how the systems work. Understanding how systems work, and how to intervene in them, is key to producing the changes you seek.

### What Is a System?

**A system is composed of three things:**

  1. Elements: The individual things in the system
  2. Interconnections: The relationships between the elements
  3. Purpose or Function: What the system achieves



To define it more cohesively, **a system is a set of elements that is interconnected in a way that achieves its function**.

Many things in the world operate as systems.

  * A football team consists of a group of players on the field, each with a specific role that interacts with the others. The larger team system also consists of coaches, support staff, and fans.
  * Within the system of a corporation, people, machines, and information work together to achieve the corporation’s goals. This corporation then takes place within the larger system of the economy.



### Stocks and Flows

Stocks and flows are the foundation of every system.

A stock represents the elements in a system that you can see, count or measure. It can be commonly thought of as an inventory, a store, or a backlog.

**Flows are the means by which the stocks change over time.** Inflows increase the level of stock, while outflows decrease the level of stock.

Let’s take a simple system: a bathtub.

  * The stock is the amount of water in the tub.
  * The inflow is water coming from the faucet into the tub. This raises the stock.
  * The outflow is the drain that removes water from the tub. This decreases the stock.



This can be drawn on a stock-and-flow diagram, as here:

![thinking-in-systems-stock-flow.png](https://media.shortform.com/images/thinking-in-systems-stock-flow.png)

Many systems are analogous to the bathtub:

  * In fossil fuels, the stock is the reservoir of fossil fuels. Mining lowers the stock, while natural processes increase the stock.
  * The world population is a stock of people. The population grows with births and shrinks with deaths.



#### Properties of Stocks and Flows

**Stocks take time to change.** In a bathtub, think about how quick it is to change the inflow or outflow. It takes just a second to turn on the faucet. It takes minutes to fill the tub.

Why do stocks change so gradually? **Because it takes time for the flows to flow.** As a result, stocks change slowly. They act as buffers, delays, and lags. They are shock absorbers to the system.

From a human point of view, this has both benefits and drawbacks. On one hand, **stocks represent stability**. They let inflows and outflows go out of balance for a period of time.

  * Your bank account stores money and gives your life stability. If you get fired from your job, the inflow of money will stop, but you can take money from your stock to continue living and figure out how to solve the problem.



On the other hand, a slowly-changing stock means things can’t change overnight.

  * If a population’s skills become meaningless because of technology, you can’t re-educate the workforce instantaneously. It takes time for the information to work its way through the system and to flow to the population.



#### Where We Focus

As humans, when we look at systems, we tend to focus more on stocks than on flows. Furthermore, **we tend to focus more on inflows than on outflows**.

  * When thinking about how the world population is growing, we naturally think about how increasing births must be driving the trend. We think less about how preventing death through better medical care also grows the population.
  * Likewise, a company that wants to increase its headcount does so instinctively by hiring more people. It doesn’t often think as hard about how to reduce the outflow of people who quit or are fired. 



This is just one example of how we, as simplicity-seeking humans, tend to ignore the complexity of systems and thus develop incomplete understandings of how to intervene.

### Feedback Loops

Systems often produce behaviors that are persistent over time. In one type of case, the system seems self-correcting—stocks stay around a certain level. In another case, the system seems to spiral out of control—it either rockets up exponentially, or it shrinks very quickly.

**When a behavior is persistent like this, it’s likely governed by a feedback loop.** Loops form when **changes in a stock affect the flows of the stock**.

#### Balancing Feedback Loops (Stabilizing)

Also known as: negative feedback loops or self-regulation.

In balancing feedback loops, there is an acceptable setpoint of stock. If the stock changes relative to this acceptable level, the flows change to push it back to the acceptable level.

  * If the stock dips below this level, the inflows increase and the outflows decrease, to increase the stock level. 
  * If the stock rises above the acceptable level, the inflows decrease and the outflows increase, to decrease the stock level.



An intuitive example is keeping a bathtub water level steady.

  * If the level is too low, plug the drain and turn on the faucet. 
  * If the level is too high and the water spills out of the tub, open the drain and turn off the faucet.



#### Reinforcing Feedback Loops (Runaway)

Also known as: positive feedback loops, vicious cycles, virtuous cycles, flywheel effects, snowballing, compound growth, or exponential growth.

Reinforcing feedback loops have the opposite effect of balancing feedback loops—they amplify the change in stock and cause it to grow more quickly or shrink more quickly.

  * As a stock level increases, the inflow also increases (or the outflow decreases), causing the stock level to further rise.
  * In the other direction, as a stock level decreases, the inflow also decreases (or the outflow increases), causing the stock level to further decrease.



Here are examples of runaway loops in the positive direction:

  * The more people there are in the world, the more they reproduce, which increases the stock of the world population.
  * A healthy national economy grows in a reinforcing loop. In a nation, the more factories and people you have, the more you can produce. The more you produce, the more you can invest back in more factories and educating people.



Here are examples of runaway loops in the negative direction:

  * In agriculture, plant roots help retain soil. The more that soil is eroded, the less roots can grow, which causes more erosion.
  * In a natural emergency, a store may have a sale on its goods. The lower the stock of a good like toilet paper, the more fervently people want to buy it, which causes the stock to shrink further.



### Building More Complicated Systems

From these basic building blocks, you can build up to more complicated systems that model the real world. In this 1-page summary, we’ll cover only one simple system and show how systems analysis can lead to an understanding of its behavior.

#### One Stock + One Reinforcing Loop, One Balancing Loop

We’ll look at a system with one stock and two loops that compete against each other—one reinforcing, and one balancing.

The concrete example we’ll use is the world population.

  * The population is the stock.
  * The reinforcing loop is birth rate—the more people there are, the more who reproduce. By itself, this leads to natural exponential growth.
  * The balancing loop is deaths—the more people there are, the more who die. (Shortform note: In essence, the setpoint of this balancing loop is 0, and the further away from 0 the stock is, the more people who will die.)



The stock and flow diagram looks like this:

![thinking-in-systems-population.png](https://media.shortform.com/images/thinking-in-systems-population.png)

How does the population behave in this scenario? It depends on the relative strength of the two competing loops.

  * If the birth rate is higher than the death rate, the population will grow exponentially. This is where the world overall currently is.
  * If the death rate becomes larger than the birth rate, the population would shrink. (This can happen if the birth rate plummets, or the death rate skyrockets, or both.)
  * If they are equal, the population will stay the same.



Different circumstances can drive the relative strength of the birth or death loop:

  * Data suggests that as countries get wealthier, birth rates fall. Therefore, poorer countries with high current birth rates may not retain high birth rates as their economies develop.
  * A lethal, contagious disease could drastically increase the death rate. For instance, during the HIV/AIDS epidemic, projections of populations in areas with high HIV prevalence had to account for higher mortality.
  * Birth rate could also fall due to social factors, such as lower interest in raising children or fertility issues.



#### More Complicated Systems

Read the full summary to learn how:

  * One stock + two balancing loops represents a thermostat keeping a room’s temperature
  * Delays introduce oscillations into system behavior, as in a car sales manager trying to keep her inventory consistent
  * How to model extraction of a non-renewable resource, such as fossil fuels
  * How to model extraction of a renewable resource, such as fish in the sea



### Why Systems Perform Well

Systems are capable of accomplishing their purposes remarkably well. They can persist for long periods without any particular oversight, and they can survive changes in the environment remarkably well. Why is that?

Strong systems have three properties:

  * Resilience: the ability to bounce back after being stressed
  * Self-organization: the ability to make itself more complex
  * Hierarchy: the arrangement of a system into layers of systems and subsystems



**Creating systems that ignore these three properties leads to brittleness, causing systems to fail under changing circumstances.**

#### Resilience

**Think of resilience as the range of conditions in which a system can perform normally.** The wider the range of conditions, the more resilient the system. For example, the human body avoids disease by foreign agents, repairs itself after injury, and survives in a wide range of temperatures and food conditions.

The stability of resilience comes from feedback loops that can exist at different layers of abstraction:

  * There are feedback loops at the baseline level that restore a system. To increase resilience, there may be multiple feedback loops that serve redundant purposes and can substitute for one another. They may operate through different mechanisms and different time scales.
  * Above the baseline loops, there are feedback loops that _restore_ other feedback loops—consider these meta-feedback loops.
  * Even further, there are meta-meta feedback loops that create better meta-loops and feedback loops. 



At times, we design systems for goals other than resilience. **Commonly, we optimize for productivity or efficiency and eliminate feedback loops that seem unnecessary or costly. This can make the system very brittle** —it narrows the range of conditions in which the system can operate normally. Minor perturbations can knock the system out of balance.

#### Self-Organization

**Self-organization means that the system is able to make itself more complex.** This is useful because the system can diversify, adapt, and improve itself.

Our world’s biology is a self-organizing system. Billions of years ago, a soup of chemicals in water formed a cellular organism, which then formed multicellular organisms, and eventually into thinking, talking humans.

Some organizations quash self-organization, possibly because they optimize toward performance and seek homogeneity, or because they’re afraid of threats to stability. This can explain why some companies reduce their workforces to machines that follow basic instructions and suppress disagreement.

**Suppressing self-organization can weaken the resilience of a system and prevent it from adapting to new situations.**

#### Hierarchy

In a hierarchy, subsystems are grouped under a larger system. For example:

  * The individual cells in your body are subsystems of the larger system, an organ. 
  * The organs are in turn subsystems of the larger system of your body. 
  * You, in turn, are a subsystem of the larger systems of your family, your company, and your community, and so on.



In an efficient hierarchy, the subsystems work well more or less independently, while serving the needs of the larger system. **The larger system’s role is to coordinate between the subsystems and help the subsystems perform better.**

The arrangement of a complex system into a hierarchy improves efficiency. Each subsystem can take care of itself internally, without needing heavy coordination with other subsystems or the larger system.

**Problems can result at both the subsystem or larger system level:**

  * If the subsystem optimizes for itself and neglects the larger system, the whole system can fail. For example, a single cell in a body can turn cancerous, optimizing for its own growth at the expense of the larger human system.
  * The larger system’s role is to help the subsystems work better, and to coordinate work between them. If the larger system exerts too much control, it can suppress self-organization and efficiency.



### How We Fail in Systems

We try to understand systems to predict their behavior and know how best to change them. However, we’re often surprised by how differently a system behaves than we expected.

At the core of this confusion is our limitation in comprehension. **Our brains prefer simplicity and can only handle so much complexity.** We also tend to think in simple cause-effect terms, and in shorter timelines, that prevent us from seeing the full ramifications of our interventions.

These limitations prevent us from seeing things as they really are. They prevent us from designing systems that function robustly, and from intervening in systems in productive ways.

Systems with similar structures tend to have similar archetypes of problems. We’ll explore two examples of these; the full summary includes more.

#### Escalation

Also known as: Keeping up with the Joneses, arms race

Two or more competitors have individual stocks. Each competitor wants the biggest stock of all. If a competitor falls behind, they try hard to catch up and be the new winner.

This is a reinforcing loop—the higher one stock gets, the higher all the other stocks aim to get, and so on. It can continue at great cost to all competitors until one or more parties bows out or collapses.

A historical example was the Cold War, where the Soviet Union and the United States monitored each others’ munitions and pushed to amass the larger arsenal, at trillions of dollars of expense. A more pedestrian example includes how advertising between competitors can get increasingly prevalent and obnoxious, to try to gain more attention.

##### Fixing Escalation

The solution is to dampen the feedback wherein competitors are responding to each others’ behaviors.

One approach is to negotiate a mutual stop between competitors. Even though the parties might not be happy about it or may distrust each others’ intentions, a successful agreement can limit the escalation and bring back balancing feedback loops that prevent runaway behavior.

If a negotiation isn’t possible, then the solution is to stop playing the escalation game. The other actors are responding to your behavior. If you deliberately keep a lower stock than the other competitors, they will be content and will stop escalating. This does require you to be able to weather the stock advantage they have over you.

#### Addiction

Also known as: dependence, shifting the burden to the intervenor

An actor in a system has a problem. In isolation, the actor would need to solve the problem herself. However, a well-meaning intervenor gives the actor a helping hand, alleviating the problem with an intervention.

This in itself isn’t bad, but in addiction, **the intervenor helps in such a way that it weakens the ability of the actor to solve the problem herself**. Maybe the intervention stifles the development of the actor’s abilities, or it solves a surface-level symptom rather than the root problem.

The problem might appear fixed temporarily, but soon enough, the problem appears again, and in an even more serious form, since the actor is now less capable of solving the problem. The intervenor has to step in and help again to a greater degree. Thus the reinforcing feedback loop is set up—more intervention is required, which in turn further weakens the actor’s ability to solve it, which in turn requires more intervention. **Over time, the actor becomes totally dependent on—addicted to—the intervention.**

An example is elder care in Western societies: families used to take care of their parents, until nursing homes and social security came along to relieve the burden. In response, people became dependent on these resources and became unable to care for their parents—they bought smaller homes and lost the skills and desire to care.

##### Fixing Addiction

When you intervene in a system:

  * Try to first diagnose the root cause of the issue. Why is the system unable to take care of itself? 
  * Then design an intervention that will solve the root cause, and that won’t weaken the system’s ability to take care of itself.
  * After you intervene, plan to remove yourself from the system promptly.



#### More System Problems

Read the full summary to learn more common system problems:

  * **Policy resistance** , where a policy seems to have little effect on the system because the actors resist its influence. Example: The war on drugs.
  * **The rich get richer** , where the winner gets a greater share of limited resources and progressively outcompetes the loser. Example: monopolies in the marketplace.
  * **Drift to low performance** , where a performance standard depends on previous performance, instead of having absolute standards. This can cause a vicious cycle of ever-worsening standards. Example: a business loses market share, each time believing, “well, it’s not that much worse than last year.”



### Improving as a Systems Thinker

Learning to think in systems is a lifelong process. The world is so endlessly complex that there is always something new to learn. Once you think you have a good handle on a system, it behaves in ways that surprise you and require you to revise your model.

And even if you understand a system well and believe you know what should be changed, actually _implementing_ the change is a whole other challenge.

Here’s guidance on how to become a better systems thinker:

  * **To understand a system, first watch to see how it behaves.** Research its history—how did this system get here? Get data—chart important metrics over time, and tease out their relationships with each other
  * **Expand your boundaries.** Think in both short and long timespans—how will the system behave 10 generations from now? Think across disciplines—to understand complex systems, you’ll need to understand fields as wide as psychology, economics, religion, and biology.
  * **Articulate your model.** As you understand a system, put pen to paper and draw a system diagram. Put into place the system elements and show how they interconnect. Drawing your system diagram makes explicit your assumptions about the system and how it works.
  * **Expose this model to other credible people and invite their feedback.** They will question your assumptions and push you to improve your understanding. You will have to admit your mistakes, redraw your model, and this trains your mental flexibility.
  * **Decide where to intervene.** Most interventions fixate on tweaking mere numbers in the system structure (such as department budgets and national interest rates). There are much higher-leverage points to intervene, such as weakening the effect of reinforcing feedback loops, improving the system’s capacity for self-organization, or resetting the system’s goals.
  * **Probe your intervention to its deepest human layers.** When probing a system and investigating why interventions don’t work, you may bring up deep questions of human existence. You might bemoan people in the system for being blind to obvious data, and if only they saw things as you did, the problem would be fixed instantly. But this raises deeper questions: How does _anyone_ process the data they receive? How do people view the same data through very different cognitive filters? 



[[book_md/thinking-in-systems/preview|preview]]

[[book_md/thinking-in-systems/introduction|introduction]]

##### Welcome!

Let’s go on a quick tour of a Shortform book guide. 

Start

##### 1-Page Summary

Every guide starts with a 1-Page Summary. This is a 5-10 minute overview of the book’s key points. 

Next

##### Finished!

If you ever need to see this tour again, click here. 

Close

Guided Tour

![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=f6bbaa85-859a-4f15-a34a-7da651f0d43d&sid=48a964a0642711eeb2d9b36fc717f5e2&vid=48a9a1e0642711eebeaf23361361f0d4&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Book&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fthinking-in-systems%2F1-page-summary&r=&lt=1110&evt=pageLoad&sv=1&rn=578144)

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__



