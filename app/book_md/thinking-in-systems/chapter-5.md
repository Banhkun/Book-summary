![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# Thinking in Systems

Back to Discover

[[book_md/thinking-in-systems/preview|preview]]

  * [[book_md/thinking-in-systems|thinking-in-systems]]
  * Full Book Guide

    * [[book_md/thinking-in-systems/introduction|introduction]]
    * [[book_md/thinking-in-systems/part-1|part-1]]
    * [[book_md/thinking-in-systems/exercise-define-a-system|exercise-define-a-system]]
    * [[book_md/thinking-in-systems/chapter-1-2|chapter-1-2]]
    * [[book_md/thinking-in-systems/exercise-feedback-loops|exercise-feedback-loops]]
    * [[book_md/thinking-in-systems/chapter-2-1|chapter-2-1]]
    * [[book_md/thinking-in-systems/chapter-2-2|chapter-2-2]]
    * [[book_md/thinking-in-systems/part-2|part-2]]
    * [[book_md/thinking-in-systems/exercise-improve-your-system|exercise-improve-your-system]]
    * [[book_md/thinking-in-systems/chapter-4|chapter-4]]
    * [[book_md/thinking-in-systems/chapter-5|chapter-5]]
    * [[book_md/thinking-in-systems/part-3|part-3]]
    * [[book_md/thinking-in-systems/chapter-7|chapter-7]]
  * [[book_md/thinking-in-systems/highlights|highlights]]
  * [[book_md/thinking-in-systems/community|community]]



Adding to Favorites 

Removing from Favorites 

## Chapter 5: How We Fail in Systems

In previous chapters, we’ve explored a range of system models and how they relate to real-life situations, such as restocking a car inventory lot and managing renewable resources. We’ve explored how misbehaving in the system can cause poor system performance, whether that means wild oscillations in restocking the car lot or driving the fish population to extinction. And in the previous chapter, we covered our limitations in comprehending how systems work.

Taken altogether, it’s little surprise that we can design systems that completely fail to achieve the purpose we desire. Furthermore, when problems appear, we can fail at designing the right solution for the problem, and our behavior can make the situation worse.

In this chapter, we’ll describe **system archetypes** , which are **system structures that produce problematic patterns of behavior** (the author also calls them “system traps”). These archetypes are ubiquitous in the real world, explaining phenomena such as nuclear arms races, the war on drugs, and business monopolies. We regularly get mired in these problems, but by understanding how the system predictably produces the behavior, we can also find the right way to intervene.

A theme to keep in mind: beyond fixing the problem, **it’s far better to avoid getting trapped in these problems in the first place**.

### Policy Resistance

#### How It Happens

Policy resistance is the failure of policies to achieve the desired outcome. It occurs when the actors resist the policies placed on them. The situation seems to be stubbornly stuck, regardless of what policies are passed to solve the problem.

From a system point of view, policy resistance occurs because the actors in the system have personal goals that differ from the policy. Visualize it as multiple actors pulling the system stock toward opposing goals. Each actor has a desired setpoint for the stock, and the actor takes action when the stock differs from its personal goal. However, each actor has a different setpoint, so all the actors are trying to pull the stock in different directions.

Furthermore, like typical balancing feedback loops, each actor’s behavior is proportional to how far the stock is from the actor’s setpoint. The stronger one actor pulls the stock to its favored direction, the stronger the other actors try to pull back to the center. You might think of this like a game of tug of war.

The system state thus is pulled tightly in multiple directions by all the actors. But since the system stock isn’t at any one actor’s preferred setpoint, everyone is dissatisfied with the situation.

#### Examples of Policy Resistance

##### The War on Drugs

The war on drugs has multiple actors with different setpoints for the system stock of drug supply:

  * Drug addicts want the drug supply high.
  * Police want the drug supply low.
  * Drug suppliers want the drug supply in the middle to stabilize prices.
  * Most citizens who don’t use drugs just want to be safe and may not care about drug supply.



When one actor gains an advantage, the other actors pull the system back to where it was. For example, the police might increase border patrols to seize stockpiles of drugs. A number of events happen in sequence:

  * The lower supply raises prices.
  * Higher prices mean more profits for drug suppliers.
  * The suppliers use the profits to buy planes to evade border patrols.
  * The supply increases, drug prices lower, and drug use continues unabated.



Thus the setpoint is back to where it began, though now with actors pulling more tightly than before. Issuing additional policies will do little to change the situation.

##### Romania’s Abortion Problem

In the 1960s, the Romanian government, headed by dictator Nicolae Ceausescu, was worried about the country’s low birth rate, which would stagnate the economy. They decided to outlaw abortion and contraception for women under 45. However, the real underlying problem of low birth rates was that parents were too poor to raise more children, and they didn’t want more children to be born.

After abortion was outlawed, the birth rate tripled for a period of time, but then the population practiced policy resistance:

  * Mothers began getting illegal abortions, which were dangerous and tripled deaths of pregnant women.
  * Children that were born were abandoned.



The policy was so extreme that when the dictator’s government was overthrown, the head family was executed, and the first law passed was to reverse the ban on abortion.

#### Fixing Policy Resistance

Much of the reason that policy resistance occurs is that people are resisting the policy. Stronger policies cause stronger counterreactions.

**The solution is counter-intuitive: give up. Cancel the policy.** Things won’t get as bad as you think, because other actors behaved intensely only because you did.

  * For example, when alcohol Prohibition in the United States ended in the 1930s, much of the violence and crime also ended.



The ideal solution is to **develop a policy that aligns all actors’ goals and find a way to satisfy everyone**. This stops the actors from pulling against each other and more toward the same goal.

  * For example, like Romania, Sweden wanted to increase its population’s birth rate in the 1930s. But instead of outlawing abortion, they focused on the larger system goal of having children who were wanted and would be cared for. They made contraception widely available, improved health care, and made divorce easier. This aligned the population and government harmoniously in the same direction.



### Escalation

Also known as: Keeping up with the Joneses, arms race

#### How It Happens

Two or more competitors have individual stocks. Each competitor wants the biggest stock of all. If a competitor falls behind, they try hard to catch up and be the new winner.

This is a reinforcing loop—the higher one stock gets, the higher all the other stocks aim to get, and so on. It can continue at great cost to all competitors until one or more parties bows out or collapses.

(Shortform note: Conceptually, this is similar to policy resistance, in that the agents in the system are responding to how the others are behaving. However, where policy resistance had balancing feedback loops driving the system stock toward a central point, escalation has reinforcing feedback loops driving the stocks as extreme as they can go.)

#### Examples of Escalation

Arms races are classic examples of escalation. During the Cold War, the Soviet Union and the United States monitored each others’ munitions and pushed to amass the larger arsenal. This was done at tremendous expense (trillions of dollars) and led to a drag on both economies, let alone the development of weapons that threaten humanity.

More pedestrian examples of escalation include:

  * Advertising between competitors gets increasingly prevalent and obnoxious, to try to gain more attention.
  * Restaurants get louder and louder as tables try to talk over each other.



Escalation can occur in the other direction as well, such as pricing wars where competitors progressively undercut each other in pricing.

#### Fixing Escalation

As in policy resistance, the solution is to dampen the feedback wherein competitors are responding to each others’ behaviors.

One approach is to negotiate a mutual stop between competitors. Even though the parties might not be happy about it or may distrust each others’ intentions, a successful agreement can limit the escalation and bring back balancing feedback loops that prevent runaway behavior.

If a negotiation isn’t possible, then the solution is to stop playing the escalation game. The other actors are responding to your behavior. If you deliberately keep a lower stock than the other competitors, they will be content and will stop escalating. This does require you to be able to weather the stock advantage they have over you.

### The Rich Get Richer

Also known as: competitive exclusion, success to the successful

#### How It Happens

Two competitors have access to the same limited pool of resources. The winner gets a greater share of resources, which in turn allows the winner to compete even better, which then earns it more resources. On the other side, the loser gets progressively fewer resources, which makes the loser even less able to compete. Reinforcing feedback loops are at play here.

If this cycle is allowed to continue unabated, the losers will eventually be forced out of the game entirely. This outcome may be unhealthy and run counter to the goals of the whole system.

#### Examples

In ecology, one species can outcompete another, taking all the system resources to the point that the loser becomes extinct. (Shortform note: An example is an invasive species that reproduces so successfully it disrupts the local ecosystem.)

In commerce, a successful business can reinvest its profits into more technology, capacity, or political lobbying, which further enlarges its share of profits. Left unchecked, the business can become a monopoly.

The author also discusses this in the context of social inequality. The poor get poorer in a number of ways:

  * The poor have access to worse education, which leads to worse job opportunities, which leads to lower incomes. Their children are born into poverty, perpetuating the cycle.
  * They pay rent to landowners, who use the income to buy more land.
  * The poor tend to organize politically less often, and so they are underrepresented in government spending and attention.



#### Fixing the Rich Get Richer

If you’re an individual agent losing against a growing competitor, you can choose to diversify, or play a different game. In business, this can mean entering a new market or seeking different resources. However, this doesn’t always work, if the monopolist can remove all budding competition, say by destroying them or buying them up.

From a system point of view, the monopolist’s reinforcing feedback loop can be countered with balancing feedback loops that limit the monopolist’s growth. These include:

  * Antitrust regulation to break up monopolies
  * Tax laws to charge the wealthier a greater percentage of their wealth
  * Estate taxes to reduce the inheritance that is passed on to the next generation, thus limiting the ability of a family to preserve its wealth



These have the effect of leveling the playing field and equalizing the players.

### Drift to Low Performance

Also known as: eroding goals, boiled frog syndrome

#### How It Happens

The actor sets a performance bar that it tries to perform above. However, instead of keeping the bar fixed at an absolute level, the bar is actually set relative to previous performance.

If the actor performs under the bar, the bar is then set a bit lower. This might be excused by sentiments like, “Well, it’s not that much worse than last year” or “Well, everyone’s in trouble too, so we’re not doing _that_ badly.”

And if the actor has a tendency to undershoot the bar, this leads to a vicious cycle that drags the performance down, possibly to complete failure.

This drift tends to happen at a _gradual_ decline. A sharp decline would cause alarm and prompt a forceful correction. However, in a gradual decline, the actor tends to become complacent and forget how good things used to be.

#### Examples of Drift to Low Performance

A business that is losing market share can lower its targets and progressively lose share until it becomes bankrupt.

(Shortform note: Steve Jobs commented on why he was infamously harsh on hiring: “A players hire A players, but B players hire C players and C players hire D players. It doesn’t take long to get to Z players. The trickle down effect causes bozo explosions in companies.”)

#### Fixing Drift to Low Performance

Instead of setting performance standards relative to previous performance, **set absolute standards that don’t change with performance**.

Better yet, turn the vicious cycle into a virtuous cycle—set the goals relative to the best performance. If the system overperforms the goal, set the goal higher.

### Tragedy of the Commons

#### How It Happens

The actors in a system share a limited common resource. When the actor uses part of the resource, he receives all of the gain, but the cost of using the resource is spread among all the users. In sum, this usage is a net gain for the actor. Therefore, the rational behavior is to use as much of the resource as he can.

The problem is that all actors in the system are thinking this way too. As all actors act in their own self-interest, the common resource is eroded, possibly to the point of irrevocable destruction.

In essence, there is a weak feedback loop between the actor’s behavior and its future impact. It’s not clear the actor is behaving in a self-destructive way until it’s too late.

#### Examples of Tragedy of the Commons

The classic example is of a common pasture, where farmers each maintain a herd of cattle. Each farmer is incentivized to grow his herd—he gets all the benefit of the additional animal, but the cost of the animal’s grazing is shared by all the pasture owners. All farmers grow their herds as much as they can, and the tragedy arises when the pasture is destroyed and all the herds die from starvation.

Other examples include:

  * Factories dumping pollution in a nearby river or land site. They gain all the benefit of removing the waste, while bearing only a small fraction of the environmental cost.
  * Fishermen have the incentive to fish as much as they individually can, which can drive the fish species to extinction.
  * Our collective use of fossil fuels may contribute to climate change, which can lead to devastating effects in the future.



#### Fixing Tragedy of the Commons

The Tragedy of the Commons occurs because there is missing feedback between the actor’s behavior and its consequences. The solution is to tighten this feedback loop, which can be accomplished in a few ways.

The first method is to educate the actors. Help them see the effects of their usage, persuade them to moderate their behavior, and hope that they self-regulate.

The second method is to parcel out the resource so it’s no longer shared. Here, the actor owns her own share of the resource, so she bears the consequences of her behavior.

Not all resources, like river water or fish in the ocean, can be divided, which leaves the third method: **regulate the resource**. Once the rules are set, all the actors trust that all the other actors will behave responsibly. This is also known as “mutual coercion, mutually agreed upon.” Examples include:

  * As drivers, we agree with each other to obey traffic lights, even if that means we stop for other cars. This avoids the self-rewarding behavior of driving wherever you like, whenever you like.
  * Broadcasting is regulated so that no actor can transmit at a specific frequency without a permit. Without this regulation, the airwaves would be crowded with competing signals, preventing any actor from fulfilling its goal.
  * Parking spaces downtown are in high demand and are rented through parking meters. Otherwise, people would park wherever they chose, for however long they chose.



**For regulation to succeed, it must be strictly enforced to discourage rulebreakers.**

### Addiction

Also known as: dependence, shifting the burden to the intervenor

#### How It Happens

An actor in a system has a problem. In isolation, the actor would need to solve the problem herself. However, a well-meaning intervenor gives the actor a helping hand, alleviating the problem with an intervention.

This in itself isn’t bad, but in addiction, **the intervenor helps in such a way that it weakens the ability of the actor to solve the problem herself**. Maybe the intervention stifles the development of the actor’s abilities, or it solves a surface-level symptom rather than the root problem. Temporarily, the problem seems to be solved, and everyone pats themselves on the back.

But soon enough, the problem appears again, and in an even more serious form, since the actor is now less capable of solving the problem. The intervenor has to step in and help again to a greater degree. Thus the reinforcing feedback loop is set up—more intervention is required, which in turn further weakens the actor’s ability to solve it, which in turn requires more intervention. **Over time, the actor becomes totally dependent on—addicted to—the intervention.**(This is why the systems term for this archetype is “shifting the burden to the intervenor.”)

A system addiction behaves similarly to a narcotic drug causing a physical addiction:

  * Sensitization: Over time, more drug is needed to achieve the same effect.
  * Withdrawal: If the drug is withheld, painful symptoms appear.



#### Examples of Addiction

Addictions occur when well-meaning interventions undermine the system’s ability to take care of itself:

  * A farmer may try to increase his efficiency by planting a monoculture of a single crop and applying fertilizer to the soil, without developing a sustainable ecosystem. This makes the crop more susceptible to a blight. In response, the farmer applies more pesticides, which causes further destruction of the ecosystem and the ability of the field to maintain itself. Thus, more fertilizer and pesticides are needed.
  * Elder care: families used to take care of their parents, until nursing homes and social security came along to relieve the burden. In response, people became dependent on these resources and became unable to care for their parents—they bought smaller homes and lost the skills and desire to care.
  * A better healthcare system shifts the responsibility of personal healthcare away from the individual person and more toward the intervening doctor. (Shortform note: Imagine a world where a heart attack meant instant death. People would probably take better care of themselves. Once surgeries and stents are invented to rescue people from heart attacks, people feel less need to take care of themselves, which might in turn _increase_ the rate of heart attacks. And as more heart attacks occur, more medical technology is developed to support them, and so on.)
  * (Shortform example: A well-meaning parent may financially support her adult child, helping them get on their feet. However, this might weaken the child’s ability or desire to generate his own income, thus becoming even more dependent on financial assistance.)



**Policies that cause addiction are deceptive** —they are often well-meaning, seem like they solve the problem, and may have consequences that are hard to foresee (unless you map out the system).

#### Fixing Addiction

Like many of these system archetypes, **the best solution is to avoid getting addicted, or causing addiction, in the first place**.

When you intervene in a system:

  * Try to first diagnose the root cause of the issue. Why is the system unable to take care of itself? 
  * Then design an intervention that will solve the root cause, and that won’t weaken the system’s ability to take care of itself.
  * After you intervene, plan to remove yourself from the system promptly.



Once addiction takes hold, the only way to cure it is to remove the intervention and go through withdrawal. This can be done gradually or all at once, depending on how bad the withdrawal symptom is. It’s better to withdraw as early as possible—the longer you wait, the more painful withdrawal will be.

### Rule Beating

Also known as: Following the letter of the law, but not the spirit

#### How It Happens

A system has a goal, and it sets rules in place to try to achieve the goal. However, the actors in the system will try to evade the rules. They’ll find technicalities that let them stay nominally compliant but behave in a way that violates the _intent_ of the rules.

This effect gets worse when the rules are designed especially poorly, so that the evasive behavior totally contradicts the system’s goals.

#### Examples of Rule Beating

  * Departments (in government and corporations alike) are allocated budget based on what they use. If the department has budget left over at the end of the year, its budget the following year is reduced. This is a well-meaning rule to try to cut costs. However, it promotes inefficiency and wasteful spending at the end of the year.
  * Wildlife protection laws in the U.S. prevent development on land containing endangered species. So when land developers discover endangered species on their property, they often kill the animals to open up development.



#### Fixing Rule Beating

The instinctive reaction is often to strengthen the rules or enforcement. However, this usually leads to worse evasion. (Shortform note: Remember policy resistance from earlier—the harder one actor pulls in one direction, the harder the other actors pull in the opposite direction.)

The better reaction is to design better rules. Try to foresee how actors will try to evade the rules and modify rules so that they better suit the goals of the system.

### Optimizing for the Wrong Goal

Also known as: “Be careful what you wish for.”

#### How It Happens

Optimizing for the wrong goal is the conceptual opposite of rule beating. Here, a goal is defined incompletely or inaccurately, so that **progress toward the goal doesn’t lead to the desired result**.

This can happen:

  * If the goal is measured incorrectly, and the wrong metrics are optimized for
  * If the goal doesn’t reflect what the system’s stakeholders really want



A system is often so good at achieving its goal that it can march steadily toward that goal before anyone realizes they never wanted that goal in the first place.

#### Examples of Optimizing for the Wrong Goal

A common theme is confusing motion with progress.

  * If a country’s national security is defined as national security spending, you will get national security spending. You may or may not get actual national security. In fact, national security might be worse, since the defense spending detracts from investment elsewhere.
  * If education is defined as standardized test results, you’ll get standardized test results. You may or may not actually get an educated population.



##### Gross National Product

National governments fixate on gross national product (GNP) as a key metric. The higher the growth rate, the better. But GNP is woefully incomplete in describing the welfare of the population. It measures the value of the goods and services produced; it doesn’t reflect happiness in a family, the quality of our political discourse, or social equality.

Counterproductively, GNP rewards inefficiency—car accidents increase GNP through medical bills and buying new cars; a new lightbulb that costs the same to manufacture but lasts twice as long decreases GNP. GNP measures throughput (the production rates of things) rather than capital stocks (the houses, computers, and things that constitute wealth).

Imagine a world where instead of competing for GNP, countries competed for the highest ratio of capital stocks to throughput (rewarding efficiency), or for the highest healthy life expectancy.

#### Fixing the Wrong Goal

Create goals that lead to the intended result. Choose indicators that show the welfare of the system, not a narrow slice of its output. Don’t confuse motion with progress.

[[book_md/thinking-in-systems/chapter-4|chapter-4]]

[[book_md/thinking-in-systems/part-3|part-3]]

![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=c8728ae6-c184-47f9-8cc3-79e031908221&sid=48a964a0642711eeb2d9b36fc717f5e2&vid=48a9a1e0642711eebeaf23361361f0d4&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Book&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fthinking-in-systems%2Fchapter-5&r=&lt=1051&evt=pageLoad&sv=1&rn=810623)

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__



