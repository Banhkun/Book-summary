![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# Bad Science

Back to Discover

[[book_md/bad-science/preview|preview]]

  * [[book_md/bad-science|bad-science]]
  * Full Book Guide

    * [[book_md/bad-science/exercise-design-your-own-study|exercise-design-your-own-study]]
  * [[book_md/bad-science/highlights|highlights]]
  * [[book_md/bad-science/community|community]]



![](/img/tutorial-fonts.175b2111.svg)

##### Change text options

Here you can change the font, text size, and reading screen to just how you like it. 

Next

  *   *   *   *   * 


![](/img/tutorial-menu.4c76dd27.svg)

##### Table of contents

Here you’ll find everything else, including the full chapter-by-chapter guide, your highlights, PDF downloads, and book discussions. 

Next

  *   *   *   *   * 


![](/img/tutorial-player.d25b1afb.svg)

##### Audio

Every guide has an audio narration so you can listen on the go. 

Next

  *   *   *   *   * 


![](/img/tutorial-favorite.b948300a.svg)

##### Add to Favorite

Mark your favorite guides here. You can find your favorites on your homepage. 

Next

  *   *   *   *   * 


![](/img/tutorial-night.ddd7fb5c.svg)

##### Night Mode

Like a darker look when you read? Turn dark mode on here. 

Finish

  *   *   *   *   * 


Adding to Favorites 

Removing from Favorites 

## 1-Page Summary

Ben Goldacre’s _Bad Science_ is a 2008 popular science title that explains how researchers, health care companies, and mainstream media outlets use to mislead the public about medical treatments, often for profit. Goldacre is a medical doctor, a professor at Oxford University, and the author of multiple books on medicine, including _Bad Pharma, _an in-depth look into corruption in the pharmaceutical industry.

In _Bad Science_ , Goldacre offers a variety of real-world examples to show how the general public has been lied to about medical research, and how those lies have led to tragedy and death. In shedding light on these manipulative tactics, Goldacre endeavors to give his readers the knowledge they need to evaluate medical claims and research for themselves.

In our guide, we’ll examine three different stages in the process of presenting misleading medical information to the public. First, we’ll discuss how researchers manipulate the results of their studies. Then, we’ll move on to cover how health care companies misrepresent the results of the research they’ve funded. Finally, we’ll learn how low-quality science journalism spreads misinformation on a massive scale. For each stage in this process, we’ll detail the specific techniques used to mislead the public and give you the tools to identify misinformation so that you can make more informed health care decisions. We’ll also include commentary on the scientific process and updates on new techniques for spreading misinformation that have emerged since _Bad Science_ was released.

### Section One: Bad Methods

In this section, we’ll discuss the methods researchers use to manipulate their results and give you the tools to evaluate research methods yourself. Goldacre stresses that it’s important to understand and evaluate scientific literature so you can make informed health care decisions.

(Shortform note: Goldacre stresses the importance of improving your own science literacy. However, some studies argue that because low science literacy is a systemic problem, it requires systemic solutions. These studies suggest that the best way to combat scientific misinformation is by increasing the quality of K-12 science education rather than asking adults to educate themselves.)

Scientific trials should be evaluated on their methods, not their results. As we’ll show, by using manipulative methods, it’s possible to engineer whatever result you want. These kinds of manipulations often happen because of the economic pressure to produce and market new treatments. According to Goldacre, most medical research is funded by pharmaceutical companies, who in turn pressure researchers to produce results that help them get their drugs to market.

(Shortform note: The situation Goldacre describes, in which the majority of medical research is funded by companies with vested interests, may only be escalating. Experts note that in recent years, government and nonprofit medical research funding has declined dramatically. Since Goldacre authored _Bad Science_ in 2008, the research landscape has become even more dominated by corporate interests.)

There are a few main ways researchers manipulate results. These include **insufficient experimental controls, inadequate blinding, and inadequate randomization**. In this section, we’ll illustrate how these methods can shape research results. We’ll also give you the tools to call out these errors when you see them.

#### Experimental Controls Shape Results

Goldacre explains that scientific studies are designed to test one treatment at a time, without any influence from other factors. To do this, **good researchers make use of experimental controls** , which are elements of a study’s design that are put in place to prevent specific factors from influencing results. By contrast, some researchers use weak experimental controls to manipulate their results.

(Shortform note: The practice of running experiments with controlled variables is called the scientific method. Scientists believe that the scientific method is what distinguishes scientific knowledge from other types of knowledge, such as the knowledge contained in philosophical treatises or religious texts. This doesn’t mean that these other kinds aren’t useful and meaningful. It simply means that _only_ knowledge produced in controlled experiments can be considered scientific.)

All scientific experiments involve a control subject and a test subject. Ideally, your control and test subjects should be identical in every way _except_ for the variable you’d like to test—in the medical field, this variable is usually a medical treatment.

Let’s demonstrate this with an example. Suppose you’re designing an experiment to test the effect of direct sunlight on pea plants. It wouldn’t be enough to simply put a pea plant in the sun and observe it, because you’d have nothing to compare it to. To really see how the sun affects plants, you’ll need at least one other plant, kept in a relatively dark location. Then, measuring against your control plant (the one kept in darkness), you’ll be able to evaluate the growth of your test plant (the one kept in the sun).

Of course, in the real world it isn’t possible to completely control variables. Researchers make decisions based on practicality, funding, ethics, and other factors. (For example, in our pea plant experiment, the different rooms in your house might be at slightly different temperature and humidity levels. Unless you were willing to spend lots of money remodeling your house, you’d be limited by money and practicality, just like a real researcher.)

(Shortform note: Experts note that one reason medical studies aren’t able to completely control variables is that health care and human bodies are both complex systems. Because these systems include so many variables, small differences in treatment as well as in patients’ bodies can lead to different medical outcomes. Even though many of these variables are difficult to spot, they can still have a huge impact on a study’s results.)

##### Spotting Bad Experimental Controls

Because controlling variables can be a complex process that includes compromise, you should carefully evaluate the studies you read. Studies that show a high level of detail and thorough commitment to controlling as many variables as possible are likely to be trustworthy. The best studies are aware of their own flaws and may even go so far as to suggest future methods that would improve those flaws.

By contrast, if a study doesn’t spend much time discussing how variables were controlled, Goldacre says you should take the study with a grain of salt. Its findings might be meaningful, but they might just as easily be the result of a variable the researchers conveniently left out.

(Shortform note: Lack of experimental controls isn’t always a bad thing. As experts describe, some studies don’t include experimental control because of the natural limitations of their experiments. For instance, in a study on the longevity of smokers as compared to nonsmokers, it’d be impossible to control aspects of the participants’ lives such as diet and exercise. However, researchers could still generate useful data from observing and comparing the two groups.)

#### Blinding and the Placebo Effect

Furthermore, Goldacre argues that some researchers manipulate their studies by allowing participant and researcher expectations to skew results due to the placebo effect.

The placebo effect is a phenomenon in which the strength of a medical treatment is affected by both the patient’s beliefs about the treatment and the doctor’s beliefs about the treatment. Because of the placebo effect, **when you believe you’re receiving a more effective treatment, your health improves more** than when you believe you’re getting an ineffective treatment, even if the treatments are identical. Similarly, when doctors believe they’re giving an effective treatment, their patients tend to improve more than when they believe they’re giving an ineffective treatment.

(Shortform note: While physicians have long understood that the placebo effect can improve patient outcomes, nobody knows why placebos work. New research shows that placebos cause increased activity in specific regions of the brain, such as the frontal lobe. Studies have also shown that placebos cause the brain to release chemicals that are linked to mood and mental health. While these results don’t fully explain how the placebo effect works, they make it clear that a complex, neurological reaction is involved.)

According to Goldacre, good studies make use of a technique called blinding to prevent the placebo effect from influencing their results. Blinding is the practice of keeping participants and administrators unaware of which treatment each participant receives. By keeping participants and those administering treatments in the dark, **blinding ensures that no group of participants will be more influenced by the placebo effect** than any other group.

> **Double Blinding and Single Blinding**
> 
> It’s important to note that there are two main types of experimental blinding, each with its own benefits. The type of study Goldacre describes, in which both participants and administrators are blinded, is commonly known as a double blind study. However, in some studies (called “single blind” studies), only participants are blinded, and administrators know which treatment each patient receives. While double blind studies are better at minimizing the placebo effect’s impact on results, single blind studies are often cheaper and easier to conduct.
> 
> Additionally, in some situations, it may not be possible to completely blind either group. For instance, in a study about the effects of exercise on a certain condition, participants will always know whether they exercised. Even well-intentioned researchers may have to compromise on blinding practices due to logistical and financial reasons.

##### Spotting Bad Blinding

Examining a study’s blinding practices can help you determine whether that study is trustworthy. Specifically, in trustworthy studies, all treatments should be administered in the same way to help ensure that participants all have the same expectations for their treatments. For example, if one group receives an experimental drug in the form of an injection to the arm, the group receiving the control drug should be given that drug by an arm injection, too. Furthermore, treatments should not be given by the researchers who designed the study. As you read a study, check to see if the study’s authors brought in outsiders to administer treatments. If they didn’t, their blinding practices may not have been thorough enough.

(Shortform note: In addition to blinding participants and researchers, researchers also recommend blinding the analysts in charge of interpreting the study’s data. Analysts who aren’t blinded may be tempted to present or interpret the data more favorably to make their studies seem more successful. When you read a study, be sure to take note of who compiled the data—it’s a red flag when researchers handle all their data by themselves.)

On the other hand, if a study’s description of its blinding methods is short, vague, or absent, take it as a red flag. By withholding this information, the study’s authors deny you the tools you need to evaluate their claims.

(Shortform note: As a tool for evaluating their own blinding methods, experts recommend that researchers ask participants whether they think they received the placebo or the real treatment. If most participants are able to guess which treatment they received, this may indicate weak blinding practices. When reading studies, you should check to see if researchers have made an attempt to analyze whether their blinding methods were successful. It’s a good sign when they use these kinds of tools and report the results.)

#### Randomization and Researcher Bias

In addition to weak blinding, Goldacre describes how **unscrupulous researchers manipulate results by strategically sorting participants into different groups**. For instance, if you wanted to make your new drug seem more effective than it is, you could decide to give your drug to the patients who were healthiest and most likely to improve anyway, while giving the standard treatment to the patients in the worst condition.

(Shortform note: Scientists refer to the influence of poor selection and sorting methods as selection bias. Experts note that even when researchers don’t intentionally manipulate their trials, weak methods can allow selection bias to affect a trial’s results.)

To prevent these kinds of manipulations, scientists use a process called randomization. Goldacre describes randomization as **the process of randomly determining which treatment a patient receives**. By assigning participants randomly, you can prevent any one group from unfairly receiving only the participants that are most likely to succeed.

(Shortform note: Randomization has many additional benefits. Researchers argue that randomized trials are especially useful for determining causal relationships. This is because randomized trials ensure that the only differences between different groups are the treatments they receive. As a result, any differences in the results of different groups can be confidently chalked up to the treatment each received.)

##### Spotting Bad Randomization

There are a few different shady randomization practices to look out for when evaluating research. Specifically, Goldacre is skeptical of the practice of assigning treatments based on the order that participants sign up for the trial. In a system like this, the first 10 participants to sign up might get treatment A, while the second group of 10 all get treatment B, and so on. While on the surface, this procedure might seem random, it leaves a lot of room for recruiters to influence results. For example, if you know that the next patient you recruit will be placed into the group testing your new treatment, you might choose a patient who you think is likely to get well anyway—when they do, it’ll appear as though your treatment worked.

(Shortform note: In addition to looking out for randomization methods based on signup order, you should also ask yourself if each group of participants is large and varied enough to accurately generalize to larger populations. For example, a study with only five participants is unlikely to contain enough variety to be compared to larger populations. However, a study with several thousand participants is more likely to produce more comprehensive findings.)

Goldacre notes that some researchers manipulate their studies by randomizing patients based on factors that more subtly affect results. For instance, suppose you come up with a randomization strategy that sorts participants into groups based on ZIP code. While this seems random, some ZIP codes might contain more affluent neighborhoods, where residents can generally afford better health care. If these more affluent patients were all sorted into the same treatment group, it might make that treatment seem more effective than it really is.

(Shortform note: These kinds of differences between the general population and the participant group used in an experiment are known as random sampling error. All studies include some degree of sampling error. While in our example the sampling error was due to intentional manipulation, sampling error is often a natural consequence of an experiment’s logistical limitations—no group of people small enough to study will ever be perfectly representative of the world’s population.)

By contrast, **good randomization methods have little room for bias to influence results**. It’s a good sign when researchers describe keeping their recruiting processes and their treatment assignment processes separate. This prevents recruiter bias from interfering with randomization. Additionally, Goldacre states that studies that use randomization software are also likely to be trustworthy—using computers for randomization reduces the effects of human bias and error.

(Shortform note: One issue that makes it hard to judge whether randomization methods have affected a study is that even strong randomization practices sometimes produce unbalanced groups. For example, suppose you flip a coin five times in a row. While it’s unlikely, if you did this enough times, you’d eventually get heads five times in a row. To account for unlucky failures in randomization, as well as other factors, the scientific method emphasizes reproducibility. Generally, you should only consider a trial’s results to be reliable if researchers can reproduce the same result when conducting the experiment a second time.)

### Section Two: Bad Claims

Moving on from the level of individual studies, in this section we’ll learn how the alternative and mainstream**health care industries use a variety of techniques to overstate the effectiveness of their treatments**. As Goldacre notes, it’s important to identify and call out these techniques because companies sometimes use them to push ineffective, dangerous treatments to market. When you’re able to evaluate research results yourself, you can make more informed decisions and inform others, too.

The main strategies companies use to make their treatments seem more effective are**selective publishing, cherry-picking positive results, and exaggerating based on surrogate outcomes.** In this section we’ll explain how these techniques are used to make treatments seem more effective than they are and to conceal their sometimes dangerous side effects. As we describe these techniques, we’ll also give you the tools to spot them.

> **Marketing Drugs, Marketing Diseases**
> 
> While Goldacre focuses on the techniques drug companies use to deceptively market their treatments, there’s another part of the process that isn’t addressed here. In addition to marketing drugs, pharmaceutical companies also produce and market diseases.
> 
> In order to open up new market niches, companies create new conditions by scaremongering about normal body functions. Generalized symptoms such as tiredness, back and body aches, and stress can be used to sell the public on the need for new supplements and other treatments.
> 
> Researchers have described recent disease awareness campaigns about low testosterone levels in older men as examples of this phenomenon. While it’s perfectly natural for testosterone levels to decrease with age, pharmaceutical companies were still able to increase their sales by drumming up a scare.

#### Publish the Good, Bury the Bad

Goldacre argues that in order to make their treatments seem more effective, **companies only publish results when their treatments perform well, and they actively conceal negative results**. This is commonly referred to as publication bias. For instance, if a company conducts three trials for a new drug, and the drug only performs well in one of them, that company could choose not to publish the other two studies. By hiding these crucial pieces of data, the company makes its treatment seem more effective than it really is.

(Shortform note: As Goldacre describes, publication bias often occurs because drug companies want their drugs to sell. However, some researchers believe that journal editors may also be responsible for publication bias, even in credible, peer-reviewed journals. In order to sell subscriptions and stay relevant, editors may seek out studies in which new treatments were shown to have strong effects, as these kinds of advancements are seen as more exciting for readers.)

As an example, Goldacre notes that when selective serotonin reuptake inhibitors (SSRIs) were being researched as a treatment for depression, pharmaceutical companies buried multiple studies in which SSRIs were shown not to work better than placebos. By hiding these lukewarm studies, the pharmaceutical industry was able to make sure SSRIs made it to market as quickly as possible.

(Shortform note: While these early studies of SSRIs reported that they vastly outperformed placebos in treating depression, more recent studies have shown that SSRIs only outperform placebos by a small margin. One possible explanation for this change is that publication bias in earlier studies made SSRIs seem more effective than they really are. However, researchers have noted that depression is now more widely diagnosed than it used to be, and that this may have also impacted results. According to this argument, because milder cases of depression are now treated with SSRIs, the relatively small impact of treatment in those cases may help explain the small clinical impact of SSRIs in general.)

In addition to omitting mediocre results, drug companies sometimes hide results that show that their products cause harm. In particular, Goldacre references Vioxx, a painkiller that was marketed from 1999 to 2004. The company that manufactured Vioxx hid evidence that Vioxx caused an increased risk of heart attack and pushed the drug to market anyway. Goldacre estimates that Vioxx caused tens of thousands of heart attacks in its brief time on the market. It’s important to understand and identify bad science, because, as illustrated here, **when drugs are pushed to market irresponsibly it can cause tremendous harm**.

(Shortform note: In addition to drug companies, irresponsible regulators may also play a part in allowing dangerous drugs to reach consumers. For example, the chairman of the safety board tasked with evaluating Vioxx owned tens of thousands of dollars of the company’s stock. This clear conflict of interest created a financial incentive for irresponsible behavior.)

##### Spotting Publication Bias

To spot publication bias, Goldacre recommends analyzing as many studies as possible when evaluating any given treatment. In general, studies with larger sample sizes and better funding should generally agree with each other. Their large sizes and superior methods tend to produce more consistent results. By contrast, the smaller studies should naturally produce a wider range of results due to their smaller sample sizes. If the smaller studies all agree with each other, it may be a sign that some studies have been omitted.

(Shortform note: Some statisticians argue that comparing results may not be a useful tool for spotting publication bias. According to this argument, small studies might agree with each other for many reasons that are unrelated to publication bias. Furthermore, some researchers don’t feel we need to test for publication bias at all—they argue that because it’s such a widespread problem, you should _always_ assume publication bias is present.)

#### Cherry-Picking Positive Results

In addition to trying to control which research gets published, **companies cherry-pick results,** referencing only positive results and ignoring or dismissing negative ones.

(Shortform note: In addition to cherry-picking which studies they reference, drug companies and researchers also cherry-pick within individual studies.). Within single studies, researchers cherry-pick by only including data that supports their treatments.)

Goldacre notes that cherry-picking is especially common in alternative medicine. For example, while the vast majority of medical literature states that homeopathic treatments are no more effective than placebos, homeopaths tend to cherry-pick from the few studies that support their practices. When confronted with studies that contradict their claims, cherry-pickers will dismiss them, claiming that those studies used flawed methods. By contrast, they’ll often choose to ignore the methodological flaws in the studies that support their treatments.

(Shortform note: Responding to these criticisms, some homeopaths point out that similar cherry-picking exists in conventional medicine. While cherry-picking is also a problem in conventional medicine, this doesn’t mean that alternative medicine is any better or worse. Instead, it implies that both the conventional and alternative medical industries are plagued by similar problems.)

As an example, Goldacre describes how companies and government officials used cherry-picking to promote ineffective treatments during the height of the AIDS epidemic in South Africa. According to Goldacre, a vitamin company led by Matthias Rath made widespread claims throughout South Africa that vitamins were more effective for the treatment of AIDS than antiretrovirals (the type of drug typically prescribed to treat AIDS). These claims were based on unscientific, unpublished trials conducted by Rath himself, and they contradicted the overwhelming scientific consensus that antiretroviral drugs are an effective treatment for AIDS patients.

(Shortform note: In addition to making claims based on his own, unpublished trials, Rath also referenced medical studies that didn’t actually exist. The few legitimate studies he referenced showed that vitamins could improve outcomes when taken alongside antiretrovirals, not that vitamins should be taken _instead_ of antiretrovirals.)

Due to their own biases, South African government officials cherry-picked Rath’s results and used them to justify the decision not to roll out antiretrovirals across South Africa. Instead, Rath’s ineffective vitamin treatments were promoted nationwide.

(Shortform note: The South African government choosing to accept Rath’s findings is an example of confirmation bias. Confirmation bias is a logical fallacy that leads you to accept new information only when it reinforces your prior beliefs. Left unchecked, confirmation bias can lead directly to cherry-picking.)

What was profitable for Rath was tragic for the people of South Africa—Goldacre estimates that hundreds of thousands of people died due to lack of access to antiretrovirals. This tragedy illustrates why it is so important to be able to call out bad science. **When we allow companies to use misleading techniques to promote their treatments, real people suffer for it**.

(Shortform note: During the Covid-19 pandemic, medical treatments became a similarly divisive issue in the United States. Some politicians and doctors widely promoted ivermectin as a treatment for Covid, even though few studies supported it. While some believe ivermectin is an effective treatment, its unauthorized use has also led to several accidental poisonings.)

##### Accounting for Cherry-Picking

To account for cherry-picking, Goldacre says you never take a single study’s results to be the final word. Instead, look up multiple studies about the topic in question, and evaluate each one’s methods. When you’ve determined which studies you think are most trustworthy, compare their results. While they’ll probably differ from each other slightly, they’ll give you a range of reasonable perspectives. New information that falls well outside this range may be cherry-picked.

(Shortform note: To protect yourself from cherry-picking, experts recommend that you remain skeptical about new evidence. This doesn’t mean ignoring new findings, but it does mean you should thoroughly investigate them. In particular, you should be suspicious of studies that don’t use diverse sample groups—for example, if all participants are the same age—as they may not be giving you the complete picture.)

##### Meta-Analysis Counteracts Cherry-Picking

When evaluating treatments, scientists also compare research results, using a tool called meta-analysis. A meta-analysis collects, compares, and summarizes all the published studies about a particular topic. By looking at all the data at once, meta-analysis can often reveal patterns that aren’t apparent in individual studies.

For example, suppose that multiple small studies show that a new cold medicine offers mild benefits. In individual studies, the benefit appears so slight that it’s not taken to be significant. However, if you combined the sample sizes of all these studies, you’d be able to get a clearer, more reliable picture of the medication’s effects, based on a larger body of evidence.

If you’re worried about cherry-picking, try to find a meta-analysis of the treatment you’re investigating. The many sources included in a meta-analysis ensure that a few strategically chosen studies don’t overpower the rest.

> **Problems With Meta-Analysis**
> 
> While meta-analysis _can_ be a powerful tool for counteracting cherry-picking, meta-analyses can also fall victim to many of the same problems as regular clinical trials.
> 
> One problem is that it takes a lot of labor to evaluate a meta-analysis’s methods. To produce a meta-analysis in the first place, researchers must seek out and painstakingly assess many studies to determine if they’re solid enough to be included. When editors are determining whether or not to publish a meta-analysis, they have to repeat the same time consuming process. Because the process of evaluating a meta-analysis’s methods is so arduous, editors may make mistakes or cut corners, which can in turn lead them to publish sub-par meta-analyses.

#### Overstating Results Using Surrogate Outcomes

Lastly, drug companies often exaggerate the effectiveness of their treatments based on surrogate outcomes. **A surrogate outcome is an experimental result that implies a treatment _may_ work, but doesn’t indicate conclusively if the treatment works or not**. It’s important to identify surrogate outcomes because they’re often used to push unproven and potentially dangerous drugs to market.

(Shortform note: In some cases, scientists _do_ consider surrogate outcomes to be acceptable stand-ins for real-world outcomes. However, this is only true when there’s a strong, proven link between the surrogate outcome and patient outcomes. For instance, because lowering blood pressure has been shown to reduce the risk of stroke, drugs that lower blood pressure can be said to reduce stroke risk.)

For example, suppose you’re testing a new drug designed to treat infection. You find that in petri dishes, your drug successfully kills bacteria. Based on this finding, it’d be easy to jump to the conclusion that your drug can be used to fight bacterial infections. However, to be sure, you’d also want to measure whether or not real, human patients receiving your treatment actually experienced improved outcomes. In this case, the petri dish test result is the surrogate outcome—it suggests that your drug works as intended, but it isn’t conclusive on its own.

##### Spotting Surrogate Outcomes

**You can better assess a company’s claims when you’re able to identify surrogate outcomes**. Specifically, you should look out for claims that reference blood test results, experiments done with cells in petri dishes, and experiments performed on lab animals. These are all surrogate outcomes. When you come across them, take them as a suggestion that a treatment _might_ work, and not proof that the treatment actually _does_ work. By contrast, if a company offers results in terms of real-world outcomes, such as heart attacks or deaths, you can take the study’s findings more seriously.

(Shortform note: When you notice that a study’s findings include surrogate outcomes, it can be helpful to look up whether they’re considered acceptable stand-ins, so that you know how seriously to take them. The FDA has produced a comprehensive table that includes all the surrogate outcomes that it has allowed researchers to use as evidence for their drugs. If a study’s surrogate outcomes are listed in this table, it’s a good sign that you can take them seriously.)

### Section Three: Bad Press

In this final section, we’ll cover the various ways mainstream media outlets misrepresent scientific findings to the public. According to Goldacre, errors in science reporting usually happen because publications prioritize profit, which leads them to pressure their reporters to generate the most exciting stories they can as quickly as possible. This pressure leads reporters to choose sensational stories, and leaves them little time to verify the accuracy of their reporting.

(Shortform note: As opposed to the profit motive, journalists argue that one of the main reasons for their errors is that they often have to report on evolving events. Journalists describe trying to balance getting information out quickly with taking enough time to gain a complete understanding of a topic. Naturally, they argue, this process involves some mistakes.)

Goldacre argues that it’s important for publications to accurately report medical findings because of their unique role in spreading ideas. Misinformation can undermine public health campaigns and lead individuals to make dangerous health care decisions.

(Shortform note: Many journalists would agree that they have an ethical responsibility to report accurately, especially when writing about medical issues. Interestingly, journalistic codes of ethics often include the imperative to minimize harm—a sentiment echoed by the Hippocratic Oath, which is the cornerstone of medical ethics.)

There are a few major ways journalists tend to misrepresent scientific studies. Specifically, **publications fail to evaluate their sources, sensationalize results, and fail to correct their mistakes by publishing retractions and updates**. We’ll describe how all these practices can be used to mislead the public, and we’ll give you the tools to identify shoddy science reporting.

#### Bad Sources, Bad Stories

According to Goldacre,**journalists often fail to properly vet the scientific sources they reference**. When journalists use untrustworthy sources, they risk presenting misleading and potentially harmful information to the general public.

Goldacre argues that one of the main reasons journalists end up using weak sources is because most journalists aren’t scientists, and they lack the training to evaluate medical research. Even though mainstream publications often employ a few science reporters with more specific expertise, major stories tend to be assigned to higher-ranking general journalists instead.

(Shortform note: One reason general journalists may have a hard time reporting on science is that scientific results are often uncertain. As compared to current events, where there is a clear chain of events to report, scientific findings often suggest more tentative links. General journalists who are unfamiliar with these nuances tend to overstate inconclusive findings.)

However, Goldacre asserts that regular people can learn to evaluate scientific sources with a little work. The issue isn’t that journalists aren’t capable of understanding science, but that low industry standards and the pressure of deadlines disincentivize journalists from doing so.

(Shortform note: Journalists themselves corroborate Goldacre’s assertion that high-pressure environments in journalism are a systemic problem. Studies show that the vast majority of journalists experience trauma and burnout on the job. Without reforms in journalism, these stressful environments may continue to lead to mistakes in reporting.)

##### Spotting Bad Sources

When you read science stories in mainstream media outlets, you should investigate their sources. Once you’ve found the studies an article references, you can **evaluate them yourself using the techniques we’ve developed in this guide**. And, as Goldacre sees it, if an article doesn’t link to its sources, it probably isn’t trustworthy.

It can also be helpful to research the authors of the articles you read. Look into the author’s background and other work. If they have a science background and focus primarily on science reporting, it’s more likely that they have the right tools for the job. On the other hand, if the author of an article has no science background and reports mostly on other topics, it may be a sign that you should investigate their claims more thoroughly.

(Shortform note: In addition to looking into the backgrounds of science journalists you come across, you can also seek out trustworthy scientists on your own. Since the advent of social media, many scientists have taken to the internet to share their findings. Taking it on yourself to identify and follow reliable sources can help ensure you have access to accurate information.)

#### Sensational Stories

Furthermore, **journalists misrepresent scientific information to the general public by sensationalizing clinical findings**. Goldacre notes that this isn’t unique to science journalism, but is a more general problem with journalism. To maximize readership and revenue, publications often encourage their reporters to write shocking, provocative stories, even if it means exaggerating. However, because science journalism impacts public health, sensational science reporting can cause significant harm.

(Shortform note: While Goldacre primarily blames the media for sensationalizing science, some members of the scientific community argue that scientists themselves may be equally to blame. Seeking to bring themselves acclaim and notoriety, researchers and institutions may exaggerate their findings to the media.)

As Goldacre describes it, journalists tend to focus on scary findings because they’re seen as better attention grabbers. For instance, stories about common household chemicals causing cancer are more likely to attract readers than stories about incremental advancements in treating lactose intolerance. It isn’t inherently misleading to publish frightening stories, as long as those stories are accurate, but sadly this isn’t always the case.

(Shortform note: While scary stories may benefit publications in the short term, they may have negative impacts in the long run. Studies have shown that sensational stories cause consumers to become distrustful and apathetic toward news media, leading them to consume less news. At scale, growing distrust in news media likely hurts circulation for many publications.)

##### Spotting Sensationalism

If you think a certain publication is exaggerating in order to play upon your fears, look into the rest of their health and science reporting. If they tend to publish only negative, frightening stories, they probably aren’t giving you all the information.

Additionally, you should **pay close attention to the way journalists report statistics**. Often, stats are presented misleadingly to make research results sound more dramatic than they really are.

(Shortform note: Misleading statistics are not unique to science journalism. Business leaders note that issues with stats are rampant in the business world. As in science, these errors are usually due to the financial interests of researchers and journalists. It’s simply more exciting to readers to publish a story about dramatic success or failure, in both science and business.)

Specifically, Goldacre notes that journalists tend to reference relative risk increase out of context. Relative risk increase is the percentage increase in risk of a certain phenomenon. Citing relative risk increase without including hard data, such as case numbers and death counts, can make small increases in risk appear very large.

For example, suppose that a new treatment causes appendicitis risk to go from one patient per thousand to two patients per thousand. Expressed in terms of relative risk, that’s an increase of 100%, which sounds a lot scarier than an additional one case per thousand patients. Because of this effect, if an article references relative risk, you should refer back to the article’s sources and check the numbers out yourself.

(Shortform note: Because of the misleading nature of relative risk increase, some researchers recommend ignoring risk increase entirely. Instead, they argue that you should focus only on the hard numbers that affect patients, such as clinical outcomes and cost.)

#### Rare Retractions

Finally, Goldacre laments that **when journalists publish findings that are later proven to be false, they rarely publish retractions** that include new evidence. Because of the potential impact of journalism on public health, Goldacre argues that media outlets have an ethical obligation to provide accurate, up-to-date information.

(Shortform note: Some studies have found that journalists only publish retractions when researchers make a press release detailing how their findings have changed. These studies suggest that when retractions are necessary, researchers may be able to help the process along by reaching out to journalists directly and making press releases.)

The panic over the MMR vaccine is a perfect example of the real-world consequences that can occur when journalists don’t take it upon themselves to publish retractions. As Goldacre recounts, in the early 2000s, British journalists published numerous articles about the supposed link between the MMR (measles, mumps, and rubella) vaccine and autism. These stories were based on the results of a single study, which used poor experimental controls and relied on surrogate outcomes. While the study in question was later discredited due to its shoddy methods, few publications published retractions. As a result of the ensuing panic over the MMR vaccine, vaccination rates in the UK plummeted, leading to waves of preventable illness and death.

(Shortform note: Even when publications do publish retractions, it often happens years after the damage has been done. One publication involved in the British MMR scare launched an admirable campaign to promote the MMR vaccine. This 2019 campaign likely saved lives by encouraging vaccination, and had it been published sooner, it could have saved many more.)

##### Accounting for Missing Retractions

When you read an article, you should check to see when it was published, and even more importantly, you should check to see when the studies it references were published. Scientific research is an ongoing process, and results from just a few months ago may have already been overturned. Because of this, **you should try to find the most recently published research into any particular subject**. That way, you can be sure you’re up to date on the most effective treatments.

(Shortform note: While it may seem daunting to continually keep up to date on new findings, openness to new evidence is part of what makes the scientific method reliable. To account for constant change, remember that science is an ongoing process, and be ready to change your opinion when necessary.)

[[book_md/bad-science/preview|preview]]

[[book_md/bad-science/exercise-design-your-own-study|exercise-design-your-own-study]]

##### Welcome!

Let’s go on a quick tour of a Shortform book guide. 

Start

##### 1-Page Summary

Every guide starts with a 1-Page Summary. This is a 5-10 minute overview of the book’s key points. 

Next

##### Finished!

If you ever need to see this tour again, click here. 

Close

Guided Tour

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__




![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=4ab6465b-c7df-46a3-b504-86849d9f14ef&sid=201ffde0635411ee902411d77b750559&vid=20202bf0635411ee9ac03f2e618b0b9f&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Bad%20Science&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fbad-science%2F1-page-summary&r=&lt=509&evt=pageLoad&sv=1&rn=156159)
