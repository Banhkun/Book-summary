![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# The Righteous Mind

Back to Discover

[[book_md/the-righteous-mind/preview|preview]]

  * [[book_md/the-righteous-mind|the-righteous-mind]]
  * Full Book Guide

    * [[book_md/the-righteous-mind/introduction|introduction]]
    * [[book_md/the-righteous-mind/part-1|part-1]]
    * [[book_md/the-righteous-mind/chapters-3-4|chapters-3-4]]
    * [[book_md/the-righteous-mind/exercise-identify-your-press-secretary|exercise-identify-your-press-secretary]]
    * [[book_md/the-righteous-mind/part-2|part-2]]
    * [[book_md/the-righteous-mind/exercise-find-your-foundations|exercise-find-your-foundations]]
    * [[book_md/the-righteous-mind/chapter-8|chapter-8]]
    * [[book_md/the-righteous-mind/exercise-build-a-good-political-advertisement|exercise-build-a-good-political-advertisement]]
    * [[book_md/the-righteous-mind/part-3|part-3]]
    * [[book_md/the-righteous-mind/chapter-10|chapter-10]]
    * [[book_md/the-righteous-mind/chapter-11|chapter-11]]
    * [[book_md/the-righteous-mind/chapter-12|chapter-12]]
  * [[book_md/the-righteous-mind/highlights|highlights]]
  * [[book_md/the-righteous-mind/community|community]]



Adding to Favorites 

Removing from Favorites 

## Chapters 3-4: Intuition First, Reasoning Second

**The last section demonstrated that we respond to stimuli first with our intuition and then use reasoning later to justify our response. This section will deepen that understanding and provide examples of why and how this happens.**

We’ll begin with intuition and move on to reasoning.

### Intuition First

In addition to Haidt’s experiments, there’s ample evidence that intuition comes before reasoning:

  1. **Our brains are instantly evaluating:** Every time we see something, we have what’s called an “affect” reaction. From something as simple as reading a positive word, like “happiness,” we get a little bit of positive effect. This sort of feeling is the first process that humans developed evolutionarily—thinking came second.
  2. **All of our social or political judgments are intuitive:** People have immediate and intense reactions when they see social groups. Most people have implicit biases against certain groups as well—think of it like the elephant seeing something and leaning away. This doesn’t have to do with any reasoned morality. For example, most younger people are biased towards the elderly, but not based on a moral reason—they have inherent biases against people who aren’t like them who they cannot understand. The same is true with politics—when conservatives see the name of a liberal president, they have an immediately negative reaction. When liberals see the name of a conservative president, they also have a negative reaction. 
  3. **Our bodies influence our judgment:** For example, seeing, tasting, or smelling something disgusting can make us judgmental. A grad student at Stanford tested this theory by giving people a questionnaire to fill out about their opinions on controversial issues. One group of respondents answered in a place that smelled bad and another did not. The group that filled out the questionnaire in the room that smelled bad gave much harsher opinions on the issues. The reaction to the smell was pure intuition and overpowered respondents’ reason. 
  4. **Psychopaths can reason but can’t feel:** When the elephant isn’t functioning properly, it’s difficult to be a productive member of society. Psychopaths have some emotions but don’t have empathy for others. This allows them to break all kinds of social contracts that bind society together, as they don’t care about torturing or killing others. The rider functions fine, but the elephant doesn’t respond. In basing their moral judgments only on reason, psychopaths often break basic social contracts that require people to make decisions based on emotion. 
  5. **Babies can feel but can’t reason:** Experiments prove that babies, while they can’t yet reason, have an innate understanding of their environment. They’ll stare at something longer if it appears to be physically impossible, like a car traveling through a wall. They can understand social interactions as well. If shown a puppet show with three puppets, one puppet helping another trying to get up a hill and a third puppet trying to stop them, babies will register surprise when one of the puppets attempting to get up the hill befriends the hinderer. By the time they are six months old, infants develop a _preference_ for people who are nice to others, outside of their own needs. 
  6. **Affective reactions happen in the right place, right time:** The famous “trolley problem” (you are told that pushing one person to his death will save five lives) pits utilitarianism against deontology. Utilitarianism suggests that you should push because you are doing an overall good. Deontology says that you have a duty to others’ individual rights to not push. The truth of the matter is deontology generally comes from a gut feeling, where utilitarianism is more calculating, based on reason. Studies show that areas of the brain involved with emotional processing activate immediately when exigent harm is involved. We feel strongly that certain actions are okay and others are not, and when immediate harm is involved our brain reacts to those feelings, making it unlikely we’d push someone into harm’s way in the moment.



The bottom line is that **when we see or hear anything in the world, the elephant, emotion or intuition, reacts right away** , before reason has a chance to.****

### Reasoning Second

There are, though, _certain****_ cases when reason can make us revise our intuition, so reason might not be a _total slave_ to passion. **The elephant is more powerful, but not _all-_ powerful.**

  * We mostly change our minds on questions of morality by interacting with others. Someone else can more easily poke holes in our logic than we can. This is especially true if there’s affection between the two parties. **If we like someone, we’ll be more willing to attempt to find truth in what they are saying.** This can lead to a changed mind.****
  * There are also times when we have _conflicting intuitions._ The elephant wants to lean two different ways at once. We start off by following one intuition and then change our own mind, but generally only if we had conflict within ourselves from the start. 
  * It’s also possible, though rare, for someone to reason themselves to a different conclusion. Studies show this happens if we _have****_ to sit and think about our own arguments before answering a question. We can reason a counterargument to our intuition, but only if we have time to do so. 



#### Intuitive Politicians

In Plato’s _Republic,_ Glaucon—a Greek philosopher and Plato’s older brother—argues that it is the _appearance_ of justice that keeps us just, rather than any actual justice. In contrast, Socrates argues we should always act based on reasoned justice. Socrates says that a truly just city has to have a philosopher-king who can divine right from wrong. Socrates is the hero of the book, but according to Haidt, it’s Glaucon who’s right.

We are all constantly acting like _intuitive politicians._ We’re guided by intuition but concerned with justifying our actions so that others like and trust us. Appearance in social situations like a workplace matters more than reality.

When people know they’ll have to justify a decision, they’re more self-critical and willing to revise their beliefs when presented with different evidence. Essentially, this is because people respond to outside social pressures. We’re looking for confirmation from the group that we’re right.

There are five examples that indicate that morally, we think much more like a politician trying to win over constituents than a scientist in search of truth:

  1. **We are fascinated by polling data (of ourselves):** Experiments show that no matter how much someone says they don’t care what others think of them, their self-esteem will plummet when told that strangers don’t like them and will rise rapidly when told strangers do. On an _unconscious_ level, we’re constantly measuring our social status. The elephant part of the mind is concerned about what others think of us, even if the “rider,” the rational mind, isn’t. 
  2. **We all have a “press secretary,” constantly justifying everything:** In other words, we all have confirmation bias and are constantly on the hunt, like a press secretary, for evidence that justifies our way of thinking. Simultaneously, we ignore anything that might challenge it. Research shows that people with higher IQs can generate more arguments to support a viewpoint, but _only for their own side.****_ As soon as the elephant leans in a direction, the rider starts looking for reasons to explain it. 
  3. **We rationalize cheating and lying so well that we can convince ourselves we’re honest:** Like politicians, when given the opportunity and plausible deniability, most people will cheat but still believe that they are virtuous. They cheat up to the point where they can no longer rationalize the cheating: In one study, when a cashier handed a subject more money than she was due, only 20% of the subjects corrected the mistake—because they were passive participants in the transaction, they could reconcile keeping the extra money with the belief that they were honest people. However, when the cashier asked if the amount was correct, 60% of people corrected the cashier’s mistake and gave the extra money back—in this case, it was harder to deny responsibility for the mistake because the cashier directly asked them about it.
  4. **We can reason ourselves into any idea:** If we _want_ to believe in something, we ask, “Can I believe it?” and look for reasons to believe. As soon as we find a piece of evidence, even if it’s weak, we stop searching and feel justified in that belief. On the other hand, if we _don’t_ want to believe something, we ask, “Must I believe it?” and look for reasons not to. If we find even one piece of counterevidence, we feel justified in not believing it. In sum, unlike scientists, who generally change their theories in response to the strongest evidence, most people believe what they want to believe.
  5. **We believe any evidence that supports our “team”:** This is why people don’t vote based on their self-interest. Rather, people care about their groups—political, racial, regional, religious—and base their decisions on their participation in those groups. For example, when people are shown hypocritical statements made by political leaders in their chosen party, they start squirming and looking for justifications. On the other hand, when they see the same hypocrisy from an opponent, they delight in it and don’t attempt to justify it. Furthermore, when they’re shown a statement that _releases_ their candidate from something that looked hypocritical, they **get a hit of dopamine.** The brain of the partisan starts to need that dopamine—being a partisan person is literally addictive. 



These rationalizations don’t lead or create our morality. Rather, rationalizations happen _after_ we make decisions in order to justify our intuition and convince others (and ourselves) that we’re moral beings. In fact, studies show that expertise in moral reasoning (like being a moral philosophy professor) does not make people any more moral, and might actually make them worse because they’re more capable at making post hoc justifications.

We have evolved not to find truth but to argue, be persuasive, and manipulate when necessary to get others to like us or be on our side. This is why confirmation bias is so strong. We should thus understand that an _individual’s_ power to reason is limited. However, if we put a lot of individuals together, the interactions between them can produce good reasoning if these individuals also have respect for one another. Think about a group of individuals discussing how to fix a car. They might have different ideas about what’s wrong with the car, based on their different experiences, but if they respect one another they’ll be much more likely to come to a solution together than one person trying to fix a car alone. **Any group looking for truth should have ideological and intellectual diversity.**

If the goal is to produce _good behavior,_ then we should trust intuition over reason even more, and create environments like the one Glaucon believed was necessary for a just society—one where humans concerned about their reputations will be more ethical.

[[book_md/the-righteous-mind/part-1|part-1]]

[[book_md/the-righteous-mind/exercise-identify-your-press-secretary|exercise-identify-your-press-secretary]]

![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=e2f97af9-5709-4286-b3ef-a93fdfa2eb8d&sid=1711133063fa11eebdec89a8b8ae3bbc&vid=171147a063fa11eea7440fcfeb230d96&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Book&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fthe-righteous-mind%2Fchapters-3-4&r=&lt=302&evt=pageLoad&sv=1&rn=958378)

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__



