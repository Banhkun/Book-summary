![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# Superforecasting

Back to Discover

[[book_md/superforecasting/preview|preview]]

  * [[book_md/superforecasting|superforecasting]]
  * Full Book Guide

    * [[book_md/superforecasting/shortform-introduction|shortform-introduction]]
    * [[book_md/superforecasting/part-1|part-1]]
    * [[book_md/superforecasting/chapter-3|chapter-3]]
    * [[book_md/superforecasting/chapter-4|chapter-4]]
    * [[book_md/superforecasting/exercise-are-you-a-hedgehog-or-a-fox|exercise-are-you-a-hedgehog-or-a-fox]]
    * [[book_md/superforecasting/part-2|part-2]]
    * [[book_md/superforecasting/exercise-answer-the-ball-and-bat-problem|exercise-answer-the-ball-and-bat-problem]]
    * [[book_md/superforecasting/exercise-generate-new-perspectives|exercise-generate-new-perspectives]]
    * [[book_md/superforecasting/chapter-6|chapter-6]]
    * [[book_md/superforecasting/exercise-embrace-probabilistic-thinking|exercise-embrace-probabilistic-thinking]]
    * [[book_md/superforecasting/chapter-7|chapter-7]]
    * [[book_md/superforecasting/chapter-8|chapter-8]]
    * [[book_md/superforecasting/exercise-develop-a-growth-mindset|exercise-develop-a-growth-mindset]]
    * [[book_md/superforecasting/chapters-9-10|chapters-9-10]]
    * [[book_md/superforecasting/exercise-identify-psychological-safety|exercise-identify-psychological-safety]]
    * [[book_md/superforecasting/chapter-11|chapter-11]]
    * [[book_md/superforecasting/exercise-weigh-the-impact-of-black-swan-events|exercise-weigh-the-impact-of-black-swan-events]]
    * [[book_md/superforecasting/chapter-12|chapter-12]]
  * [[book_md/superforecasting/highlights|highlights]]
  * [[book_md/superforecasting/community|community]]



Adding to Favorites 

Removing from Favorites 

## Chapter 6: Superforecasters Think in Probabilities

Despite all the emphasis on technique over talent, the fact that superforecasters work with such minute numerical details might lead you to believe that superforecasters are secretly an elite class of mathletes. According to the authors, you wouldn’t be completely wrong—superforecasters are almost universally skilled with numbers. What is surprising about that is that **forecasting very rarely _requires_ higher-level math skills. **

(Shortform note: As an example, one superforecaster argued that he and his teammates never explicitly use Bayes’ rule (a mathematical equation for updating predictions) in their forecasts. However, Tetlock countered that while they may not actually whip out the equation for any particular problem, superforecasters are numerate enough to understand the principles of Bayes’ theorem better than most people. We’ll learn more about superforecasters’ Bayesian thinking in Chapter 7.)

### Probabilistic Thinking

So what does superforecasters’ superior numeracy have to do with their success? According to the authors, superforecasters are probabilistic thinkers. This goes beyond just phrasing their forecasts in terms of probability percentages. Essentially, in situations where most of us think in terms of black and white, superforecasters think in shades of grey.

**Most people’s mental “probability dial” has three distinct settings: yes, no, and maybe. By contrast, probabilistic thinkers have an unlimited number of settings.** They’re more likely to answer questions in terms of percentages rather than “yes” or “no.” And this is not just in the realm of forecasting—this is how superforecasters normally think and speak in their everyday lives.

(Shortform note: Superforecasters’ emphasis on probabilistic thinking may help to explain the gender gap among superforecasters, who tend to be male. Young children perform about the same on tests of probabilistic thinking regardless of gender—however, by age 10, boys tend to outperform girls, a pattern that holds true for many other math skills. This could be because, as Sheryl Sandberg argues in _Lean In_ , social norms discourage girls from pursuing math and science.)

#### The Two- (or Three-) Setting Dial

According to Tetlock and Gardner, there is a good reason that most of us are not natural probabilistic thinkers. For most of human history, the three-setting dial was reduced even further to two settings (“yes” or “no”). For our ancestors, this was an advantage. Early humans lived in a world where predators were a constant threat—but our brains and bodies aren’t designed for perpetual vigilance, and stress wears us down over time. Snap judgments became an evolutionary life hack: While the probabilistic thinkers were fretting over the likelihood that a strange noise came from a predator, the concrete thinkers had already landed on an answer and responded accordingly.

(Shortform note: As Daniel Kahneman describes in _Thinking, Fast and Slow_ , this evolutionary mechanism also partly explains why we have such trouble understanding randomness. Our ancestors saved time and mental energy by making snap judgments about whether two things are related—like whether a sound is related to a predator’s presence, or whether seeing predators out hunting is related to the fact that it just rained. Noticing connections (like, “the lions are more active after it rains”) allows us to predict and avoid future threats (in this case, by not going out after a rainy day lest we encounter a hungry lion). Assuming a causal pattern keeps us safe, even if those patterns are really the result of random chance.)

But what about “maybe”? For life-or-death decisions, “maybe” is not particularly helpful. The authors believe that most of us use “maybe” as a last resort, only when the odds are roughly even and the stakes are low. The uncertainty that comes with a “maybe” answer is intuitively unsettling, possibly because we have evolved to associate uncertainty with danger. **We settle for maybe only when we’re forced to—usually for probabilities roughly between 40% and 60%.** Anything higher is “yes," anything lower is “no.”

Two- and three-setting mental dials helped our species survive into the modern era, and they are still helpful when snap decisions are necessary. But thankfully, most of the judgments we make on a daily basis are not immediate, life-or-death decisions. For everything else, the most accurate answer is “maybe.” This is where probabilistic thinkers shine—they see “maybe” not as an answer in itself but as an infinite range of possible answers.

> **Learn to Embrace “Maybe”**
> 
> Thinking probabilistically can help you make better decisions. However, it’s often easier said than done because this method of thinking requires accepting uncertainty, which is new territory for many of us.
> 
> In _Thinking in Bets_ , former professional poker player Annie Duke lays out a strategy for getting comfortable with uncertainty. Duke recommends thinking of each decision as a bet with real money on the line. This trick makes the consequences of being wrong feel more concrete, which can help motivate you to double-check your logic and think about all the possible sources of uncertainty.
> 
> Placing an imaginary bet can be helpful even when we already have a numerical probability prediction. For example, imagine you check the weather forecast and see that there’s an 80% chance of rain. Under normal circumstances, you might interpret that as “it will definitely rain” because 80% is higher than chance. However, if you ask yourself, “Would I bet $500 that it will rain?”, you may feel a lot less confident in that prediction; as a result, you’re more likely to grapple with the uncertainty of the forecast instead of just assuming that an 80% chance is a definite “yes.”

#### The Hunt for bin Laden

The authors describe a historical example of the tension between probabilistic and concrete thinking. In 2011, the intelligence community identified a compound in Pakistan that they suspected housed Osama bin Laden, the terrorist responsible for the 9/11 attacks. There was enough evidence to suggest that bin Laden was in the compound—but not enough for analysts to be completely certain. Leaders from several IC agencies gathered to debate the evidence and come up with a forecast that would ultimately be presented to President Barack Obama, who would decide whether to authorize a raid on the compound.

Although different accounts of that historic conversation vary on the details, the authors report that multiple IC analysts presented their personal confidence levels to the president based on the data available. These confidence levels ranged from 30% to 95%. Averaged together, the group was around 70% certain that the man in that compound was bin Laden. President Obama responded, “This is fifty-fifty. Look guys, this is the flip of the coin.”

Given the context, it’s unlikely that the president meant there was a literal 50% likelihood of bin Laden being in the compound. Instead, the authors believe he used “fifty-fifty” as a synonym for “maybe.” **This illustrates the fundamental difference between probabilistic and concrete thinking: While the analysts were adjusting percentages, the president focused on accepting the inherent uncertainty of the situation and moving on.** His three-setting dial was set to “maybe,” and without enough evidence to move it to “yes” or “no,” that dial was no longer useful to him.

> **Barack Obama Explains His Decision-Making Process**
> 
> In his 2020 memoir, _A Promised Land_ , former president Barack Obama gave his own account of the fateful decision to authorize the raid. Tetlock and Gardner were right to conclude that Obama’s “fifty-fifty” comment was his way of acknowledging the inherent uncertainty of the situation—he knew that, despite the intelligence community’s diligence, they could never be 100% certain that the tall man in the compound really was bin Laden.
> 
> As a result, Obama switched his focus from the odds of success to the possible consequences of failure. Then-vice president Joe Biden was strongly opposed to the raid; he’d been in Washington in 1980 and witnessed the intense fallout from Operation Eagle Claw, the failed attempt to rescue American hostages being held in the U.S. embassy in Tehran. Eight service members were killed in the attempt, and President Carter’s political career never recovered. On top of that, the bin Laden raid was to be conducted without the knowledge or consent of the Pakistani government; if it failed, it would be a major diplomatic disaster.
> 
> Ultimately, Obama weighed these risks against the risk of _not_ authorizing the raid: namely, squandering the best lead the intelligence community had had on bin Laden’s whereabouts in a decade. He decided that, despite the unreliable odds, the chance to take out the criminal responsible for the 9/11 terrorist attacks was worth the risks. The mission was successful: On May 1st, 2011, a Navy SEAL team raided the compound and executed Osama bin Laden.

[[book_md/superforecasting/exercise-generate-new-perspectives|exercise-generate-new-perspectives]]

[[book_md/superforecasting/exercise-embrace-probabilistic-thinking|exercise-embrace-probabilistic-thinking]]

![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=a33c2880-ff00-4151-9a6e-a42c10f14176&sid=f30c5e70639211ee87d33f0876d93783&vid=f30c9700639211eeb3a75d830392c94f&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Book&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fsuperforecasting%2Fchapter-6&r=&lt=404&evt=pageLoad&sv=1&rn=876857)

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__



