![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# Superforecasting

Back to Discover

[[book_md/superforecasting/preview|preview]]

  * [[book_md/superforecasting|superforecasting]]
  * Full Book Guide

    * [[book_md/superforecasting/shortform-introduction|shortform-introduction]]
    * [[book_md/superforecasting/part-1|part-1]]
    * [[book_md/superforecasting/chapter-3|chapter-3]]
    * [[book_md/superforecasting/chapter-4|chapter-4]]
    * [[book_md/superforecasting/exercise-are-you-a-hedgehog-or-a-fox|exercise-are-you-a-hedgehog-or-a-fox]]
    * [[book_md/superforecasting/part-2|part-2]]
    * [[book_md/superforecasting/exercise-answer-the-ball-and-bat-problem|exercise-answer-the-ball-and-bat-problem]]
    * [[book_md/superforecasting/exercise-generate-new-perspectives|exercise-generate-new-perspectives]]
    * [[book_md/superforecasting/chapter-6|chapter-6]]
    * [[book_md/superforecasting/exercise-embrace-probabilistic-thinking|exercise-embrace-probabilistic-thinking]]
    * [[book_md/superforecasting/chapter-7|chapter-7]]
    * [[book_md/superforecasting/chapter-8|chapter-8]]
    * [[book_md/superforecasting/exercise-develop-a-growth-mindset|exercise-develop-a-growth-mindset]]
    * [[book_md/superforecasting/chapters-9-10|chapters-9-10]]
    * [[book_md/superforecasting/exercise-identify-psychological-safety|exercise-identify-psychological-safety]]
    * [[book_md/superforecasting/chapter-11|chapter-11]]
    * [[book_md/superforecasting/exercise-weigh-the-impact-of-black-swan-events|exercise-weigh-the-impact-of-black-swan-events]]
    * [[book_md/superforecasting/chapter-12|chapter-12]]
  * [[book_md/superforecasting/highlights|highlights]]
  * [[book_md/superforecasting/community|community]]



Adding to Favorites 

Removing from Favorites 

## Chapter 11: Does Superforecasting Really Matter?

Superforecasting is an impressive skill, and certain superforecaster traits can turn good leaders into great ones. But Tetlock and Gardner caution that human brains are not built for objective analysis. As we’ve noted, even the best superforecasters are not immune to cognitive bias. So what is the point of developing superforecasting abilities if we are always one unchecked assumption away from being completely wrong? In this chapter, we’ll explore that question.

### The Superforecaster vs. the Black Swan

According to the authors, the value of _any_ kind of forecasting is predicated on the assumption that it’s possible to predict meaningful future events in the first place. This is not a universally accepted idea.

One strong critic of superforecasting is author and former Wall Street trader Nassim Taleb, who argues that the only truly important events in the course of history have been completely unpredictable. He calls these “black swan events.” (Shortform note: In _The Black Swan_ , Taleb describes another characteristic of black swan events that Tetlock and Gardner don’t address: the fact that humans struggle to accept the inherent unpredictability of black swans. In the aftermath of a black swan event, people often try to argue that the event was, in fact, predictable, despite the fact that no one successfully predicted it.)

If Taleb is right, there is no point to developing forecasting skills, because the only events that matter are the ones that cannot possibly be predicted.

So is forecasting a fool’s errand? For that to be true, the authors argue, we need to accept _both_ of Taleb’s conclusions: that black swan events are literally impossible to predict, and that _only_ black swan events change the course of history. Let’s explore both of these conclusions in detail.

#### Are “Black Swans” Totally Unpredictable?

If the term “black swan” only describes truly unpredictable events, then the authors believe there have been very few actual black swans in history. The most commonly cited black swan example is the 9/11 terrorist attacks. But even 9/11 was not completely impossible to predict—similar attacks had been thwarted in the past, and the intelligence community was actively examining the threat.

In practice, that evidence means that while it would have been extremely difficult to predict the exact date and time of the 9/11 attacks, it was entirely possible to predict a terrorist attack in which a plane was turned into a flying bomb, and several people actually _did_ make this prediction before the event.

(Shortform note: Taleb would disagree that 9/11 was at all predictable. In fact, in _The Black Swan_ , he argues that the 9/11 attacks weren’t just unpredictable—they happened _because_ they were unpredictable (because if we’d been able to predict the attacks, we’d have prevented them happening in the first place). His concept of “successfully predicting” black swans seems to rely on predicting them _exactly_ , including the specific time, place, and people involved.)

But what if we take “black swans” to mean, in Taleb’s words, “highly improbable consequential events,” rather than events that can’t possibly be predicted? In that case, Taleb’s logic becomes easier to swallow. The authors argue that black swans, even defined more loosely, are still incredibly rare by definition, and it could take hundreds or even thousands of years to generate the amount of data that would allow us to calibrate how accurately we can predict them. In that sense, Taleb is correct—trying to predict black swan events is pointless.

> **Black Swan Predictions Get Lost in the Noise**
> 
> We’ve seen how many people predicted an event similar to the events of September 11, 2001. In the face of that evidence, we could argue that the issue is not the pure inability to predict these events—the issue is that even if a few people _do_ predict a black swan, there’s no real reason to listen to those particular people over the millions of others predicting things that will never happen. Data scientists call this “noise,” which is all the extraneous information that obscures the “signal” that we need to focus on. In _Fooled by Randomness_ , Taleb describes how noise makes it nearly impossible to successfully identify which signals will end up being relevant in the future. In other words, the dots are there, but we can only connect them after the fact, once we know how it all works out.

#### Are “Black Swans” the Only Events That Matter?

The second part of Taleb’s logic is that _only_ black swan events change the course of history. This claim is much easier to dispute, as we have evidence that non-black swan events have changed the world—the gradual development of technology and slow growth of the global economy have had enormous consequences. Improved technology has led to advances in medicine, hygiene, infrastructure, and so on—all undeniably important developments with no single black swan cause.

> **COVID-19: The “White Swan” That Changed the World**
> 
> The COVID-19 pandemic blew a massive hole in Taleb’s theory that black swans are the single most important events in human history. While some people have described the pandemic as a black swan, Taleb argues that the COVID-19 pandemic is an archetypal white swan because so many people warned of the exponential risks of a pandemic in an age of global connectivity—including Taleb himself in a January, 2020 paper on the topic.
> 
> However, while COVID-19 may have been a white swan, there is no doubt that both the pandemic and its social, political, and economic fallout have fundamentally changed many aspects of daily life for people all over the globe. Taleb conceded this point in a 2021 interview in which he predicted how the pandemic will permanently impact certain industries (such as real estate) and how countries with unsuccessful pandemic responses will struggle in the future. In other words, the pandemic is unimpeachable evidence that predictable events can be even more impactful than black swans.

##### The Consequences Are Predictable, Even if the Event Isn’t

Tetlock and Gardner believe that it’s also important to consider where we draw the boundaries of an event itself. For example, we don’t talk about the 2008 financial crisis as a black swan event just because it was unpredictable—unpredictable things happen all the time without earth-shattering ramifications. But the 2008 financial crisis marks a turning point in world history because it launched a worldwide economic recession. In other words,**what makes black swans so important is not just the event itself but the _consequences._**

This presents a challenge to Taleb’s logic. While the details of the 2008 recession may have been unpredictable, the consequences were not. Superforecasters have made accurate forecasts on questions like the likelihood that a government will bail out certain institutions or how much unemployment rates will rise during a recession. If black swans are important in part because of their consequences, and superforecasters can predict some of those consequences, then forecasting itself is a useful enterprise.

> **Becoming “Antifragile” Requires Anticipating Consequences**
> 
> Tetlock and Gardner present this emphasis on consequences as part of their rebuttal to Taleb’s criticism of formal forecasting. As a reminder, Taleb thinks forecasting is pointless because the only events worth predicting are, by his definition, unpredictable. As we’ve just seen Tetlock and Gardner disagree because the consequences of important events are possible to predict, even if the events themselves are not, and these consequences are important too.
> 
> Taleb would most likely agree that the consequences of black swan events are a big part of what makes them so important. His 2012 book, _Antifragile_ , primarily focuses on the consequences of black swan events.
> 
> However, unlike Tetlock, Taleb isn’t all that concerned with predicting the likelihood of any given consequence. Instead, his goal is to be “antifragile,” which means to position himself in such a way that he’s protected from the consequences of negative black swans while still poised to benefit from positive black swan outcomes (for example, by making a fortune investing in Apple or Google when they first started out and weren’t guaranteed successes). In Taleb’s eyes, trying to predict which consequences are likely to occur is futile because prediction is so tricky to get right, and the most influential events are unpredictable anyway. It’s therefore a better use of time and energy to focus on strengthening our position to the extent that we can weather (or exploit) any and every consequence.

### How Do We Prepare for the Unpredictable?

Taleb, Kahneman, and Tetlock all agree that trying to predict events more than a few years in the future is pointless because too much can change in that amount of time. But _not_ anticipating future events is often not an option, even if those events are unlikely, due to their possible consequences.

For example, there is a network of underground bunkers beneath the White House designed to keep the American president, the president’s immediate family, and key cabinet members safe in an emergency (such as a terrorist attack). The most recent addition to this network cost at least $86 million, an enormously high price tag for something that, so far, hasn't been used. However, losing these key members of government in a terrorist attack would be catastrophic, so the preparation is arguably justified.

All of this preparation depends on context. Why isn’t there an $86 million dollar bunker beneath each state governor’s residence? Because **the probability of disaster must be high enough to justify the cost of preparation**(and the White House is a likelier target for an international terrorist attack than a governor’s mansion).

(Shortform note: In situations where there is a small risk of big disaster, people often choose to ignore the situation entirely instead of preparing for the worst. For example, Tetlock believes that although many people predicted the COVID-19 pandemic, governments still weren’t adequately prepared for a pandemic because it’s “too easy to tune out chronic low-probability risks.”)

[[book_md/superforecasting/exercise-identify-psychological-safety|exercise-identify-psychological-safety]]

[[book_md/superforecasting/exercise-weigh-the-impact-of-black-swan-events|exercise-weigh-the-impact-of-black-swan-events]]

![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=9a42bbae-9934-4a7f-88cf-87916ab125e3&sid=f30c5e70639211ee87d33f0876d93783&vid=f30c9700639211eeb3a75d830392c94f&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Book&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fsuperforecasting%2Fchapter-11&r=&lt=355&evt=pageLoad&sv=1&rn=594639)

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__



