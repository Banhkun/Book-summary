![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

Discover

Books

Articles

My library

Search

Discover

![Shortform App](/img/logo.36a2399e.svg)![Shortform App](/img/logo-dark.70c1b072.svg)

# Superforecasting

Back to Discover

[[book_md/superforecasting/preview|preview]]

  * [[book_md/superforecasting|superforecasting]]
  * Full Book Guide

    * [[book_md/superforecasting/shortform-introduction|shortform-introduction]]
    * [[book_md/superforecasting/part-1|part-1]]
    * [[book_md/superforecasting/chapter-3|chapter-3]]
    * [[book_md/superforecasting/chapter-4|chapter-4]]
    * [[book_md/superforecasting/exercise-are-you-a-hedgehog-or-a-fox|exercise-are-you-a-hedgehog-or-a-fox]]
    * [[book_md/superforecasting/part-2|part-2]]
    * [[book_md/superforecasting/exercise-answer-the-ball-and-bat-problem|exercise-answer-the-ball-and-bat-problem]]
    * [[book_md/superforecasting/exercise-generate-new-perspectives|exercise-generate-new-perspectives]]
    * [[book_md/superforecasting/chapter-6|chapter-6]]
    * [[book_md/superforecasting/exercise-embrace-probabilistic-thinking|exercise-embrace-probabilistic-thinking]]
    * [[book_md/superforecasting/chapter-7|chapter-7]]
    * [[book_md/superforecasting/chapter-8|chapter-8]]
    * [[book_md/superforecasting/exercise-develop-a-growth-mindset|exercise-develop-a-growth-mindset]]
    * [[book_md/superforecasting/chapters-9-10|chapters-9-10]]
    * [[book_md/superforecasting/exercise-identify-psychological-safety|exercise-identify-psychological-safety]]
    * [[book_md/superforecasting/chapter-11|chapter-11]]
    * [[book_md/superforecasting/exercise-weigh-the-impact-of-black-swan-events|exercise-weigh-the-impact-of-black-swan-events]]
    * [[book_md/superforecasting/chapter-12|chapter-12]]
  * [[book_md/superforecasting/highlights|highlights]]
  * [[book_md/superforecasting/community|community]]



Adding to Favorites 

Removing from Favorites 

## Shortform Introduction

_Superforecasting_ is the result of decades of research on **“superforecasters”: people who can predict future events with an accuracy better than chance.** Superforecasters are intelligent, but more importantly, they’re open-minded, deeply curious, and adept at sidestepping their own cognitive biases. Not everyone is cut out to be a superforecaster, but by studying the way superforecasters make predictions, anyone can improve their ability to predict the future.

### About the Authors

**Phillip Tetlock is a Canadian-American author and researcher** focusing on good judgment, political psychology, and behavioral economics.**** He currently teaches at the University of Pennsylvania in the Wharton School of business as well as the departments of psychology and political science.

In 2011, Tetlock and his spouse, psychologist Barbara Mellers, co-founded the Good Judgment Project, a research project involving more than twenty thousand amateur forecasters. The Project was designed to discover just how accurate the best human forecasters can be and what makes some people better forecasters than others. It led to Tetlock discovering a group of “superforecasters” who could outperform professional intelligence analysts; these findings eventually inspired _Superforecasting_.

Today, the Good Judgment Project hosts training sessions on general forecasting techniques for both individuals and organizations as well as producing custom forecasts.

**Connect with Philip Tetlock:**

  * Academic Profile
  * Twitter
  * LinkedIn



**Dan Gardner is a Canadian journalist and co-author of _Superforecasting_.** Gardner has authored two other books on the psychology of decision-making and prediction:_Risk: The Science and Politics of Fear_ in 2008, which delves into the science of how we make decisions about risky situations; and _Future Babble_ , in 2011, which explores Tetlock’s earlier research on experts’ inability to accurately predict the future. He is a senior fellow at the University of Ottawa’s Graduate School of Public Policy and International Affairs.

**Connect with Dan Gardner:**

  * Website
  * Twitter
  * LinkedIn
  * Academic Profile



### The Book’s Publication

Publisher: Crown Publishing Group, a subsidiary of Penguin Random House

_Superforecasting_ was published in 2015. It is Tetlock’s fourth book (Gardner’s third) and is the most well-known book in both authors’ respective bibliographies.

_Superforecasting_ builds on Tetlock’s previous book, _Expert Political Judgment_ , in which he first described the results of the Good Judgment Project and answered the question, “Why are political experts so bad at making predictions?” In _Superforecasting_ , Tetlock turns his attention away from experts’ failures and toward the successes of a few average people who can predict global events more accurately than chance.

### The Book’s Context

#### Intellectual Context

The idea for _Superforecasting_ came from Tetlock’s experiences with the Expert Political Judgment and Good Judgment Project forecasting experiments, during which Tetlock and his research team discovered that some people are significantly better at predicting the future than others. Tetlock and Gardner set out to explore exactly what sets this group of “superforecasters” apart from regular forecasters; _Superforecasting_ is the result.

**_Superforecasting_ fits in with the tidal wave of research on issues of predictability, uncertainty, and cognitive biases that happened in the 2000s and 2010s.** _Superforecasting_ directly references Daniel Kahneman’s _Thinking, Fast and Slow_ ; Kahneman’s pioneering research on metacognition and cognitive biases paved the way for Tetlock’s study of the limits of forecasting. Tetlock and Gardner also directly reference Nassim Nicholas Taleb, author of several books on uncertainty, including _The Black Swan_ , _Antifragile_ , and _Fooled by Randomness. _Taleb is deeply critical of forecasting as an enterprise, and the authors devote an entire section of _Superforecasting_ to addressing his critiques.

At its core, _Superforecasting_ is an exploration of how superforecasters think, with a particular emphasis on the way they avoid knee jerk assumptions and cognitive biases. This presents a helpful counterpart to books like Dan Ariely’s _Predictably Irrational _and Malcolm Gladwell’s _Blink, _both of which explore the risks and benefits of subconscious thinking in more depth.

#### The Book’s Impact

_Superforecasting_ was a New York Times bestseller and was listed as “One of the Best Books of 2015” by Amazon, Bloomberg, and The Economist. **The book’s intellectual impact was strongest within the fields of forecasting and behavioral science.** For example, poker champion and author Annie Duke references _Superforecasting_ in her 2018 book, _Thinking in Bets_ , in which she builds on Tetlock’s research on avoiding cognitive biases and creating teams of like-minded people to help make decisions.

_Superforecasting_ also played a small role in a British government scandal. Dominic Cummings, former aide to UK Prime Minister Boris Johnson, told reporters to read the book instead of listening to “political pundits who don’t know what they’re talking about.” He even wrote his own glowing review of the book on his personal blog. Cummings also hired Andrew Sabisky, a superforecaster, as an advisor. However, Sabisky resigned after only a few days on the job after old blog posts surfaced in which he claimed that Black people have lower IQs than white people and that the government should adopt eugenics policies to prevent the growth of the “lower class.” For many people, this scandal was their first encounter with the concept of “superforecasting.”

### The Book’s Strengths and Weaknesses

#### Critical Reception

_Superforecasting_ was generally well-received by critics and readers. People in a wide variety of fields—including real estate, ecology, management, and actuarial science—gave _Superforecasting_ positive reviews and recommended it to anyone in their respective industries who wants to improve their decision-making skills. A _New York Times_ reviewer praised the book for providing practical advice on how to make better forecasts rather than just describing the forecasting process. Some reviewers even tried their hand at making their own forecasts after reading the book.

Critical reviews of _Superforecasting_ focus not so much on the book itself as on the utility of forecasting as a practice. One reviewer argued that, while superforecasters may be able to make accurate predictions about very specific events in the near future, the types of events they predict are not the ones we should be most worried about. Instead, we should focus on the events that are likely to have the biggest impact on society—which are likely to be so rare that they are completely unpredictable. These events are what author Nassim Nicholas Taleb calls “black swans,” which we’ll explore in depth in this guide.

#### Commentary on the Book’s Approach

While _Superforecasting_ has two official authors, the book is written in Tetlock’s voice as he describes his personal experience conducting decades of research on forecasting tournaments. Tetlock and Gardner accurately represent the criticisms other authors (such as Taleb) have levied against formal forecasting and make a compelling case for the utility of forecasting as an enterprise, especially on a national and global scale. The authors also describe the techniques that superforecasters use in enough detail that readers come away well-equipped to try making their own predictions. (If you’d like to test your forecasting skills after reading, you can take on one of the challenges in the Good Judgment Open, an online, ongoing forecasting tournament.)

#### Commentary on the Book’s Organization

_Superforecasting_ begins with an overview of Tetlock’s approach to forecasting, including both his optimism about the strengths of “superforecasters” as well as his understanding that, while superforecasters make more accurate predictions than other forecasters, there is still a hard limit to how far any human can see into the future. The authors then discuss the difficulties of measuring a forecaster’s accuracy, how the lack of a solid measurement system has significantly hindered forecasting research, and how Tetlock’s “Expert Political Judgment” and “Good Judgment Project” forecasting tournaments changed the landscape of forecasting research. The bulk of _Superforecasting_ describes the skills and traits of the superforecasters themselves with the goal of advancing the authors’ thesis: that the skills that make superforecasters so “super” aren’t inborn—they can be developed with practice.

The book’s organization serves the authors’ goal of introducing the reader to the world of formal forecasting, holding up superforecasters as a model of the full potential of human forecasting, and arguing for the importance of forecasting tournaments. The authors seem to understand that the kind of formal, geopolitical forecasting that goes on in forecasting tournaments is completely foreign to many readers, so they begin with very general concepts (like the idea that, to a certain degree, the future is knowable) before getting into more specific details of what makes superforecasters so good at what they do.

One downside to the authors’ decision to move from broad concepts to specific details is that certain core ideas are separated into multiple parts of the book, which can be confusing for the reader. For example, the sections on calculating Brier scores and measuring regression to the mean—two ways of measuring forecasters’ performance—are located in two different chapters.

### Our Approach in This Guide

In this guide, we’ve moved some sections of the book’s original chapters to other chapters to keep information on major ideas together. For example, the section on cognitive biases from the book’s Chapter 2 is now in Chapter 5, which outlines common traits of superforecasters. That’s because avoiding common biases is an important skill that superforecasters practice.

To begin the guide, we’ll discuss the history and underlying theory of formal forecasting (including the forecasting tournaments that ultimately led to the discovery of superforecasters) to give readers an overview of the field. Then, we’ll discuss the process of identifying “superforecasters” using precise measurements of accuracy. Next, we’ll move into the largest section of the guide: an overview of the traits that make superforecasters so good at predicting the future, such as embracing uncertainty, updating their predictions, and being generous teammates. Finally, we’ll address the major criticisms of forecasting (such as the relative importance of unpredictable “black swan” events) and how those concerns might impact the future of forecasting.

Throughout the guide, we’ll compare Tetlock and Gardner’s approach to ideas from other popular books on forecasting, decision making, behavioral economics, and cognitive psychology, such as Daniel Kahneman’s _Thinking, Fast and Slow_ ; Malcolm Gladwell’s _Blink_ ; Dan Ariely’s _Predictably Irrational_ ; and Nassim Nicholas Taleb’s _Fooled by Randomness,_ _The Black Swan, _and _Antifragile. _Taleb is highly critical of forecasting, and we’ll explore these criticisms (and the resulting professional friction between Tetlock and Taleb) in detail.

[[book_md/superforecasting/1-page-summary|1-page-summary]]

[[book_md/superforecasting/part-1|part-1]]

![](https://bat.bing.com/action/0?ti=56018282&Ver=2&mid=59a5bb63-3b63-490b-bffd-2ac342fa8f3a&sid=f30c5e70639211ee87d33f0876d93783&vid=f30c9700639211eeb3a75d830392c94f&vids=0&msclkid=N&pi=0&lg=en-US&sw=800&sh=600&sc=24&nwd=1&tl=Shortform%20%7C%20Book&p=https%3A%2F%2Fwww.shortform.com%2Fapp%2Fbook%2Fsuperforecasting%2Fshortform-introduction&r=&lt=388&evt=pageLoad&sv=1&rn=407184)

__

  *   * Allow anyone to **view** this annotation
  * Allow anyone to **edit** this annotation



* * *

Save Cancel

__



